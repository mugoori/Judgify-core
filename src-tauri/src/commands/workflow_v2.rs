use serde::{Deserialize, Serialize};
use crate::services::workflow_service::WorkflowService;
use crate::engines::rule_engine::RuleEngine;
use crate::services::judgment_engine::{JudgmentEngine, JudgmentInput};
use serde_json::json;
use rusqlite::{params, Connection};

/// Phase 9 WorkflowBuilderV2ìš© ë°ì´í„° êµ¬ì¡°
///
/// Ver2.0 6ê°œ NodeType:
/// - TRIGGER: íŠ¸ë¦¬ê±° (ì„ê³„ê°’, ìŠ¤ì¼€ì¤„, ì´ë²¤íŠ¸, ìˆ˜ë™)
/// - QUERY: ë°ì´í„° ì¡°íšŒ (DB, API, ì„¼ì„œ, íŒŒì¼)
/// - CALC: ê³„ì‚° (ìˆ˜ì‹, ì§‘ê³„, ë³€í™˜)
/// - JUDGMENT: AI íŒë‹¨ (Rule/LLM/Hybrid)
/// - APPROVAL: ìŠ¹ì¸ (ìˆ˜ë™, ìë™, ì¡°ê±´ë¶€)
/// - ALERT: ì•Œë¦¼ (Email, Slack, Teams, Webhook)

/// ì›Œí¬í”Œë¡œìš° ë©”íƒ€ë°ì´í„° (WorkflowBuilderV2.tsxì™€ ë™ê¸°í™”)
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct WorkflowMetadata {
    pub name: String,
    pub description: String,
    #[serde(rename = "isActive")]
    pub is_active: bool,
}

/// ì›Œí¬í”Œë¡œìš° ìŠ¤í… (WorkflowBuilderV2.tsxì™€ ë™ê¸°í™”)
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct WorkflowStep {
    pub id: String,
    #[serde(rename = "type")]
    pub step_type: String, // "TRIGGER" | "QUERY" | "CALC" | "JUDGMENT" | "APPROVAL" | "ALERT"
    pub label: String,
    pub config: serde_json::Value, // NodeTypeë³„ ì„¤ì • (Formsì—ì„œ ìƒì„±)
}

/// ì›Œí¬í”Œë¡œìš° ì €ì¥ ìš”ì²­ (Phase 2 UI â†’ Backend)
#[derive(Debug, Serialize, Deserialize)]
pub struct SaveWorkflowRequest {
    pub metadata: WorkflowMetadata,
    pub steps: Vec<WorkflowStep>,
}

/// ì›Œí¬í”Œë¡œìš° ì €ì¥ ì‘ë‹µ
#[derive(Debug, Serialize, Deserialize)]
pub struct SaveWorkflowResponse {
    pub id: String,
    pub version: i32,
    pub message: String,
}

/// ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸° ì‘ë‹µ
#[derive(Debug, Serialize, Deserialize)]
pub struct LoadWorkflowResponse {
    pub id: String,
    pub metadata: WorkflowMetadata,
    pub steps: Vec<WorkflowStep>,
    pub version: i32,
    pub created_at: String,
}

/// ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ ì‘ë‹µ
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkflowListItem {
    pub id: String,
    pub name: String,
    pub description: String,
    pub is_active: bool,
    pub step_count: usize,
    pub version: i32,
    pub created_at: String,
}

/// ì›Œí¬í”Œë¡œìš° ì €ì¥ Tauri Command
///
/// Phase 3-2ì—ì„œ êµ¬í˜„ë  CRUD APIì˜ ì¼ë¶€
/// Frontend: WorkflowBuilderV2.handleSaveWorkflow() â†’ Backend: ì´ í•¨ìˆ˜
#[tauri::command]
pub async fn save_workflow_v2(
    request: SaveWorkflowRequest,
) -> Result<SaveWorkflowResponse, String> {
    println!("ğŸ’¾ [WorkflowV2] ì›Œí¬í”Œë¡œìš° ì €ì¥ ìš”ì²­:");
    println!("   ì´ë¦„: {}", request.metadata.name);
    println!("   ìŠ¤í… ê°œìˆ˜: {}", request.steps.len());

    // JSON definition ìƒì„± (Phase 2 êµ¬ì¡° ê·¸ëŒ€ë¡œ ì €ì¥)
    let definition = json!({
        "metadata": request.metadata,
        "steps": request.steps,
        "version": "2.0", // Phase 2 ë²„ì „
        "format": "vertical-list" // Phase 2 UI í˜•ì‹
    });

    // WorkflowServiceë¡œ ì €ì¥
    let service = WorkflowService::new()
        .map_err(|e| format!("WorkflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e))?;

    let workflow = service
        .create_workflow(
            request.metadata.name.clone(),
            definition,
            None, // rule_expressionì€ JUDGMENT ë…¸ë“œ configì— ì €ì¥ë¨
        )
        .map_err(|e| format!("ì›Œí¬í”Œë¡œìš° ì €ì¥ ì‹¤íŒ¨: {}", e))?;

    println!("âœ… [WorkflowV2] ì›Œí¬í”Œë¡œìš° ì €ì¥ ì™„ë£Œ: {}", workflow.id);

    Ok(SaveWorkflowResponse {
        id: workflow.id,
        version: workflow.version,
        message: "ì›Œí¬í”Œë¡œìš°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.".to_string(),
    })
}

/// ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸° Tauri Command
#[tauri::command]
pub async fn load_workflow_v2(workflow_id: String) -> Result<LoadWorkflowResponse, String> {
    println!("ğŸ“‚ [WorkflowV2] ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸°: {}", workflow_id);

    let service = WorkflowService::new()
        .map_err(|e| format!("WorkflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e))?;

    let workflow = service
        .get_workflow(&workflow_id)
        .map_err(|e| format!("ì›Œí¬í”Œë¡œìš° ì¡°íšŒ ì‹¤íŒ¨: {}", e))?
        .ok_or_else(|| format!("ì›Œí¬í”Œë¡œìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", workflow_id))?;

    // JSON definition íŒŒì‹±
    let definition: serde_json::Value = serde_json::from_str(&workflow.definition)
        .map_err(|e| format!("ì›Œí¬í”Œë¡œìš° definition íŒŒì‹± ì‹¤íŒ¨: {}", e))?;

    let metadata: WorkflowMetadata = serde_json::from_value(definition["metadata"].clone())
        .map_err(|e| format!("metadata íŒŒì‹± ì‹¤íŒ¨: {}", e))?;

    let steps: Vec<WorkflowStep> = serde_json::from_value(definition["steps"].clone())
        .map_err(|e| format!("steps íŒŒì‹± ì‹¤íŒ¨: {}", e))?;

    println!("âœ… [WorkflowV2] ì›Œí¬í”Œë¡œìš° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: {} (ìŠ¤í… {}ê°œ)", workflow.id, steps.len());

    Ok(LoadWorkflowResponse {
        id: workflow.id,
        metadata,
        steps,
        version: workflow.version,
        created_at: workflow.created_at.to_rfc3339(),
    })
}

/// ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ Tauri Command
#[tauri::command]
pub async fn list_workflows_v2() -> Result<Vec<WorkflowListItem>, String> {
    println!("ğŸ“‹ [WorkflowV2] ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ");

    let service = WorkflowService::new()
        .map_err(|e| format!("WorkflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e))?;

    let workflows = service
        .get_all_workflows()
        .map_err(|e| format!("ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {}", e))?;

    let list: Vec<WorkflowListItem> = workflows
        .into_iter()
        .filter_map(|w| {
            // JSON definition íŒŒì‹±
            let definition: serde_json::Value = serde_json::from_str(&w.definition).ok()?;

            // metadata ì¶”ì¶œ
            let metadata: WorkflowMetadata = serde_json::from_value(definition["metadata"].clone()).ok()?;

            // steps ë°°ì—´ í¬ê¸° ì¶”ì¶œ
            let steps_count = definition["steps"].as_array().map(|arr| arr.len()).unwrap_or(0);

            Some(WorkflowListItem {
                id: w.id,
                name: metadata.name,
                description: metadata.description,
                is_active: w.is_active,
                step_count: steps_count,
                version: w.version,
                created_at: w.created_at.to_rfc3339(),
            })
        })
        .collect();

    println!("âœ… [WorkflowV2] ì›Œí¬í”Œë¡œìš° ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {}ê°œ", list.len());

    Ok(list)
}

/// ì›Œí¬í”Œë¡œìš° ì‚­ì œ Tauri Command (Soft Delete)
#[tauri::command]
pub async fn delete_workflow_v2(workflow_id: String) -> Result<String, String> {
    println!("ğŸ—‘ï¸ [WorkflowV2] ì›Œí¬í”Œë¡œìš° ì‚­ì œ: {}", workflow_id);

    let service = WorkflowService::new()
        .map_err(|e| format!("WorkflowService ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e))?;

    service
        .delete_workflow(&workflow_id)
        .map_err(|e| format!("ì›Œí¬í”Œë¡œìš° ì‚­ì œ ì‹¤íŒ¨: {}", e))?;

    println!("âœ… [WorkflowV2] ì›Œí¬í”Œë¡œìš° ì‚­ì œ ì™„ë£Œ: {}", workflow_id);

    Ok(format!("ì›Œí¬í”Œë¡œìš° {}ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", workflow_id))
}

/// ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜ ìš”ì²­
#[derive(Debug, Serialize, Deserialize)]
pub struct SimulateWorkflowRequest {
    pub workflow_id: String,
    pub steps: Vec<WorkflowStep>,
    pub test_data: serde_json::Value, // ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ ë°ì´í„°
}

/// ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ
#[derive(Debug, Serialize, Deserialize)]
pub struct SimulateWorkflowResponse {
    pub workflow_id: String,
    pub steps_executed: Vec<StepExecutionResult>,
    pub final_result: serde_json::Value,
    pub total_execution_time_ms: u64,
    pub status: String, // "success" | "partial_success" | "error"
}

/// ìŠ¤í… ì‹¤í–‰ ê²°ê³¼
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct StepExecutionResult {
    pub step_id: String,
    pub step_type: String,
    pub label: String,
    pub status: String, // "success" | "error" | "skipped"
    pub input: serde_json::Value,
    pub output: Option<serde_json::Value>,
    pub error: Option<String>,
    pub execution_time_ms: u64,
}

/// ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì´ë ¥ ëª©ë¡ í•­ëª©
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkflowExecutionListItem {
    pub id: String,
    pub workflow_id: String,
    pub status: String,
    pub execution_time_ms: i64,
    pub created_at: String,
}

/// ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì´ë ¥ ìƒì„¸
#[derive(Debug, Serialize, Deserialize)]
pub struct WorkflowExecutionDetail {
    pub id: String,
    pub workflow_id: String,
    pub status: String,
    pub steps_executed: Vec<StepExecutionResult>,
    pub final_result: serde_json::Value,
    pub execution_time_ms: i64,
    pub created_at: String,
}

/// ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜ Tauri Command
///
/// Phase 3-5ì—ì„œ 6ê°œ NodeType ì‹¤í–‰ ë¡œì§ êµ¬í˜„
/// í˜„ì¬ëŠ” ê¸°ë³¸ ìŠ¤ì¼ˆë ˆí†¤ë§Œ ì œê³µ
#[tauri::command]
pub async fn simulate_workflow_v2(
    request: SimulateWorkflowRequest,
) -> Result<SimulateWorkflowResponse, String> {
    println!("ğŸ­ [WorkflowV2] ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘: {}", request.workflow_id);
    println!("   ìŠ¤í… ê°œìˆ˜: {}", request.steps.len());

    let start_time = std::time::Instant::now();
    let mut steps_executed: Vec<StepExecutionResult> = Vec::new();
    let mut global_data = request.test_data.clone();
    let mut overall_status = "success".to_string();

    // ê° ìŠ¤í… ìˆœì°¨ ì‹¤í–‰
    for step in request.steps.iter() {
        println!("  â–¶ï¸ ìŠ¤í… ì‹¤í–‰: {} ({})", step.label, step.step_type);

        let step_start = std::time::Instant::now();
        let result = execute_step_v2(step, &global_data).await;

        let execution_time = step_start.elapsed().as_millis() as u64;

        match result {
            Ok((output, next_data)) => {
                steps_executed.push(StepExecutionResult {
                    step_id: step.id.clone(),
                    step_type: step.step_type.clone(),
                    label: step.label.clone(),
                    status: "success".to_string(),
                    input: global_data.clone(),
                    output: Some(output.clone()),
                    error: None,
                    execution_time_ms: execution_time,
                });

                // ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë°ì´í„° ì „ë‹¬
                global_data = next_data;
            }
            Err(e) => {
                steps_executed.push(StepExecutionResult {
                    step_id: step.id.clone(),
                    step_type: step.step_type.clone(),
                    label: step.label.clone(),
                    status: "error".to_string(),
                    input: global_data.clone(),
                    output: None,
                    error: Some(e.clone()),
                    execution_time_ms: execution_time,
                });

                overall_status = "partial_success".to_string();
                println!("  âŒ ìŠ¤í… ì‹¤í–‰ ì‹¤íŒ¨: {}", e);
                break; // ì—ëŸ¬ ë°œìƒì‹œ ì¤‘ë‹¨
            }
        }
    }

    let total_time = start_time.elapsed().as_millis() as u64;

    println!("âœ… [WorkflowV2] ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: {}ms (ìƒíƒœ: {})", total_time, overall_status);

    // DBì— ì‹¤í–‰ ì´ë ¥ ì €ì¥
    let execution_id = match get_db_connection() {
        Ok(conn) => {
            match save_workflow_execution(
                &conn,
                &request.workflow_id,
                &overall_status,
                &steps_executed,
                &global_data,
                total_time,
            ) {
                Ok(id) => Some(id),
                Err(e) => {
                    eprintln!("âš ï¸ [WorkflowV2] DB ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œ): {}", e);
                    None
                }
            }
        }
        Err(e) => {
            eprintln!("âš ï¸ [WorkflowV2] DB ì—°ê²° ì‹¤íŒ¨ (ë¬´ì‹œ): {}", e);
            None
        }
    };

    if let Some(id) = &execution_id {
        println!("ğŸ’¾ [WorkflowV2] ì‹¤í–‰ ID: {}", id);
    }

    Ok(SimulateWorkflowResponse {
        workflow_id: request.workflow_id,
        steps_executed,
        final_result: global_data,
        total_execution_time_ms: total_time,
        status: overall_status,
    })
}

/// ê°œë³„ ìŠ¤í… ì‹¤í–‰ ë¡œì§
///
/// Phase 3-5ì—ì„œ 6ê°œ NodeTypeë³„ ì‹¤í–‰ ë¡œì§ ìƒì„¸ êµ¬í˜„
/// í˜„ì¬ëŠ” ê¸°ë³¸ ìŠ¤ì¼ˆë ˆí†¤ë§Œ ì œê³µ
async fn execute_step_v2(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    match step.step_type.as_str() {
        "TRIGGER" => execute_trigger_step(step, input_data).await,
        "QUERY" => execute_query_step(step, input_data).await,
        "CALC" => execute_calc_step(step, input_data).await,
        "JUDGMENT" => execute_judgment_step(step, input_data).await,
        "APPROVAL" => execute_approval_step(step, input_data).await,
        "ALERT" => execute_alert_step(step, input_data).await,
        _ => Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤í… íƒ€ì…: {}", step.step_type)),
    }
}

/// TRIGGER ìŠ¤í… ì‹¤í–‰
async fn execute_trigger_step(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    let config = &step.config;
    let trigger_type = config["triggerType"].as_str().unwrap_or("manual");

    match trigger_type {
        "threshold" => {
            // ì„ê³„ê°’ ì´ˆê³¼ íŠ¸ë¦¬ê±°
            let condition = config["condition"].as_str().ok_or("condition í•„ë“œ í•„ìš”")?;
            let threshold = config["threshold"].as_f64().ok_or("threshold í•„ë“œ í•„ìš”")?;

            // condition íŒŒì‹± (ì˜ˆ: "temperature > 90")
            let parts: Vec<&str> = condition.split_whitespace().collect();
            if parts.len() < 3 {
                return Err("condition í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: temperature > 90)".to_string());
            }

            let field_name = parts[0];
            let operator = parts[1];
            let field_value = input_data[field_name].as_f64().unwrap_or(0.0);

            let triggered = match operator {
                ">" => field_value > threshold,
                ">=" => field_value >= threshold,
                "<" => field_value < threshold,
                "<=" => field_value <= threshold,
                "==" => (field_value - threshold).abs() < 0.0001,
                _ => return Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—°ì‚°ì: {}", operator)),
            };

            Ok((
                json!({
                    "step_type": "TRIGGER",
                    "trigger_type": "threshold",
                    "triggered": triggered,
                    "condition": condition,
                    "threshold": threshold,
                    "actual_value": field_value,
                    "message": if triggered {
                        format!("{} {} {} ì¡°ê±´ ì¶©ì¡±", field_name, operator, threshold)
                    } else {
                        format!("{} {} {} ì¡°ê±´ ë¯¸ì¶©ì¡± (í˜„ì¬: {})", field_name, operator, threshold, field_value)
                    }
                }),
                input_data.clone(),
            ))
        }
        "scheduled" => {
            // ìŠ¤ì¼€ì¤„ íŠ¸ë¦¬ê±° (ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” í•­ìƒ true)
            let schedule = config["schedule"].as_str().unwrap_or("* * * * *");
            Ok((
                json!({
                    "step_type": "TRIGGER",
                    "trigger_type": "scheduled",
                    "triggered": true,
                    "schedule": schedule,
                    "message": format!("ìŠ¤ì¼€ì¤„ íŠ¸ë¦¬ê±° ì‹¤í–‰ ({})", schedule)
                }),
                input_data.clone(),
            ))
        }
        "event" => {
            // ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° (ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” í•­ìƒ true)
            Ok((
                json!({
                    "step_type": "TRIGGER",
                    "trigger_type": "event",
                    "triggered": true,
                    "message": "ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° ê°ì§€"
                }),
                input_data.clone(),
            ))
        }
        "manual" => {
            // ìˆ˜ë™ íŠ¸ë¦¬ê±° (ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” í•­ìƒ true)
            Ok((
                json!({
                    "step_type": "TRIGGER",
                    "trigger_type": "manual",
                    "triggered": true,
                    "message": "ìˆ˜ë™ íŠ¸ë¦¬ê±° ì‹¤í–‰"
                }),
                input_data.clone(),
            ))
        }
        _ => Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŠ¸ë¦¬ê±° íƒ€ì…: {}", trigger_type)),
    }
}

/// QUERY ìŠ¤í… ì‹¤í–‰
async fn execute_query_step(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    let config = &step.config;
    let data_source = config["dataSource"].as_str().unwrap_or("database");
    let query = config["query"].as_str().unwrap_or("");

    match data_source {
        "database" => {
            // ì‹¤ì œ SQLite ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
            let query_type = config["queryType"].as_str().unwrap_or("sql");

            // DB ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            let app_data = std::env::var("APPDATA")
                .or_else(|_| std::env::var("HOME"))
                .map_err(|e| format!("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: {}", e))?;
            let db_path = std::path::PathBuf::from(app_data).join("Judgify").join("judgify.db");

            // DB ì—°ê²°
            let conn = Connection::open(&db_path)
                .map_err(|e| format!("DB ì—°ê²° ì‹¤íŒ¨: {}", e))?;

            // ì¿¼ë¦¬ ì‹¤í–‰
            let query_result = if query.is_empty() {
                // ê¸°ë³¸ ì¿¼ë¦¬: ìµœê·¼ judgments ì¡°íšŒ
                execute_default_query(&conn)?
            } else {
                // ì‚¬ìš©ì ì§€ì • ì¿¼ë¦¬ ì‹¤í–‰ (SELECTë§Œ í—ˆìš©)
                execute_custom_query(&conn, query)?
            };

            let row_count = query_result.as_array().map(|a| a.len()).unwrap_or(0);

            let mut output_data = input_data.clone();
            if let Some(obj) = output_data.as_object_mut() {
                obj.insert("query_result".to_string(), query_result.clone());
            }

            Ok((
                json!({
                    "step_type": "QUERY",
                    "data_source": "database",
                    "query_type": query_type,
                    "query": if query.is_empty() { "SELECT * FROM judgments LIMIT 10" } else { query },
                    "data": query_result,
                    "message": format!("ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì™„ë£Œ ({}ê°œ ê²°ê³¼)", row_count)
                }),
                output_data,
            ))
        }
        "api" => {
            // ì™¸ë¶€ API í˜¸ì¶œ (Mock ì‘ë‹µ)
            let mock_response = json!({
                "status": "success",
                "data": {
                    "sensor_id": "SENS-001",
                    "readings": [85.2, 86.1, 87.5]
                }
            });

            let mut output_data = input_data.clone();
            if let Some(obj) = output_data.as_object_mut() {
                obj.insert("api_response".to_string(), mock_response.clone());
            }

            Ok((
                json!({
                    "step_type": "QUERY",
                    "data_source": "api",
                    "endpoint": query,
                    "response": mock_response,
                    "message": "API í˜¸ì¶œ ì„±ê³µ"
                }),
                output_data,
            ))
        }
        "sensor" => {
            // ì„¼ì„œ ë°ì´í„° ì¡°íšŒ (Mock)
            let mock_sensor_data = json!({
                "timestamp": "2025-11-20T10:30:00Z",
                "temperature": 88.5,
                "vibration": 42.3,
                "pressure": 120.5
            });

            let mut output_data = input_data.clone();
            if let Some(obj) = output_data.as_object_mut() {
                obj.insert("sensor_data".to_string(), mock_sensor_data.clone());
            }

            Ok((
                json!({
                    "step_type": "QUERY",
                    "data_source": "sensor",
                    "sensor_data": mock_sensor_data,
                    "message": "ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ"
                }),
                output_data,
            ))
        }
        "file" => {
            // íŒŒì¼ ì‹œìŠ¤í…œ ì¡°íšŒ (Mock)
            let mock_file_data = json!({
                "filename": "production_data.csv",
                "rows": 150,
                "sample": [
                    {"date": "2025-11-19", "output": 1250, "defects": 15},
                    {"date": "2025-11-20", "output": 1180, "defects": 22}
                ]
            });

            let mut output_data = input_data.clone();
            if let Some(obj) = output_data.as_object_mut() {
                obj.insert("file_data".to_string(), mock_file_data.clone());
            }

            Ok((
                json!({
                    "step_type": "QUERY",
                    "data_source": "file",
                    "file_data": mock_file_data,
                    "message": "íŒŒì¼ ì¡°íšŒ ì™„ë£Œ"
                }),
                output_data,
            ))
        }
        _ => Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤: {}", data_source)),
    }
}

/// CALC ìŠ¤í… ì‹¤í–‰
async fn execute_calc_step(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    let config = &step.config;
    let calc_type = config["calcType"].as_str().unwrap_or("formula");
    let output_field = config["outputField"].as_str().unwrap_or("result");

    match calc_type {
        "formula" => {
            // ìˆ˜ì‹ ê³„ì‚°
            let formula = config["formula"].as_str().ok_or("formula í•„ë“œ í•„ìš”")?;

            // ê°„ë‹¨í•œ ìˆ˜ì‹ í‰ê°€ (ì˜ˆ: "(defect_count / total_count) * 100")
            // input_dataì˜ ë³€ìˆ˜ë¥¼ ì¹˜í™˜
            let mut eval_formula = formula.to_string();

            if let Some(obj) = input_data.as_object() {
                for (key, value) in obj {
                    if let Some(num) = value.as_f64() {
                        eval_formula = eval_formula.replace(key, &num.to_string());
                    }
                }
            }

            // ê°„ë‹¨í•œ ìˆ˜ì‹ í‰ê°€ (evalexpr í¬ë ˆì´íŠ¸ ì‚¬ìš© ê¶Œì¥, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨ êµ¬í˜„)
            let result = evaluate_simple_formula(&eval_formula)
                .map_err(|e| format!("ìˆ˜ì‹ í‰ê°€ ì‹¤íŒ¨: {}", e))?;

            let mut output_data = input_data.clone();
            if let Some(obj) = output_data.as_object_mut() {
                obj.insert(output_field.to_string(), json!(result));
            }

            Ok((
                json!({
                    "step_type": "CALC",
                    "calc_type": "formula",
                    "formula": formula,
                    "result": result,
                    "output_field": output_field,
                    "message": format!("ìˆ˜ì‹ ê³„ì‚° ì™„ë£Œ: {} = {}", output_field, result)
                }),
                output_data,
            ))
        }
        "aggregate" => {
            // ì§‘ê³„ í•¨ìˆ˜ (avg, sum, min, max, count)
            let agg_func = config["aggregateFunction"].as_str().unwrap_or("avg");
            let target_field = config["targetField"].as_str().ok_or("targetField í•„ë“œ í•„ìš”")?;

            // input_dataì—ì„œ ë°°ì—´ ë°ì´í„° ì¶”ì¶œ
            let values: Vec<f64> = if let Some(arr) = input_data[target_field].as_array() {
                arr.iter()
                    .filter_map(|v| v.as_f64())
                    .collect()
            } else if let Some(num) = input_data[target_field].as_f64() {
                vec![num]
            } else {
                return Err(format!("{} í•„ë“œê°€ ìˆ«ì ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤", target_field));
            };

            if values.is_empty() {
                return Err("ì§‘ê³„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤".to_string());
            }

            let result = match agg_func {
                "sum" => values.iter().sum(),
                "avg" => values.iter().sum::<f64>() / values.len() as f64,
                "min" => values.iter().cloned().fold(f64::INFINITY, f64::min),
                "max" => values.iter().cloned().fold(f64::NEG_INFINITY, f64::max),
                "count" => values.len() as f64,
                _ => return Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§‘ê³„ í•¨ìˆ˜: {}", agg_func)),
            };

            let mut output_data = input_data.clone();
            if let Some(obj) = output_data.as_object_mut() {
                obj.insert(output_field.to_string(), json!(result));
            }

            Ok((
                json!({
                    "step_type": "CALC",
                    "calc_type": "aggregate",
                    "aggregate_function": agg_func,
                    "target_field": target_field,
                    "result": result,
                    "output_field": output_field,
                    "message": format!("ì§‘ê³„ ì™„ë£Œ: {}({}) = {}", agg_func, target_field, result)
                }),
                output_data,
            ))
        }
        "transform" => {
            // ë°ì´í„° ë³€í™˜ (ê°„ë‹¨ êµ¬í˜„)
            Ok((
                json!({
                    "step_type": "CALC",
                    "calc_type": "transform",
                    "message": "ë°ì´í„° ë³€í™˜ ì™„ë£Œ (Mock)"
                }),
                input_data.clone(),
            ))
        }
        _ => Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” ê³„ì‚° íƒ€ì…: {}", calc_type)),
    }
}

/// ê°„ë‹¨í•œ ìˆ˜ì‹ í‰ê°€ í•¨ìˆ˜ (ì‚¬ì¹™ì—°ì‚°ë§Œ ì§€ì›)
fn evaluate_simple_formula(formula: &str) -> Result<f64, String> {
    // ê³µë°± ì œê±°
    let formula = formula.replace(" ", "");

    // ê°„ë‹¨í•œ íŒŒì„œ (ê´„í˜¸, ì‚¬ì¹™ì—°ì‚°)
    // ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” evalexpr í¬ë ˆì´íŠ¸ ì‚¬ìš© ê¶Œì¥
    meval::eval_str(&formula).map_err(|e| format!("ìˆ˜ì‹ í‰ê°€ ì˜¤ë¥˜: {}", e))
}

/// JUDGMENT ìŠ¤í… ì‹¤í–‰ (Phase 4: í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ í†µí•©)
async fn execute_judgment_step(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    let config = &step.config;
    let judgment_method = config["judgmentMethod"].as_str().unwrap_or("rule");

    match judgment_method {
        "rule" => {
            // Rule Engineë§Œ ì‚¬ìš©
            let rule_expr = config["ruleExpression"]
                .as_str()
                .ok_or("Rule í‘œí˜„ì‹ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")?;

            let engine = RuleEngine::new();
            let result = engine
                .evaluate(rule_expr, input_data)
                .map_err(|e| format!("Rule í‰ê°€ ì‹¤íŒ¨: {}", e))?;

            Ok((
                json!({
                    "step_type": "JUDGMENT",
                    "judgment": result,
                    "method": "rule",
                    "confidence": 1.0,
                    "explanation": "Rule Engine ê¸°ë°˜ íŒë‹¨"
                }),
                input_data.clone(),
            ))
        }
        "llm" | "hybrid" => {
            // JudgmentEngine ì„œë¹„ìŠ¤ ì‚¬ìš© (LLM + Few-shot í•™ìŠµ)
            let workflow_id = format!("workflow-{}", step.id);

            let judgment_input = JudgmentInput {
                workflow_id: workflow_id.clone(),
                input_data: input_data.clone(),
            };

            let engine = JudgmentEngine::new()
                .map_err(|e| format!("JudgmentEngine ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e))?;

            let result = engine
                .judge_with_few_shot(judgment_input)
                .await
                .map_err(|e| format!("í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ì‹¤íŒ¨: {}", e))?;

            Ok((
                json!({
                    "step_type": "JUDGMENT",
                    "judgment": result.result,
                    "method": result.method_used,
                    "confidence": result.confidence,
                    "explanation": result.explanation
                }),
                input_data.clone(),
            ))
        }
        _ => Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒë‹¨ ë°©ì‹: {}", judgment_method))
    }
}

/// APPROVAL ìŠ¤í… ì‹¤í–‰
///
/// ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ vs ì‹¤ì œ ëª¨ë“œ:
/// - ì‹œë®¬ë ˆì´ì…˜: í•­ìƒ ì¦‰ì‹œ ìŠ¹ì¸ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
/// - ì‹¤ì œ: DBì— ìŠ¹ì¸ ìš”ì²­ ì €ì¥ í›„ ëŒ€ê¸° ìƒíƒœ ë°˜í™˜
async fn execute_approval_step(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    let config = &step.config;
    let approval_type = config["approvalType"].as_str().unwrap_or("manual");

    // ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì²´í¬ (ê¸°ë³¸ê°’: true = ì‹œë®¬ë ˆì´ì…˜)
    let is_simulation = config["isSimulation"].as_bool().unwrap_or(true);

    // ì›Œí¬í”Œë¡œìš° ì •ë³´ (ì‹¤ì œ ìŠ¹ì¸ ìš”ì²­ ìƒì„±ì‹œ ì‚¬ìš©)
    let workflow_id = config["workflowId"].as_str().unwrap_or("unknown");
    let workflow_name = config["workflowName"].as_str().unwrap_or("Unknown Workflow");

    match approval_type {
        "auto" => {
            // ìë™ ìŠ¹ì¸ - í•­ìƒ ì¦‰ì‹œ í†µê³¼
            Ok((
                json!({
                    "step_type": "APPROVAL",
                    "approval_type": "auto",
                    "approved": true,
                    "message": "ìë™ ìŠ¹ì¸ ì™„ë£Œ"
                }),
                input_data.clone(),
            ))
        }
        "conditional" => {
            // ì¡°ê±´ë¶€ ìŠ¹ì¸
            let auto_approve_condition = config["autoApproveCondition"].as_str();

            if let Some(condition) = auto_approve_condition {
                // ê°„ë‹¨í•œ ì¡°ê±´ í‰ê°€ (ì˜ˆ: "amount < 100000")
                let parts: Vec<&str> = condition.split_whitespace().collect();
                if parts.len() >= 3 {
                    let field_name = parts[0];
                    let operator = parts[1];
                    let threshold = parts[2].parse::<f64>().unwrap_or(0.0);

                    let field_value = input_data[field_name].as_f64().unwrap_or(0.0);

                    let auto_approved = match operator {
                        ">" => field_value > threshold,
                        ">=" => field_value >= threshold,
                        "<" => field_value < threshold,
                        "<=" => field_value <= threshold,
                        "==" | "=" => (field_value - threshold).abs() < 0.0001,
                        "!=" => (field_value - threshold).abs() >= 0.0001,
                        _ => false,
                    };

                    if auto_approved {
                        // ì¡°ê±´ ì¶©ì¡± â†’ ìë™ ìŠ¹ì¸
                        Ok((
                            json!({
                                "step_type": "APPROVAL",
                                "approval_type": "conditional",
                                "approved": true,
                                "auto_approved": true,
                                "condition": condition,
                                "message": format!("ì¡°ê±´ ì¶©ì¡±ìœ¼ë¡œ ìë™ ìŠ¹ì¸: {}", condition)
                            }),
                            input_data.clone(),
                        ))
                    } else if is_simulation {
                        // ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: ì¡°ê±´ ë¯¸ì¶©ì¡±ì´ì–´ë„ ìë™ ìŠ¹ì¸
                        let approvers = config["approvers"]
                            .as_str()
                            .unwrap_or("admin@example.com")
                            .to_string();

                        Ok((
                            json!({
                                "step_type": "APPROVAL",
                                "approval_type": "conditional",
                                "approved": true,
                                "auto_approved": false,
                                "approvers": approvers,
                                "condition": condition,
                                "is_simulation": true,
                                "message": format!("ì¡°ê±´ ë¯¸ì¶©ì¡± â†’ ìˆ˜ë™ ìŠ¹ì¸ ì²˜ë¦¬ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ): {}", condition)
                            }),
                            input_data.clone(),
                        ))
                    } else {
                        // ì‹¤ì œ ëª¨ë“œ: DBì— ìŠ¹ì¸ ìš”ì²­ ìƒì„±
                        let approval_request = create_approval_request(
                            workflow_id,
                            workflow_name,
                            step,
                            input_data,
                            "conditional",
                            Some(condition),
                        )?;

                        Ok((
                            json!({
                                "step_type": "APPROVAL",
                                "approval_type": "conditional",
                                "approved": false,
                                "pending": true,
                                "request_id": approval_request.id,
                                "approvers": approval_request.approvers,
                                "condition": condition,
                                "timeout_minutes": approval_request.timeout_minutes,
                                "expires_at": approval_request.expires_at,
                                "message": format!("ì¡°ê±´ ë¯¸ì¶©ì¡± â†’ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ (ID: {})", approval_request.id)
                            }),
                            input_data.clone(),
                        ))
                    }
                } else {
                    Err("ì¡°ê±´ í˜•ì‹ ì˜¤ë¥˜ (ì˜ˆ: amount < 100000)".to_string())
                }
            } else {
                Err("autoApproveCondition í•„ë“œ í•„ìš”".to_string())
            }
        }
        "manual" => {
            // ìˆ˜ë™ ìŠ¹ì¸
            let approvers = config["approvers"]
                .as_str()
                .unwrap_or("admin@example.com")
                .to_string();
            let timeout_minutes = config["timeoutMinutes"].as_u64().unwrap_or(60);

            if is_simulation {
                // ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: í•­ìƒ ì¦‰ì‹œ ìŠ¹ì¸
                Ok((
                    json!({
                        "step_type": "APPROVAL",
                        "approval_type": "manual",
                        "approved": true,
                        "approvers": approvers,
                        "timeout_minutes": timeout_minutes,
                        "is_simulation": true,
                        "message": format!("ìˆ˜ë™ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ (ì‹œë®¬ë ˆì´ì…˜: ìë™ ìŠ¹ì¸) - ìŠ¹ì¸ì: {}", approvers)
                    }),
                    input_data.clone(),
                ))
            } else {
                // ì‹¤ì œ ëª¨ë“œ: DBì— ìŠ¹ì¸ ìš”ì²­ ìƒì„±
                let approval_request = create_approval_request(
                    workflow_id,
                    workflow_name,
                    step,
                    input_data,
                    "manual",
                    None,
                )?;

                Ok((
                    json!({
                        "step_type": "APPROVAL",
                        "approval_type": "manual",
                        "approved": false,
                        "pending": true,
                        "request_id": approval_request.id,
                        "approvers": approval_request.approvers,
                        "timeout_minutes": approval_request.timeout_minutes,
                        "expires_at": approval_request.expires_at,
                        "message": format!("ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ (ID: {}) - ìŠ¹ì¸ì: {}", approval_request.id, approval_request.approvers)
                    }),
                    input_data.clone(),
                ))
            }
        }
        _ => Err(format!("ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¹ì¸ íƒ€ì…: {}", approval_type)),
    }
}

/// ALERT ìŠ¤í… ì‹¤í–‰
async fn execute_alert_step(
    step: &WorkflowStep,
    input_data: &serde_json::Value,
) -> Result<(serde_json::Value, serde_json::Value), String> {
    let config = &step.config;
    let channels = config["channels"].as_array().map(|arr| {
        arr.iter()
            .filter_map(|v| v.as_str())
            .map(|s| s.to_string())
            .collect::<Vec<String>>()
    }).unwrap_or_else(|| vec!["email".to_string()]);

    let recipients = config["recipients"].as_str().unwrap_or("admin@example.com");
    let subject = config["subject"].as_str().unwrap_or("ì•Œë¦¼");
    let message_template = config["messageTemplate"].as_str().unwrap_or("ì›Œí¬í”Œë¡œìš° ì•Œë¦¼");
    let priority = config["priority"].as_str().unwrap_or("medium");
    let include_data = config["includeData"].as_bool().unwrap_or(false);

    // ë©”ì‹œì§€ í…œí”Œë¦¿ì— ë³€ìˆ˜ ì¹˜í™˜ (ì˜ˆ: {equipment_id} â†’ EQ-001)
    let mut message = message_template.to_string();
    if let Some(obj) = input_data.as_object() {
        for (key, value) in obj {
            let placeholder = format!("{{{}}}", key);
            if message.contains(&placeholder) {
                let replacement = match value {
                    serde_json::Value::String(s) => s.clone(),
                    serde_json::Value::Number(n) => n.to_string(),
                    serde_json::Value::Bool(b) => b.to_string(),
                    _ => format!("{}", value),
                };
                message = message.replace(&placeholder, &replacement);
            }
        }
    }

    // ì‹¤ì œ ë°œì†¡ ë¡œì§ (Slack Webhook, Email SMTP Proxy, Notion API)
    eprintln!("ğŸ“§ ALERT ë°œì†¡:");
    eprintln!("  ì±„ë„: {}", channels.join(", "));
    eprintln!("  ìˆ˜ì‹ ì: {}", recipients);
    eprintln!("  ìš°ì„ ìˆœìœ„: {}", priority);
    eprintln!("  ì œëª©: {}", subject);
    eprintln!("  ë©”ì‹œì§€: {}", message);

    if include_data {
        eprintln!("  ì›Œí¬í”Œë¡œìš° ë°ì´í„°: {}", serde_json::to_string_pretty(input_data).unwrap_or_default());
    }

    let mut sent_channels = Vec::new();
    let http_client = reqwest::Client::new();

    for channel in &channels {
        match channel.as_str() {
            "email" => {
                // ì´ë©”ì¼: í™˜ê²½ë³€ìˆ˜ì—ì„œ SMTP í”„ë¡ì‹œ URL í™•ì¸
                let result = match std::env::var("JUDGIFY_EMAIL_WEBHOOK") {
                    Ok(webhook_url) => {
                        send_email_webhook(&http_client, &webhook_url, recipients, subject, &message).await
                    }
                    Err(_) => {
                        eprintln!("  âš ï¸ JUDGIFY_EMAIL_WEBHOOK ë¯¸ì„¤ì • - Mock ëª¨ë“œ");
                        Ok("mock".to_string())
                    }
                };
                match result {
                    Ok(status) => {
                        eprintln!("  âœ… ì´ë©”ì¼ ë°œì†¡: {} â†’ {} ({})", subject, recipients, status);
                        sent_channels.push(json!({"channel": "email", "status": "sent", "recipient": recipients}));
                    }
                    Err(e) => {
                        eprintln!("  âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {}", e);
                        sent_channels.push(json!({"channel": "email", "status": "failed", "error": e}));
                    }
                }
            }
            "slack" => {
                // Slack: í™˜ê²½ë³€ìˆ˜ì—ì„œ Webhook URL í™•ì¸
                let result = match std::env::var("JUDGIFY_SLACK_WEBHOOK") {
                    Ok(webhook_url) => {
                        send_slack_webhook(&http_client, &webhook_url, subject, &message, priority).await
                    }
                    Err(_) => {
                        eprintln!("  âš ï¸ JUDGIFY_SLACK_WEBHOOK ë¯¸ì„¤ì • - Mock ëª¨ë“œ");
                        Ok("mock".to_string())
                    }
                };
                match result {
                    Ok(status) => {
                        eprintln!("  âœ… Slack ë°œì†¡: {} ({})", message, status);
                        sent_channels.push(json!({"channel": "slack", "status": "sent", "recipient": recipients}));
                    }
                    Err(e) => {
                        eprintln!("  âŒ Slack ë°œì†¡ ì‹¤íŒ¨: {}", e);
                        sent_channels.push(json!({"channel": "slack", "status": "failed", "error": e}));
                    }
                }
            }
            "notion" => {
                // Notion: í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë° Database ID í™•ì¸
                let result = match (std::env::var("NOTION_API_KEY"), std::env::var("NOTION_DATABASE_ID")) {
                    (Ok(api_key), Ok(db_id)) => {
                        send_notion_page(&http_client, &api_key, &db_id, subject, &message, priority).await
                    }
                    _ => {
                        eprintln!("  âš ï¸ NOTION_API_KEY/NOTION_DATABASE_ID ë¯¸ì„¤ì • - Mock ëª¨ë“œ");
                        Ok("mock".to_string())
                    }
                };
                match result {
                    Ok(status) => {
                        eprintln!("  âœ… Notion ë°œì†¡: {} ({})", message, status);
                        sent_channels.push(json!({"channel": "notion", "status": "sent", "recipient": recipients}));
                    }
                    Err(e) => {
                        eprintln!("  âŒ Notion ë°œì†¡ ì‹¤íŒ¨: {}", e);
                        sent_channels.push(json!({"channel": "notion", "status": "failed", "error": e}));
                    }
                }
            }
            _ => {
                eprintln!("  âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ì±„ë„: {}", channel);
            }
        }
    }

    Ok((
        json!({
            "step_type": "ALERT",
            "channels": channels,
            "recipients": recipients,
            "subject": subject,
            "message": message,
            "priority": priority,
            "sent_channels": sent_channels,
            "sent": true,
            "summary": format!("ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ ({}ê°œ ì±„ë„)", channels.len())
        }),
        input_data.clone(),
    ))
}

// ================== DB ì €ì¥ í—¬í¼ í•¨ìˆ˜ ==================

/// DB ì—°ê²° ê°€ì ¸ì˜¤ê¸°
fn get_db_connection() -> Result<Connection, String> {
    let app_data_dir = dirs::data_dir()
        .ok_or("AppData ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")?
        .join("Judgify");

    let db_path = app_data_dir.join("judgify.db");

    Connection::open(&db_path)
        .map_err(|e| format!("DB ì—°ê²° ì‹¤íŒ¨: {}", e))
}

/// ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ë¥¼ DBì— ì €ì¥
fn save_workflow_execution(
    conn: &Connection,
    workflow_id: &str,
    status: &str,
    steps_executed: &[StepExecutionResult],
    final_result: &serde_json::Value,
    execution_time_ms: u64,
) -> Result<String, String> {
    // JSON ì§ë ¬í™”
    let steps_json = serde_json::to_string(steps_executed)
        .map_err(|e| format!("steps_executed ì§ë ¬í™” ì‹¤íŒ¨: {}", e))?;

    let final_result_json = serde_json::to_string(final_result)
        .map_err(|e| format!("final_result ì§ë ¬í™” ì‹¤íŒ¨: {}", e))?;

    // INSERT ì‹¤í–‰
    conn.execute(
        r#"
        INSERT INTO workflow_executions (workflow_id, status, steps_executed, final_result, execution_time_ms)
        VALUES (?1, ?2, ?3, ?4, ?5)
        "#,
        params![workflow_id, status, steps_json, final_result_json, execution_time_ms as i64],
    )
    .map_err(|e| format!("DB ì €ì¥ ì‹¤íŒ¨: {}", e))?;

    // ìƒì„±ëœ ID ê°€ì ¸ì˜¤ê¸°
    let execution_id = conn.last_insert_rowid().to_string();

    println!("ğŸ’¾ [WorkflowV2] ì‹¤í–‰ ì´ë ¥ ì €ì¥ ì™„ë£Œ: {}", execution_id);

    Ok(execution_id)
}

// ================== ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ API ==================

/// íŠ¹ì • workflowì˜ ì‹¤í–‰ ì´ë ¥ ëª©ë¡ ì¡°íšŒ
#[tauri::command]
pub async fn get_workflow_executions(
    workflow_id: String,
    limit: Option<i64>,
) -> Result<Vec<WorkflowExecutionListItem>, String> {
    let conn = get_db_connection()?;

    let limit_value = limit.unwrap_or(50);

    let mut stmt = conn
        .prepare(
            r#"
            SELECT id, workflow_id, status, execution_time_ms, created_at
            FROM workflow_executions
            WHERE workflow_id = ?1
            ORDER BY created_at DESC
            LIMIT ?2
            "#,
        )
        .map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;

    let executions = stmt
        .query_map(params![workflow_id, limit_value], |row| {
            let id: i64 = row.get(0)?;
            Ok(WorkflowExecutionListItem {
                id: id.to_string(),
                workflow_id: row.get(1)?,
                status: row.get(2)?,
                execution_time_ms: row.get(3)?,
                created_at: row.get(4)?,
            })
        })
        .map_err(|e| format!("ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?
        .collect::<Result<Vec<_>, _>>()
        .map_err(|e| format!("ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {}", e))?;

    println!("ğŸ“‹ [WorkflowV2] ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ: {} ({}ê±´)", workflow_id, executions.len());

    Ok(executions)
}

/// íŠ¹ì • ì‹¤í–‰ ì´ë ¥ ìƒì„¸ ì¡°íšŒ
#[tauri::command]
pub async fn get_workflow_execution_detail(
    execution_id: String,
) -> Result<WorkflowExecutionDetail, String> {
    let conn = get_db_connection()?;

    let mut stmt = conn
        .prepare(
            r#"
            SELECT id, workflow_id, status, steps_executed, final_result, execution_time_ms, created_at
            FROM workflow_executions
            WHERE id = ?1
            "#,
        )
        .map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;

    let result = stmt
        .query_row(params![execution_id], |row| {
            let steps_json: String = row.get(3)?;
            let final_result_json: String = row.get(4)?;

            let steps_executed: Vec<StepExecutionResult> = serde_json::from_str(&steps_json)
                .map_err(|e| rusqlite::Error::InvalidQuery)?;

            let final_result: serde_json::Value = serde_json::from_str(&final_result_json)
                .map_err(|e| rusqlite::Error::InvalidQuery)?;

            let id: i64 = row.get(0)?;
            Ok(WorkflowExecutionDetail {
                id: id.to_string(),
                workflow_id: row.get(1)?,
                status: row.get(2)?,
                steps_executed,
                final_result,
                execution_time_ms: row.get(5)?,
                created_at: row.get(6)?,
            })
        })
        .map_err(|e| match e {
            rusqlite::Error::QueryReturnedNoRows => "ì‹¤í–‰ ì´ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤".to_string(),
            _ => format!("ì¡°íšŒ ì‹¤íŒ¨: {}", e),
        })?;

    println!("ğŸ” [WorkflowV2] ì‹¤í–‰ ì´ë ¥ ìƒì„¸ ì¡°íšŒ: {}", execution_id);

    Ok(result)
}

// ================== QUERY ë…¸ë“œ í—¬í¼ í•¨ìˆ˜ ==================

/// ê¸°ë³¸ ì¿¼ë¦¬ ì‹¤í–‰ (judgments í…Œì´ë¸” ì¡°íšŒ)
fn execute_default_query(conn: &Connection) -> Result<serde_json::Value, String> {
    let mut stmt = conn
        .prepare("SELECT id, workflow_id, input_data, result, confidence, method_used, explanation, created_at FROM judgments ORDER BY created_at DESC LIMIT 10")
        .map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;

    let rows = stmt
        .query_map([], |row| {
            Ok(json!({
                "id": row.get::<_, String>(0)?,
                "workflow_id": row.get::<_, String>(1)?,
                "input_data": row.get::<_, String>(2)?,
                "result": row.get::<_, i32>(3)?,
                "confidence": row.get::<_, f64>(4)?,
                "method_used": row.get::<_, String>(5)?,
                "explanation": row.get::<_, Option<String>>(6)?,
                "created_at": row.get::<_, String>(7)?
            }))
        })
        .map_err(|e| format!("ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?;

    let results: Vec<serde_json::Value> = rows
        .filter_map(|r| r.ok())
        .collect();

    Ok(json!(results))
}

/// ì‚¬ìš©ì ì§€ì • ì¿¼ë¦¬ ì‹¤í–‰ (SELECTë§Œ í—ˆìš©)
fn execute_custom_query(conn: &Connection, query: &str) -> Result<serde_json::Value, String> {
    // ë³´ì•ˆ: SELECT ë¬¸ë§Œ í—ˆìš©
    let query_upper = query.trim().to_uppercase();
    if !query_upper.starts_with("SELECT") {
        return Err("ë³´ì•ˆìƒ SELECT ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤".to_string());
    }

    // ìœ„í—˜í•œ í‚¤ì›Œë“œ ì°¨ë‹¨
    let dangerous_keywords = ["DROP", "DELETE", "UPDATE", "INSERT", "ALTER", "CREATE", "TRUNCATE"];
    for keyword in dangerous_keywords {
        if query_upper.contains(keyword) {
            return Err(format!("ë³´ì•ˆìƒ {} í‚¤ì›Œë“œëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤", keyword));
        }
    }

    let mut stmt = conn
        .prepare(query)
        .map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;

    // ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    let column_count = stmt.column_count();
    let column_names: Vec<String> = (0..column_count)
        .map(|i| stmt.column_name(i).unwrap_or("unknown").to_string())
        .collect();

    let rows = stmt
        .query_map([], |row| {
            let mut obj = serde_json::Map::new();
            for (i, col_name) in column_names.iter().enumerate() {
                // íƒ€ì… ì¶”ë¡ í•˜ì—¬ ì ì ˆí•œ JSON ê°’ìœ¼ë¡œ ë³€í™˜
                let value: serde_json::Value = match row.get_ref(i) {
                    Ok(rusqlite::types::ValueRef::Null) => serde_json::Value::Null,
                    Ok(rusqlite::types::ValueRef::Integer(i)) => json!(i),
                    Ok(rusqlite::types::ValueRef::Real(f)) => json!(f),
                    Ok(rusqlite::types::ValueRef::Text(t)) => {
                        json!(String::from_utf8_lossy(t).to_string())
                    }
                    Ok(rusqlite::types::ValueRef::Blob(b)) => {
                        json!(format!("[BLOB: {} bytes]", b.len()))
                    }
                    Err(_) => serde_json::Value::Null,
                };
                obj.insert(col_name.clone(), value);
            }
            Ok(serde_json::Value::Object(obj))
        })
        .map_err(|e| format!("ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?;

    let results: Vec<serde_json::Value> = rows
        .filter_map(|r| r.ok())
        .collect();

    Ok(json!(results))
}

// ================== ALERT ë…¸ë“œ ë°œì†¡ í—¬í¼ í•¨ìˆ˜ ==================

/// Slack Webhookìœ¼ë¡œ ë©”ì‹œì§€ ë°œì†¡
async fn send_slack_webhook(
    client: &reqwest::Client,
    webhook_url: &str,
    title: &str,
    message: &str,
    priority: &str,
) -> Result<String, String> {
    let emoji = match priority {
        "high" => "ğŸš¨",
        "medium" => "âš ï¸",
        "low" => "â„¹ï¸",
        _ => "ğŸ“Œ",
    };

    let payload = json!({
        "blocks": [
            {
                "type": "header",
                "text": {"type": "plain_text", "text": format!("{} {}", emoji, title)}
            },
            {
                "type": "section",
                "text": {"type": "mrkdwn", "text": message}
            },
            {
                "type": "context",
                "elements": [
                    {"type": "mrkdwn", "text": format!("*Priority:* {} | *From:* Judgify Workflow", priority)}
                ]
            }
        ]
    });

    let response = client
        .post(webhook_url)
        .json(&payload)
        .send()
        .await
        .map_err(|e| format!("Slack ìš”ì²­ ì‹¤íŒ¨: {}", e))?;

    if response.status().is_success() {
        Ok("sent".to_string())
    } else {
        Err(format!("Slack ì‘ë‹µ ì˜¤ë¥˜: {}", response.status()))
    }
}

/// ì´ë©”ì¼ Webhook (SendGrid, Mailgun ë“± í˜¸í™˜)
async fn send_email_webhook(
    client: &reqwest::Client,
    webhook_url: &str,
    to: &str,
    subject: &str,
    body: &str,
) -> Result<String, String> {
    let payload = json!({
        "to": to,
        "subject": subject,
        "body": body,
        "from": "noreply@judgify.app"
    });

    let response = client
        .post(webhook_url)
        .json(&payload)
        .send()
        .await
        .map_err(|e| format!("Email ìš”ì²­ ì‹¤íŒ¨: {}", e))?;

    if response.status().is_success() {
        Ok("sent".to_string())
    } else {
        Err(format!("Email ì‘ë‹µ ì˜¤ë¥˜: {}", response.status()))
    }
}

/// Notion Databaseì— í˜ì´ì§€ ìƒì„±
async fn send_notion_page(
    client: &reqwest::Client,
    api_key: &str,
    database_id: &str,
    title: &str,
    content: &str,
    priority: &str,
) -> Result<String, String> {
    let payload = json!({
        "parent": {"database_id": database_id},
        "properties": {
            "Name": {"title": [{"text": {"content": title}}]},
            "Priority": {"select": {"name": priority}},
            "Status": {"select": {"name": "New"}}
        },
        "children": [
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": content}}]
                }
            }
        ]
    });

    let response = client
        .post("https://api.notion.com/v1/pages")
        .header("Authorization", format!("Bearer {}", api_key))
        .header("Notion-Version", "2022-06-28")
        .header("Content-Type", "application/json")
        .json(&payload)
        .send()
        .await
        .map_err(|e| format!("Notion ìš”ì²­ ì‹¤íŒ¨: {}", e))?;

    if response.status().is_success() {
        Ok("sent".to_string())
    } else {
        let error_text = response.text().await.unwrap_or_default();
        Err(format!("Notion ì‘ë‹µ ì˜¤ë¥˜: {}", error_text))
    }
}

// ============================================================
// APPROVAL ë…¸ë“œ ì‹¤ì œ ìŠ¹ì¸ í”Œë¡œìš° (Phase 9-3)
// ============================================================

/// ìŠ¹ì¸ ìš”ì²­ ìƒíƒœ
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ApprovalRequest {
    pub id: String,
    pub workflow_id: String,
    pub workflow_name: String,
    pub step_id: String,
    pub step_name: String,
    pub approval_type: String,
    pub status: String, // pending, approved, rejected, expired
    pub approvers: String,
    pub input_data: serde_json::Value,
    pub condition: Option<String>,
    pub timeout_minutes: i64,
    pub decided_by: Option<String>,
    pub decided_at: Option<String>,
    pub comment: Option<String>,
    pub created_at: String,
    pub expires_at: Option<String>,
}

/// ìŠ¹ì¸/ê±°ë¶€ ìš”ì²­
#[derive(Debug, Serialize, Deserialize)]
pub struct ApprovalDecision {
    pub request_id: String,
    pub decision: String, // "approved" or "rejected"
    pub decided_by: String,
    pub comment: Option<String>,
}

/// ìŠ¹ì¸ ìš”ì²­ ìƒì„± (ë‚´ë¶€ í—¬í¼)
fn create_approval_request(
    workflow_id: &str,
    workflow_name: &str,
    step: &WorkflowStep,
    input_data: &serde_json::Value,
    approval_type: &str,
    condition: Option<&str>,
) -> Result<ApprovalRequest, String> {
    let config = &step.config;
    let approvers = config["approvers"].as_str().unwrap_or("admin@example.com").to_string();
    let timeout_minutes = config["timeoutMinutes"].as_i64().unwrap_or(60);

    let request_id = format!("apr-{}", uuid::Uuid::new_v4().to_string().split('-').next().unwrap_or("000"));
    let now = chrono::Utc::now();
    let expires_at = now + chrono::Duration::minutes(timeout_minutes);

    // DBì— ìŠ¹ì¸ ìš”ì²­ ì €ì¥
    let app_data = std::env::var("APPDATA")
        .or_else(|_| std::env::var("HOME"))
        .map_err(|e| format!("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: {}", e))?;
    let db_path = std::path::PathBuf::from(app_data).join("Judgify").join("judgify.db");

    let conn = Connection::open(&db_path)
        .map_err(|e| format!("DB ì—°ê²° ì‹¤íŒ¨: {}", e))?;

    conn.execute(
        "INSERT INTO approval_requests (id, workflow_id, workflow_name, step_id, step_name, approval_type, status, approvers, input_data, condition, timeout_minutes, created_at, expires_at)
         VALUES (?1, ?2, ?3, ?4, ?5, ?6, 'pending', ?7, ?8, ?9, ?10, ?11, ?12)",
        params![
            &request_id,
            workflow_id,
            workflow_name,
            &step.id,
            &step.label,
            approval_type,
            &approvers,
            serde_json::to_string(input_data).unwrap_or_default(),
            condition,
            timeout_minutes,
            now.to_rfc3339(),
            expires_at.to_rfc3339(),
        ],
    ).map_err(|e| format!("ìŠ¹ì¸ ìš”ì²­ ì €ì¥ ì‹¤íŒ¨: {}", e))?;

    println!("ğŸ“‹ [APPROVAL] ìŠ¹ì¸ ìš”ì²­ ìƒì„±: {} (ë§Œë£Œ: {}ë¶„)", request_id, timeout_minutes);

    Ok(ApprovalRequest {
        id: request_id,
        workflow_id: workflow_id.to_string(),
        workflow_name: workflow_name.to_string(),
        step_id: step.id.clone(),
        step_name: step.label.clone(),
        approval_type: approval_type.to_string(),
        status: "pending".to_string(),
        approvers,
        input_data: input_data.clone(),
        condition: condition.map(|s| s.to_string()),
        timeout_minutes,
        decided_by: None,
        decided_at: None,
        comment: None,
        created_at: now.to_rfc3339(),
        expires_at: Some(expires_at.to_rfc3339()),
    })
}

/// ëŒ€ê¸° ì¤‘ì¸ ìŠ¹ì¸ ìš”ì²­ ëª©ë¡ ì¡°íšŒ
#[tauri::command]
pub async fn get_pending_approvals() -> Result<Vec<ApprovalRequest>, String> {
    println!("ğŸ“‹ [APPROVAL] ëŒ€ê¸° ì¤‘ì¸ ìŠ¹ì¸ ìš”ì²­ ì¡°íšŒ");

    let app_data = std::env::var("APPDATA")
        .or_else(|_| std::env::var("HOME"))
        .map_err(|e| format!("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: {}", e))?;
    let db_path = std::path::PathBuf::from(app_data).join("Judgify").join("judgify.db");

    let conn = Connection::open(&db_path)
        .map_err(|e| format!("DB ì—°ê²° ì‹¤íŒ¨: {}", e))?;

    // ë§Œë£Œëœ ìš”ì²­ ìë™ ì²˜ë¦¬
    let now = chrono::Utc::now().to_rfc3339();
    conn.execute(
        "UPDATE approval_requests SET status = 'expired' WHERE status = 'pending' AND expires_at < ?1",
        params![&now],
    ).map_err(|e| format!("ë§Œë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {}", e))?;

    // ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ì¡°íšŒ
    let mut stmt = conn.prepare(
        "SELECT id, workflow_id, workflow_name, step_id, step_name, approval_type, status, approvers, input_data, condition, timeout_minutes, decided_by, decided_at, comment, created_at, expires_at
         FROM approval_requests WHERE status = 'pending' ORDER BY created_at DESC"
    ).map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;

    let requests = stmt.query_map([], |row| {
        let input_data_str: String = row.get(8)?;
        let input_data: serde_json::Value = serde_json::from_str(&input_data_str).unwrap_or(json!({}));

        Ok(ApprovalRequest {
            id: row.get(0)?,
            workflow_id: row.get(1)?,
            workflow_name: row.get(2)?,
            step_id: row.get(3)?,
            step_name: row.get(4)?,
            approval_type: row.get(5)?,
            status: row.get(6)?,
            approvers: row.get(7)?,
            input_data,
            condition: row.get(9)?,
            timeout_minutes: row.get(10)?,
            decided_by: row.get(11)?,
            decided_at: row.get(12)?,
            comment: row.get(13)?,
            created_at: row.get(14)?,
            expires_at: row.get(15)?,
        })
    }).map_err(|e| format!("ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?;

    let result: Vec<ApprovalRequest> = requests.filter_map(|r| r.ok()).collect();
    println!("ğŸ“‹ [APPROVAL] ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­: {}ê±´", result.len());

    Ok(result)
}

/// ìŠ¹ì¸/ê±°ë¶€ ì²˜ë¦¬
#[tauri::command]
pub async fn process_approval(decision: ApprovalDecision) -> Result<serde_json::Value, String> {
    println!("ğŸ“‹ [APPROVAL] ìŠ¹ì¸ ì²˜ë¦¬: {} â†’ {}", decision.request_id, decision.decision);

    if decision.decision != "approved" && decision.decision != "rejected" {
        return Err("decisionì€ 'approved' ë˜ëŠ” 'rejected'ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤".to_string());
    }

    let app_data = std::env::var("APPDATA")
        .or_else(|_| std::env::var("HOME"))
        .map_err(|e| format!("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: {}", e))?;
    let db_path = std::path::PathBuf::from(app_data).join("Judgify").join("judgify.db");

    let conn = Connection::open(&db_path)
        .map_err(|e| format!("DB ì—°ê²° ì‹¤íŒ¨: {}", e))?;

    let now = chrono::Utc::now().to_rfc3339();

    let affected = conn.execute(
        "UPDATE approval_requests SET status = ?1, decided_by = ?2, decided_at = ?3, comment = ?4 WHERE id = ?5 AND status = 'pending'",
        params![&decision.decision, &decision.decided_by, &now, &decision.comment, &decision.request_id],
    ).map_err(|e| format!("ìŠ¹ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {}", e))?;

    if affected == 0 {
        return Err(format!("ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤: {}", decision.request_id));
    }

    println!("âœ… [APPROVAL] ìŠ¹ì¸ ì²˜ë¦¬ ì™„ë£Œ: {} by {}", decision.decision, decision.decided_by);

    Ok(json!({
        "request_id": decision.request_id,
        "decision": decision.decision,
        "decided_by": decision.decided_by,
        "decided_at": now,
        "message": format!("ìŠ¹ì¸ ìš”ì²­ì´ {}ë˜ì—ˆìŠµë‹ˆë‹¤", if decision.decision == "approved" { "ìŠ¹ì¸" } else { "ê±°ë¶€" })
    }))
}

/// ìŠ¹ì¸ ìš”ì²­ ìƒì„¸ ì¡°íšŒ
#[tauri::command]
pub async fn get_approval_request(request_id: String) -> Result<ApprovalRequest, String> {
    println!("ğŸ“‹ [APPROVAL] ìŠ¹ì¸ ìš”ì²­ ìƒì„¸ ì¡°íšŒ: {}", request_id);

    let app_data = std::env::var("APPDATA")
        .or_else(|_| std::env::var("HOME"))
        .map_err(|e| format!("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: {}", e))?;
    let db_path = std::path::PathBuf::from(app_data).join("Judgify").join("judgify.db");

    let conn = Connection::open(&db_path)
        .map_err(|e| format!("DB ì—°ê²° ì‹¤íŒ¨: {}", e))?;

    let mut stmt = conn.prepare(
        "SELECT id, workflow_id, workflow_name, step_id, step_name, approval_type, status, approvers, input_data, condition, timeout_minutes, decided_by, decided_at, comment, created_at, expires_at
         FROM approval_requests WHERE id = ?1"
    ).map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;

    stmt.query_row(params![&request_id], |row| {
        let input_data_str: String = row.get(8)?;
        let input_data: serde_json::Value = serde_json::from_str(&input_data_str).unwrap_or(json!({}));

        Ok(ApprovalRequest {
            id: row.get(0)?,
            workflow_id: row.get(1)?,
            workflow_name: row.get(2)?,
            step_id: row.get(3)?,
            step_name: row.get(4)?,
            approval_type: row.get(5)?,
            status: row.get(6)?,
            approvers: row.get(7)?,
            input_data,
            condition: row.get(9)?,
            timeout_minutes: row.get(10)?,
            decided_by: row.get(11)?,
            decided_at: row.get(12)?,
            comment: row.get(13)?,
            created_at: row.get(14)?,
            expires_at: row.get(15)?,
        })
    }).map_err(|e| format!("ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", e))
}

// ============================================================
// ì›Œí¬í”Œë¡œìš° ìŠ¤ì¼€ì¤„ëŸ¬ (Phase 9-4: Cron-based Scheduler)
// ============================================================

/// ìŠ¤ì¼€ì¤„ ì„¤ì •
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct WorkflowSchedule {
    pub id: String,
    pub workflow_id: String,
    pub workflow_name: String,
    pub cron_expression: String,
    pub timezone: String,
    pub is_active: bool,
    pub input_data: serde_json::Value,
    pub last_run_at: Option<String>,
    pub next_run_at: Option<String>,
    pub run_count: i64,
    pub last_status: Option<String>,
    pub last_error: Option<String>,
    pub created_at: String,
    pub updated_at: String,
}

/// ìŠ¤ì¼€ì¤„ ìƒì„± ìš”ì²­
#[derive(Debug, Serialize, Deserialize)]
pub struct CreateScheduleRequest {
    pub workflow_id: String,
    pub workflow_name: String,
    pub cron_expression: String,
    pub timezone: Option<String>,
    pub input_data: Option<serde_json::Value>,
}

/// Rowë¥¼ WorkflowScheduleë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼
fn row_to_schedule(row: &rusqlite::Row) -> Result<WorkflowSchedule, rusqlite::Error> {
    let input_data_str: String = row.get(6)?;
    let input_data: serde_json::Value = serde_json::from_str(&input_data_str).unwrap_or(json!({}));
    Ok(WorkflowSchedule {
        id: row.get(0)?,
        workflow_id: row.get(1)?,
        workflow_name: row.get(2)?,
        cron_expression: row.get(3)?,
        timezone: row.get(4)?,
        is_active: row.get::<_, i32>(5)? != 0,
        input_data,
        last_run_at: row.get(7)?,
        next_run_at: row.get(8)?,
        run_count: row.get(9)?,
        last_status: row.get(10)?,
        last_error: row.get(11)?,
        created_at: row.get(12)?,
        updated_at: row.get(13)?,
    })
}

/// ìŠ¤ì¼€ì¤„ ëª©ë¡ ì¡°íšŒ
#[tauri::command]
pub async fn get_workflow_schedules(
    workflow_id: Option<String>,
    active_only: Option<bool>,
) -> Result<Vec<WorkflowSchedule>, String> {
    println!("ğŸ“… [SCHEDULER] ìŠ¤ì¼€ì¤„ ëª©ë¡ ì¡°íšŒ");

    let conn = get_db_connection()?;
    let active_filter = active_only.unwrap_or(false);

    let mut result: Vec<WorkflowSchedule> = Vec::new();

    if let Some(wf_id) = workflow_id {
        let query = if active_filter {
            "SELECT id, workflow_id, workflow_name, cron_expression, timezone, is_active, input_data, last_run_at, next_run_at, run_count, last_status, last_error, created_at, updated_at FROM workflow_schedules WHERE workflow_id = ?1 AND is_active = 1 ORDER BY created_at DESC"
        } else {
            "SELECT id, workflow_id, workflow_name, cron_expression, timezone, is_active, input_data, last_run_at, next_run_at, run_count, last_status, last_error, created_at, updated_at FROM workflow_schedules WHERE workflow_id = ?1 ORDER BY created_at DESC"
        };
        let mut stmt = conn.prepare(query).map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;
        let schedules = stmt.query_map(params![wf_id], row_to_schedule)
            .map_err(|e| format!("ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?;
        result = schedules.filter_map(|r| r.ok()).collect();
    } else {
        let query = if active_filter {
            "SELECT id, workflow_id, workflow_name, cron_expression, timezone, is_active, input_data, last_run_at, next_run_at, run_count, last_status, last_error, created_at, updated_at FROM workflow_schedules WHERE is_active = 1 ORDER BY created_at DESC"
        } else {
            "SELECT id, workflow_id, workflow_name, cron_expression, timezone, is_active, input_data, last_run_at, next_run_at, run_count, last_status, last_error, created_at, updated_at FROM workflow_schedules ORDER BY created_at DESC"
        };
        let mut stmt = conn.prepare(query).map_err(|e| format!("ì¿¼ë¦¬ ì¤€ë¹„ ì‹¤íŒ¨: {}", e))?;
        let schedules = stmt.query_map([], row_to_schedule)
            .map_err(|e| format!("ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?;
        result = schedules.filter_map(|r| r.ok()).collect();
    }

    println!("ğŸ“… [SCHEDULER] ì¡°íšŒëœ ìŠ¤ì¼€ì¤„: {}ê±´", result.len());
    Ok(result)
}

/// ìŠ¤ì¼€ì¤„ ìƒì„±
#[tauri::command]
pub async fn create_workflow_schedule(
    request: CreateScheduleRequest,
) -> Result<WorkflowSchedule, String> {
    println!("ğŸ“… [SCHEDULER] ìŠ¤ì¼€ì¤„ ìƒì„±: {} ({})", request.workflow_name, request.cron_expression);

    // Cron í‘œí˜„ì‹ ìœ íš¨ì„± ê²€ì‚¬
    use cron::Schedule;
    use std::str::FromStr;

    let _schedule = Schedule::from_str(&request.cron_expression)
        .map_err(|e| format!("ì˜ëª»ëœ Cron í‘œí˜„ì‹: {} - {}", request.cron_expression, e))?;

    let schedule_id = format!("sch-{}", uuid::Uuid::new_v4().to_string().split('-').next().unwrap_or("000"));
    let timezone = request.timezone.unwrap_or_else(|| "Asia/Seoul".to_string());
    let input_data = request.input_data.unwrap_or(json!({}));
    let now = chrono::Utc::now().to_rfc3339();

    // ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    let next_run = _schedule.upcoming(chrono::Utc).next()
        .map(|dt| dt.to_rfc3339());

    let conn = get_db_connection()?;

    conn.execute(
        "INSERT INTO workflow_schedules (id, workflow_id, workflow_name, cron_expression, timezone, is_active, input_data, next_run_at, created_at, updated_at)
         VALUES (?1, ?2, ?3, ?4, ?5, 1, ?6, ?7, ?8, ?8)",
        params![
            &schedule_id,
            &request.workflow_id,
            &request.workflow_name,
            &request.cron_expression,
            &timezone,
            &serde_json::to_string(&input_data).unwrap_or_default(),
            &next_run,
            &now
        ],
    ).map_err(|e| format!("ìŠ¤ì¼€ì¤„ ìƒì„± ì‹¤íŒ¨: {}", e))?;

    println!("âœ… [SCHEDULER] ìŠ¤ì¼€ì¤„ ìƒì„± ì™„ë£Œ: {} (ë‹¤ìŒ ì‹¤í–‰: {:?})", schedule_id, next_run);

    Ok(WorkflowSchedule {
        id: schedule_id,
        workflow_id: request.workflow_id,
        workflow_name: request.workflow_name,
        cron_expression: request.cron_expression,
        timezone,
        is_active: true,
        input_data,
        last_run_at: None,
        next_run_at: next_run,
        run_count: 0,
        last_status: None,
        last_error: None,
        created_at: now.clone(),
        updated_at: now,
    })
}

/// ìŠ¤ì¼€ì¤„ í™œì„±í™”/ë¹„í™œì„±í™” í† ê¸€
#[tauri::command]
pub async fn toggle_workflow_schedule(
    schedule_id: String,
    is_active: bool,
) -> Result<serde_json::Value, String> {
    println!("ğŸ“… [SCHEDULER] ìŠ¤ì¼€ì¤„ í† ê¸€: {} â†’ {}", schedule_id, if is_active { "í™œì„±í™”" } else { "ë¹„í™œì„±í™”" });

    let conn = get_db_connection()?;
    let now = chrono::Utc::now().to_rfc3339();

    let affected = conn.execute(
        "UPDATE workflow_schedules SET is_active = ?1, updated_at = ?2 WHERE id = ?3",
        params![is_active as i32, &now, &schedule_id],
    ).map_err(|e| format!("ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {}", e))?;

    if affected == 0 {
        return Err(format!("ìŠ¤ì¼€ì¤„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", schedule_id));
    }

    Ok(json!({
        "schedule_id": schedule_id,
        "is_active": is_active,
        "message": format!("ìŠ¤ì¼€ì¤„ì´ {}ë˜ì—ˆìŠµë‹ˆë‹¤", if is_active { "í™œì„±í™”" } else { "ë¹„í™œì„±í™”" })
    }))
}

/// ìŠ¤ì¼€ì¤„ ì‚­ì œ
#[tauri::command]
pub async fn delete_workflow_schedule(schedule_id: String) -> Result<serde_json::Value, String> {
    println!("ğŸ“… [SCHEDULER] ìŠ¤ì¼€ì¤„ ì‚­ì œ: {}", schedule_id);

    let conn = get_db_connection()?;

    let affected = conn.execute(
        "DELETE FROM workflow_schedules WHERE id = ?1",
        params![&schedule_id],
    ).map_err(|e| format!("ìŠ¤ì¼€ì¤„ ì‚­ì œ ì‹¤íŒ¨: {}", e))?;

    if affected == 0 {
        return Err(format!("ìŠ¤ì¼€ì¤„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", schedule_id));
    }

    println!("âœ… [SCHEDULER] ìŠ¤ì¼€ì¤„ ì‚­ì œ ì™„ë£Œ: {}", schedule_id);

    Ok(json!({
        "schedule_id": schedule_id,
        "message": "ìŠ¤ì¼€ì¤„ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
    }))
}

/// Cron í‘œí˜„ì‹ ìœ íš¨ì„± ê²€ì‚¬ ë° ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ë¯¸ë¦¬ë³´ê¸°
#[tauri::command]
pub async fn validate_cron_expression(
    cron_expression: String,
    count: Option<usize>,
) -> Result<serde_json::Value, String> {
    use cron::Schedule;
    use std::str::FromStr;

    let schedule = Schedule::from_str(&cron_expression)
        .map_err(|e| format!("ì˜ëª»ëœ Cron í‘œí˜„ì‹: {}", e))?;

    let count = count.unwrap_or(5);
    let upcoming: Vec<String> = schedule
        .upcoming(chrono::Utc)
        .take(count)
        .map(|dt| dt.to_rfc3339())
        .collect();

    Ok(json!({
        "valid": true,
        "expression": cron_expression,
        "next_runs": upcoming,
        "message": format!("ìœ íš¨í•œ Cron í‘œí˜„ì‹ì…ë‹ˆë‹¤. ë‹¤ìŒ {}íšŒ ì‹¤í–‰ ì˜ˆì •", count)
    }))
}

/// ìŠ¤ì¼€ì¤„ ì‹¤í–‰ ê¸°ë¡ ì—…ë°ì´íŠ¸ (ë‚´ë¶€ìš©)
fn update_schedule_run_status(
    conn: &Connection,
    schedule_id: &str,
    status: &str,
    error: Option<&str>,
) -> Result<(), String> {
    use cron::Schedule;
    use std::str::FromStr;

    let now = chrono::Utc::now().to_rfc3339();

    // í˜„ì¬ ìŠ¤ì¼€ì¤„ì˜ cron expression ê°€ì ¸ì˜¤ê¸°
    let cron_expr: String = conn.query_row(
        "SELECT cron_expression FROM workflow_schedules WHERE id = ?1",
        params![schedule_id],
        |row| row.get(0),
    ).map_err(|e| format!("ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì‹¤íŒ¨: {}", e))?;

    // ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    let next_run = Schedule::from_str(&cron_expr)
        .ok()
        .and_then(|s| s.upcoming(chrono::Utc).next())
        .map(|dt| dt.to_rfc3339());

    conn.execute(
        "UPDATE workflow_schedules SET last_run_at = ?1, last_status = ?2, last_error = ?3, next_run_at = ?4, run_count = run_count + 1, updated_at = ?1 WHERE id = ?5",
        params![&now, status, error, &next_run, schedule_id],
    ).map_err(|e| format!("ìŠ¤ì¼€ì¤„ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {}", e))?;

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_workflow_metadata_serialization() {
        let metadata = WorkflowMetadata {
            name: "í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš°".to_string(),
            description: "í…ŒìŠ¤íŠ¸ ì„¤ëª…".to_string(),
            is_active: true,
        };

        let json = serde_json::to_string(&metadata).unwrap();
        assert!(json.contains("isActive")); // camelCase í™•ì¸
        assert!(json.contains("í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš°"));
    }

    #[test]
    fn test_workflow_step_serialization() {
        let step = WorkflowStep {
            id: "step-1".to_string(),
            step_type: "TRIGGER".to_string(),
            label: "íŠ¸ë¦¬ê±° ìŠ¤í…".to_string(),
            config: json!({
                "triggerType": "threshold",
                "condition": "temperature > 90",
                "threshold": 90
            }),
        };

        let json = serde_json::to_string(&step).unwrap();
        assert!(json.contains("\"type\":\"TRIGGER\"")); // type í•„ë“œ í™•ì¸
        assert!(json.contains("triggerType"));
    }

    #[tokio::test]
    async fn test_execute_trigger_step() {
        let step = WorkflowStep {
            id: "step-1".to_string(),
            step_type: "TRIGGER".to_string(),
            label: "íŠ¸ë¦¬ê±°".to_string(),
            config: json!({}),
        };

        let input = json!({"test": true});
        let result = execute_trigger_step(&step, &input).await;

        assert!(result.is_ok());
        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "TRIGGER");
        assert_eq!(output["triggered"], true);
    }

    #[tokio::test]
    async fn test_execute_judgment_step_with_rule() {
        let step = WorkflowStep {
            id: "step-judgment".to_string(),
            step_type: "JUDGMENT".to_string(),
            label: "AI íŒë‹¨".to_string(),
            config: json!({
                "judgmentMethod": "rule",
                "ruleExpression": "temperature > 90"
            }),
        };

        let input = json!({"temperature": 95});
        let result = execute_judgment_step(&step, &input).await;

        assert!(result.is_ok());
        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "JUDGMENT");
        assert_eq!(output["judgment"], true);
        assert_eq!(output["method"], "rule");
        assert_eq!(output["confidence"], 1.0);
    }

    #[tokio::test]
    async fn test_execute_judgment_step_rule_missing() {
        // Rule ëª¨ë“œì¸ë° ruleExpressionì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        let step = WorkflowStep {
            id: "step-judgment".to_string(),
            step_type: "JUDGMENT".to_string(),
            label: "AI íŒë‹¨".to_string(),
            config: json!({
                "judgmentMethod": "rule"
                // ruleExpression ëˆ„ë½
            }),
        };

        let input = json!({"temperature": 95});
        let result = execute_judgment_step(&step, &input).await;

        assert!(result.is_err());
        assert!(result.unwrap_err().contains("Rule í‘œí˜„ì‹ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"));
    }

    // Phase 4: LLM/Hybrid ëª¨ë“œ í†µí•© í…ŒìŠ¤íŠ¸ëŠ” Mock API í™˜ê²½ì—ì„œ ë³„ë„ í…ŒìŠ¤íŠ¸ í•„ìš”
    // (ì‹¤ì œ Claude API í˜¸ì¶œ ëŒ€ì‹  Mock LLM Engine ì‚¬ìš©)
    //
    // TODO: ë‹¤ìŒ ë‹¨ê³„ì—ì„œ êµ¬í˜„
    // - test_execute_judgment_step_llm_mode()
    // - test_execute_judgment_step_hybrid_rule_success()
    // - test_execute_judgment_step_hybrid_llm_fallback()

    #[tokio::test]
    async fn test_e2e_workflow_6_nodetypes() {
        // Phase 4-1: 6ê°œ NodeType End-to-End ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
        // TRIGGER â†’ QUERY â†’ CALC â†’ JUDGMENT â†’ APPROVAL â†’ ALERT

        let request = SimulateWorkflowRequest {
            workflow_id: "e2e-test-workflow".to_string(),
            steps: vec![
                WorkflowStep {
                    id: "step-1-trigger".to_string(),
                    step_type: "TRIGGER".to_string(),
                    label: "ì˜¨ë„ ì„ê³„ê°’ íŠ¸ë¦¬ê±°".to_string(),
                    config: json!({
                        "triggerType": "threshold",
                        "condition": "temperature > 90",
                    "threshold": 90.0
                    }),
                },
                WorkflowStep {
                    id: "step-2-query".to_string(),
                    step_type: "QUERY".to_string(),
                    label: "ì„¤ë¹„ ë°ì´í„° ì¡°íšŒ".to_string(),
                    config: json!({
                        "queryType": "database",
                        "tableName": "equipment_status"
                    }),
                },
                WorkflowStep {
                    id: "step-3-calc".to_string(),
                    step_type: "CALC".to_string(),
                    label: "í‰ê·  ì˜¨ë„ ê³„ì‚°".to_string(),
                    config: json!({
                        "calcType": "aggregate",
                        "aggregateFunction": "avg",
                        "targetField": "temperature",
                        "outputField": "avg_temperature"
                    }),
                },
                WorkflowStep {
                    id: "step-4-judgment".to_string(),
                    step_type: "JUDGMENT".to_string(),
                    label: "ê³ ì˜¨ ì´ìƒ íŒë‹¨".to_string(),
                    config: json!({
                        "judgmentMethod": "rule",
                        "ruleExpression": "avg_temperature > 85"
                    }),
                },
                WorkflowStep {
                    id: "step-5-approval".to_string(),
                    step_type: "APPROVAL".to_string(),
                    label: "ìë™ ìŠ¹ì¸".to_string(),
                    config: json!({
                        "approvalType": "auto"
                    }),
                },
                WorkflowStep {
                    id: "step-6-alert".to_string(),
                    step_type: "ALERT".to_string(),
                    label: "Slack ì•Œë¦¼".to_string(),
                    config: json!({
                        "channels": ["slack"],
                        "recipients": ["#alerts"],
                        "message": "ê³ ì˜¨ ì´ìƒ ê°ì§€: {avg_temperature}ë„"
                    }),
                },
            ],
            test_data: json!({
                "temperature": 95,
                "equipment_id": "EQ-001"
            }),
        };

        let result = simulate_workflow_v2(request).await;

        assert!(result.is_ok());
        let response = result.unwrap();

        // ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì„±ê³µ í™•ì¸
        assert_eq!(response.status, "success");

        // 6ê°œ ìŠ¤í… ëª¨ë‘ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        assert_eq!(response.steps_executed.len(), 6);

        // ê° ìŠ¤í… íƒ€ì… í™•ì¸ (Option<JsonValue>ì´ë¯€ë¡œ unwrap í•„ìš”)
        let output_0 = response.steps_executed[0].output.as_ref().unwrap();
        let output_1 = response.steps_executed[1].output.as_ref().unwrap();
        let output_2 = response.steps_executed[2].output.as_ref().unwrap();
        let output_3 = response.steps_executed[3].output.as_ref().unwrap();
        let output_4 = response.steps_executed[4].output.as_ref().unwrap();
        let output_5 = response.steps_executed[5].output.as_ref().unwrap();

        assert_eq!(output_0["step_type"], "TRIGGER");
        assert_eq!(output_1["step_type"], "QUERY");
        assert_eq!(output_2["step_type"], "CALC");
        assert_eq!(output_3["step_type"], "JUDGMENT");
        assert_eq!(output_4["step_type"], "APPROVAL");
        assert_eq!(output_5["step_type"], "ALERT");

        // TRIGGER ì„±ê³µ í™•ì¸
        assert_eq!(output_0["triggered"], true);

        // CALC ì§‘ê³„ ê²°ê³¼ í™•ì¸
        assert!(output_2["result"].is_number());

        // JUDGMENT íŒë‹¨ ê²°ê³¼ í™•ì¸
        assert!(output_3["judgment"].is_boolean());
        assert_eq!(output_3["method"], "rule");

        // APPROVAL ìŠ¹ì¸ í™•ì¸
        assert_eq!(output_4["approved"], true);

        // ALERT ë°œì†¡ í™•ì¸
        assert_eq!(output_5["sent"], true);

        // ì‹¤í–‰ ì‹œê°„ í™•ì¸ (0msì¼ ìˆ˜ë„ ìˆìŒ - ë¹ ë¥¸ ì‹¤í–‰)
        assert!(response.total_execution_time_ms >= 0);

        println!("âœ… E2E ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
        println!("  - ì´ ì‹¤í–‰ ì‹œê°„: {}ms", response.total_execution_time_ms);
        println!("  - ìµœì¢… ìƒíƒœ: {}", response.status);
    }

    #[tokio::test]
    async fn test_get_workflow_executions() {
        // E2E í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰ (DBì— ë°ì´í„° ìƒì„±)
        let request = SimulateWorkflowRequest {
            workflow_id: "test-history-workflow".to_string(),
            steps: vec![
                WorkflowStep {
                    id: "trigger-1".to_string(),
                    step_type: "TRIGGER".to_string(),
                    label: "í…ŒìŠ¤íŠ¸ íŠ¸ë¦¬ê±°".to_string(),
                    config: json!({
                        "triggerType": "manual"
                    }),
                },
            ],
            test_data: json!({"test": "data"}),
        };

        let result = simulate_workflow_v2(request).await;
        assert!(result.is_ok());

        // ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ
        let executions = get_workflow_executions("test-history-workflow".to_string(), Some(10)).await;
        assert!(executions.is_ok());

        let list = executions.unwrap();
        assert!(list.len() > 0);

        println!("âœ… ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
        println!("  - ì¡°íšŒëœ ì´ë ¥: {}ê±´", list.len());

        // ìƒì„¸ ì¡°íšŒ
        let execution_id = list[0].id.clone();
        let detail = get_workflow_execution_detail(execution_id).await;
        assert!(detail.is_ok());

        let detail_data = detail.unwrap();
        assert_eq!(detail_data.workflow_id, "test-history-workflow");
        assert_eq!(detail_data.status, "success");

        println!("âœ… ì‹¤í–‰ ì´ë ¥ ìƒì„¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
        println!("  - ìŠ¤í… ê°œìˆ˜: {}", detail_data.steps_executed.len());
    }

    #[tokio::test]
    async fn test_query_step_database() {
        let step = WorkflowStep {
            id: "query-1".to_string(),
            step_type: "QUERY".to_string(),
            label: "ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ".to_string(),
            config: json!({
                "dataSource": "database",
                "queryType": "SELECT",
                "query": "SELECT * FROM judgments LIMIT 5"
            }),
        };

        let input_data = json!({"test": "data"});

        let result = execute_query_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, updated_data) = result.unwrap();
        assert_eq!(output["step_type"], "QUERY");
        assert_eq!(output["data_source"], "database");
        assert!(output["data"].is_array());
        assert!(updated_data["query_result"].is_array());

        println!("âœ… QUERY (database) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_query_step_api() {
        let step = WorkflowStep {
            id: "query-2".to_string(),
            step_type: "QUERY".to_string(),
            label: "API í˜¸ì¶œ".to_string(),
            config: json!({
                "dataSource": "api",
                "query": "https://api.example.com/sensors/SENS-001"
            }),
        };

        let input_data = json!({"test": "data"});

        let result = execute_query_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, updated_data) = result.unwrap();
        assert_eq!(output["step_type"], "QUERY");
        assert_eq!(output["data_source"], "api");
        assert_eq!(output["response"]["status"], "success");
        assert!(updated_data["api_response"]["data"]["readings"].is_array());

        println!("âœ… QUERY (api) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_query_step_sensor() {
        let step = WorkflowStep {
            id: "query-3".to_string(),
            step_type: "QUERY".to_string(),
            label: "ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘".to_string(),
            config: json!({
                "dataSource": "sensor",
                "sensorId": "SENS-001"
            }),
        };

        let input_data = json!({"test": "data"});

        let result = execute_query_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, updated_data) = result.unwrap();
        assert_eq!(output["step_type"], "QUERY");
        assert_eq!(output["data_source"], "sensor");
        assert!(output["sensor_data"]["temperature"].is_number());
        assert!(updated_data["sensor_data"]["vibration"].is_number());

        println!("âœ… QUERY (sensor) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_query_step_file() {
        let step = WorkflowStep {
            id: "query-4".to_string(),
            step_type: "QUERY".to_string(),
            label: "íŒŒì¼ ì¡°íšŒ".to_string(),
            config: json!({
                "dataSource": "file",
                "filePath": "/data/production_data.csv"
            }),
        };

        let input_data = json!({"test": "data"});

        let result = execute_query_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, updated_data) = result.unwrap();
        assert_eq!(output["step_type"], "QUERY");
        assert_eq!(output["data_source"], "file");
        assert!(output["file_data"]["sample"].is_array());
        assert_eq!(output["file_data"]["rows"], 150);
        assert!(updated_data["file_data"].is_object());

        println!("âœ… QUERY (file) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_query_step_invalid_source() {
        let step = WorkflowStep {
            id: "query-5".to_string(),
            step_type: "QUERY".to_string(),
            label: "ì˜ëª»ëœ ë°ì´í„° ì†ŒìŠ¤".to_string(),
            config: json!({
                "dataSource": "invalid_source"
            }),
        };

        let input_data = json!({"test": "data"});

        let result = execute_query_step(&step, &input_data).await;
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì†ŒìŠ¤"));

        println!("âœ… QUERY (invalid source) ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_alert_step_email() {
        let step = WorkflowStep {
            id: "alert-1".to_string(),
            step_type: "ALERT".to_string(),
            label: "ì´ë©”ì¼ ì•Œë¦¼".to_string(),
            config: json!({
                "channels": ["email"],
                "recipients": "manager@example.com",
                "subject": "ê¸´ê¸‰: ì„¤ë¹„ ê³ ì¥",
                "messageTemplate": "ì„¤ë¹„ {equipment_id}ì—ì„œ ì´ìƒ ê°ì§€",
                "priority": "high",
                "includeData": true
            }),
        };

        let input_data = json!({
            "equipment_id": "EQ-001",
            "temperature": 95.5
        });

        let result = execute_alert_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "ALERT");
        assert!(output["channels"].as_array().unwrap().contains(&json!("email")));
        assert_eq!(output["recipients"], "manager@example.com");
        assert!(output["message"].as_str().unwrap().contains("EQ-001"));

        println!("âœ… ALERT (email) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_alert_step_slack() {
        let step = WorkflowStep {
            id: "alert-2".to_string(),
            step_type: "ALERT".to_string(),
            label: "Slack ì•Œë¦¼".to_string(),
            config: json!({
                "channels": ["slack"],
                "recipients": "#production-alerts",
                "subject": "í’ˆì§ˆ ê²½ê³ ",
                "messageTemplate": "ë¶ˆëŸ‰ë¥  {defect_rate}% ì´ˆê³¼",
                "priority": "medium"
            }),
        };

        let input_data = json!({
            "defect_rate": 7.5
        });

        let result = execute_alert_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "ALERT");
        assert!(output["channels"].as_array().unwrap().contains(&json!("slack")));
        assert!(output["message"].as_str().unwrap().contains("7.5"));

        println!("âœ… ALERT (slack) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_alert_step_teams() {
        let step = WorkflowStep {
            id: "alert-3".to_string(),
            step_type: "ALERT".to_string(),
            label: "Teams ì•Œë¦¼".to_string(),
            config: json!({
                "channels": ["teams"],
                "recipients": "Production Team",
                "subject": "ìƒì‚° ì§€ì—°",
                "messageTemplate": "ë¼ì¸ {line_id}ì—ì„œ {delay_minutes}ë¶„ ì§€ì—°",
                "priority": "low"
            }),
        };

        let input_data = json!({
            "line_id": "LINE-A",
            "delay_minutes": 15
        });

        let result = execute_alert_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "ALERT");
        assert!(output["channels"].as_array().unwrap().contains(&json!("teams")));
        assert!(output["message"].as_str().unwrap().contains("LINE-A"));
        assert!(output["message"].as_str().unwrap().contains("15"));

        println!("âœ… ALERT (teams) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_alert_step_webhook() {
        let step = WorkflowStep {
            id: "alert-4".to_string(),
            step_type: "ALERT".to_string(),
            label: "Webhook ì•Œë¦¼".to_string(),
            config: json!({
                "channels": ["webhook"],
                "recipients": "https://example.com/webhook",
                "subject": "ì‹œìŠ¤í…œ ì•Œë¦¼",
                "messageTemplate": "ì´ë²¤íŠ¸ ë°œìƒ: {event_type}",
                "priority": "high"
            }),
        };

        let input_data = json!({
            "event_type": "EQUIPMENT_FAILURE"
        });

        let result = execute_alert_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "ALERT");
        assert!(output["channels"].as_array().unwrap().contains(&json!("webhook")));
        assert!(output["message"].as_str().unwrap().contains("EQUIPMENT_FAILURE"));

        println!("âœ… ALERT (webhook) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    #[tokio::test]
    async fn test_alert_step_multiple_channels() {
        let step = WorkflowStep {
            id: "alert-5".to_string(),
            step_type: "ALERT".to_string(),
            label: "ë‹¤ì¤‘ ì±„ë„ ì•Œë¦¼".to_string(),
            config: json!({
                "channels": ["email", "slack", "teams"],
                "recipients": "admin@example.com",
                "subject": "ê¸´ê¸‰ ì•Œë¦¼",
                "messageTemplate": "ë‹¤ì¤‘ ì±„ë„ í…ŒìŠ¤íŠ¸",
                "priority": "high"
            }),
        };

        let input_data = json!({"test": "data"});

        let result = execute_alert_step(&step, &input_data).await;
        assert!(result.is_ok());

        let (output, _) = result.unwrap();
        assert_eq!(output["step_type"], "ALERT");
        let channels = output["channels"].as_array().unwrap();
        assert_eq!(channels.len(), 3);
        assert!(channels.contains(&json!("email")));
        assert!(channels.contains(&json!("slack")));
        assert!(channels.contains(&json!("teams")));

        println!("âœ… ALERT (multiple channels) ìœ ë‹› í…ŒìŠ¤íŠ¸ ì„±ê³µ!");
    }

    // ============================================================================
    // Phase 9-2: AI Workflow Generator í…ŒìŠ¤íŠ¸
    // ============================================================================

    #[test]
    fn test_system_prompt_contains_all_node_types() {
        // Given: System prompt ìƒì„±
        let system_prompt = create_workflow_dsl_prompt();

        // When: 6ê°œ NodeTypeì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦
        let expected_types = vec![
            "TRIGGER", "QUERY", "CALC", "JUDGMENT", "APPROVAL", "ALERT"
        ];

        // Then: ëª¨ë“  NodeTypeì´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì–´ì•¼ í•¨
        for node_type in expected_types {
            assert!(
                system_prompt.contains(node_type),
                "System prompt should contain NodeType: {}",
                node_type
            );
        }
        println!("âœ… System Prompt NodeType ê²€ì¦ ì„±ê³µ!");
    }

    #[test]
    fn test_system_prompt_contains_few_shot_examples() {
        // Given: System prompt ìƒì„±
        let system_prompt = create_workflow_dsl_prompt();

        // When: 5ê°œ Few-shot ì˜ˆì‹œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì¦
        let expected_examples = vec![
            "ë¶ˆëŸ‰ë¥  ëª¨ë‹ˆí„°ë§",      // Example 1
            "ì„¤ë¹„ ê°€ë™ë¥  ë¶„ì„",     // Example 2
            "AI í’ˆì§ˆ íŒë‹¨",         // Example 3
            "ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§",      // Example 4 (ì‹¤ì œ prompt í…ìŠ¤íŠ¸)
            "ë‹¤ë‹¨ê³„ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤", // Example 5
        ];

        // Then: ëª¨ë“  ì˜ˆì‹œê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì–´ì•¼ í•¨
        for example in expected_examples {
            assert!(
                system_prompt.contains(example),
                "System prompt should contain example: {}",
                example
            );
        }
        println!("âœ… System Prompt Few-shot ì˜ˆì‹œ ê²€ì¦ ì„±ê³µ!");
    }

    #[test]
    fn test_parse_simple_workflow_json() {
        // Given: Claudeê°€ ë°˜í™˜í•œ ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš° JSON
        let json_response = r#"[
            {
                "id": "trigger_1",
                "type": "TRIGGER",
                "label": "ë¶ˆëŸ‰ ê°ì§€",
                "config": {
                    "triggerType": "threshold",
                    "metric": "ë¶ˆëŸ‰ë¥ ",
                    "condition": "> 3%"
                }
            },
            {
                "id": "alert_1",
                "type": "ALERT",
                "label": "ì•Œë¦¼ ì „ì†¡",
                "config": {
                    "channel": "slack",
                    "message": "ë¶ˆëŸ‰ë¥  ì´ˆê³¼"
                }
            }
        ]"#;

        // When: JSON íŒŒì‹±
        let result: Result<Vec<WorkflowStep>, _> = serde_json::from_str(json_response);

        // Then: íŒŒì‹± ì„±ê³µ ë° 2ê°œ ìŠ¤í… í™•ì¸
        assert!(result.is_ok(), "JSON parsing should succeed");
        let steps = result.unwrap();
        assert_eq!(steps.len(), 2, "Should have 2 steps");
        assert_eq!(steps[0].step_type, "TRIGGER");
        assert_eq!(steps[1].step_type, "ALERT");
        println!("âœ… ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš° JSON íŒŒì‹± ì„±ê³µ!");
    }

    #[test]
    fn test_parse_complex_workflow_json() {
        // Given: Claudeê°€ ë°˜í™˜í•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° JSON (6ê°œ NodeType ëª¨ë‘ í¬í•¨)
        let json_response = r#"[
            {
                "id": "trigger_1",
                "type": "TRIGGER",
                "label": "ë§¤ ì‹œê°„ ì‹¤í–‰",
                "config": { "cron": "0 * * * *" }
            },
            {
                "id": "query_1",
                "type": "QUERY",
                "label": "ë¶ˆëŸ‰ë¥  ì¡°íšŒ",
                "config": { "sql": "SELECT AVG(defect_rate) FROM line_1" }
            },
            {
                "id": "calc_1",
                "type": "CALC",
                "label": "í‰ê·  ê³„ì‚°",
                "config": { "formula": "SUM(values) / COUNT(values)" }
            },
            {
                "id": "judgment_1",
                "type": "JUDGMENT",
                "label": "íŒë‹¨ ì‹¤í–‰",
                "config": { "rule": "defect_rate > 3%" }
            },
            {
                "id": "approval_1",
                "type": "APPROVAL",
                "label": "íŒ€ì¥ ìŠ¹ì¸",
                "config": { "approver": "ìƒì‚°íŒ€ì¥" }
            },
            {
                "id": "alert_1",
                "type": "ALERT",
                "label": "ì•Œë¦¼ ì „ì†¡",
                "config": { "channel": "slack" }
            }
        ]"#;

        // When: JSON íŒŒì‹±
        let result: Result<Vec<WorkflowStep>, _> = serde_json::from_str(json_response);

        // Then: íŒŒì‹± ì„±ê³µ ë° 6ê°œ NodeType ëª¨ë‘ í™•ì¸
        assert!(result.is_ok(), "JSON parsing should succeed");
        let steps = result.unwrap();
        assert_eq!(steps.len(), 6, "Should have 6 steps");

        // ê° NodeType ê²€ì¦
        assert_eq!(steps[0].step_type, "TRIGGER");
        assert_eq!(steps[1].step_type, "QUERY");
        assert_eq!(steps[2].step_type, "CALC");
        assert_eq!(steps[3].step_type, "JUDGMENT");
        assert_eq!(steps[4].step_type, "APPROVAL");
        assert_eq!(steps[5].step_type, "ALERT");
        println!("âœ… ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° JSON íŒŒì‹± ì„±ê³µ (6ê°œ NodeType)!");
    }

    #[test]
    fn test_parse_invalid_json_should_fail() {
        // Given: ì˜ëª»ëœ JSON (type í•„ë“œ ëˆ„ë½)
        let invalid_json = r#"[
            {
                "id": "trigger_1",
                "label": "ë¶ˆëŸ‰ ê°ì§€",
                "config": {}
            }
        ]"#;

        // When: JSON íŒŒì‹± ì‹œë„
        let result: Result<Vec<WorkflowStep>, _> = serde_json::from_str(invalid_json);

        // Then: íŒŒì‹± ì‹¤íŒ¨í•´ì•¼ í•¨
        assert!(result.is_err(), "Invalid JSON should fail to parse");
        println!("âœ… ì˜ëª»ëœ JSON íŒŒì‹± ì‹¤íŒ¨ ê²€ì¦ ì„±ê³µ!");
    }
}

// ============================================================================
// Phase 9-2: AI Workflow Generator
// ============================================================================

/// AI ì›Œí¬í”Œë¡œìš° ìƒì„± (ìì—°ì–´ â†’ WorkflowStep ë°°ì—´)
///
/// # Arguments
/// * `user_prompt` - ì‚¬ìš©ì ìì—°ì–´ ì…ë ¥ (ì˜ˆ: "1í˜¸ì„  ë¶ˆëŸ‰ë¥  3% ì´ˆê³¼ì‹œ ì•Œë¦¼")
/// * `app_handle` - Tauri AppHandle (ChatService ì´ˆê¸°í™”ìš©)
///
/// # Returns
/// * `Ok(Vec<WorkflowStep>)` - ìƒì„±ëœ ì›Œí¬í”Œë¡œìš° ìŠ¤í… ë°°ì—´
/// * `Err(String)` - ì—ëŸ¬ ë©”ì‹œì§€
///
/// # Example
/// ```rust
/// let steps = generate_workflow_draft(
///     "1í˜¸ì„  ë¶ˆëŸ‰ë¥  3% ì´ˆê³¼ì‹œ ì•Œë¦¼".to_string(),
///     app_handle
/// ).await?;
/// ```
#[tauri::command]
pub async fn generate_workflow_draft(
    user_prompt: String,
    app_handle: tauri::AppHandle,
) -> Result<Vec<WorkflowStep>, String> {
    use crate::services::chat_service::ChatService;

    // 1. ChatService ì´ˆê¸°í™”
    let chat_service = ChatService::with_app_handle(Some(app_handle))
        .map_err(|e| format!("ChatService ì´ˆê¸°í™” ì‹¤íŒ¨: {}", e))?;

    // 2. System Prompt (Manufacturing DSL)
    let system_prompt = create_workflow_dsl_prompt();

    // 3. Claude API í˜¸ì¶œ
    let response = chat_service
        .generate_workflow_from_prompt(&system_prompt, &user_prompt)
        .await
        .map_err(|e| format!("Claude API í˜¸ì¶œ ì‹¤íŒ¨: {}", e))?;

    // 4. JSON íŒŒì‹± â†’ Vec<WorkflowStep>
    let steps: Vec<WorkflowStep> = serde_json::from_str(&response)
        .map_err(|e| format!("ì›Œí¬í”Œë¡œìš° JSON íŒŒì‹± ì‹¤íŒ¨: {}\n\nReceived: {}", e, response))?;

    // 5. ìœ íš¨ì„± ê²€ì¦
    if steps.is_empty() {
        return Err("ìƒì„±ëœ ì›Œí¬í”Œë¡œìš°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.".to_string());
    }

    Ok(steps)
}

/// Manufacturing DSL System Prompt ìƒì„±
///
/// Claudeê°€ í•œêµ­ì–´ ì œì¡°ì—… ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•˜ë„ë¡ ê°€ì´ë“œí•˜ëŠ” í”„ë¡¬í”„íŠ¸
fn create_workflow_dsl_prompt() -> String {
    r##"You are a Manufacturing Workflow Architect specializing in Korean smart factory automation.

# Available Node Types (6ê°œ):
1. **TRIGGER**: Event-based activation (ì‹œê°„, ì„¼ì„œ, Webhook ë“±)
2. **QUERY**: Data retrieval (DB, API, File ë“±)
3. **CALC**: Mathematical calculations (í†µê³„, ì§‘ê³„ ë“±)
4. **JUDGMENT**: Rule-based or AI-powered decision (í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨)
5. **APPROVAL**: Human approval gates (ìƒì‚°íŒ€ì¥, í’ˆì§ˆíŒ€ì¥ ë“±)
6. **ALERT**: Notifications (Email, Slack, Teams, Webhook)

# Output Format (JSON Array ONLY - NO MARKDOWN!):
Return ONLY a valid JSON array. Do NOT wrap in markdown code blocks.

[
  {
    "id": "step-{unique-id}",
    "type": "TRIGGER|QUERY|CALC|JUDGMENT|APPROVAL|ALERT",
    "label": "í•œê¸€ ìŠ¤í… ì´ë¦„",
    "config": { /* typeë³„ ì„¤ì • */ }
  }
]

# Rules:
- Always return valid JSON array (no markdown, no explanation)
- Use Korean labels for clarity
- Infer factory/line IDs from context (default: "Plant-A", "L01")
- JUDGMENT rules use structured format: "field operator value" (ì˜ˆ: "rate > 3.0")
- ALERT default channel: ["email"] (ì‚¬ìš©ìê°€ ëª…ì‹œí•˜ë©´ slack, teams ì¶”ê°€)
- Each step must have unique ID (step-1, step-2, ...)

# Few-Shot Examples:

## Example 1: ë¶ˆëŸ‰ë¥  ëª¨ë‹ˆí„°ë§
User: "1í˜¸ì„  ë¶ˆëŸ‰ë¥ ì´ 3% ì´ˆê³¼í•˜ë©´ ì•Œë¦¼"
Output:
[
  {
    "id": "step-1",
    "type": "QUERY",
    "label": "1í˜¸ì„  ë¶ˆëŸ‰ë¥  ì¡°íšŒ",
    "config": {
      "dataSource": "database",
      "query": "SELECT rate FROM defect_rates WHERE line_id = 'L01' ORDER BY created_at DESC LIMIT 1",
      "queryType": "sql"
    }
  },
  {
    "id": "step-2",
    "type": "JUDGMENT",
    "label": "ë¶ˆëŸ‰ë¥  3% ì´ˆê³¼ íŒë‹¨",
    "config": {
      "judgmentMethod": "rule",
      "ruleExpression": "rate > 3.0"
    }
  },
  {
    "id": "step-3",
    "type": "ALERT",
    "label": "ì´ë©”ì¼ ì•Œë¦¼ ë°œì†¡",
    "config": {
      "channels": ["email"],
      "recipients": "production-team@company.com",
      "messageTemplate": "âš ï¸ 1í˜¸ì„  ë¶ˆëŸ‰ë¥  {rate}% ì´ˆê³¼ ë°œìƒ!"
    }
  }
]

## Example 2: ì„¤ë¹„ ê°€ë™ë¥  ë¶„ì„
User: "Aë¼ì¸ ì„¤ë¹„ ê°€ë™ë¥  ê³„ì‚°í•˜ê³  80% ë¯¸ë§Œì´ë©´ íŒ€ì¥ ìŠ¹ì¸ í›„ ì•Œë¦¼"
Output:
[
  {
    "id": "step-1",
    "type": "QUERY",
    "label": "Aë¼ì¸ ê°€ë™ ì‹œê°„ ì¡°íšŒ",
    "config": {
      "dataSource": "database",
      "query": "SELECT uptime_hours, total_hours FROM equipment_status WHERE line_id = 'A' AND date = CURRENT_DATE",
      "queryType": "sql"
    }
  },
  {
    "id": "step-2",
    "type": "CALC",
    "label": "ê°€ë™ë¥  ê³„ì‚°",
    "config": {
      "formula": "(uptime_hours / total_hours) * 100",
      "outputVariable": "utilization_rate"
    }
  },
  {
    "id": "step-3",
    "type": "JUDGMENT",
    "label": "ê°€ë™ë¥  80% ë¯¸ë§Œ íŒë‹¨",
    "config": {
      "judgmentMethod": "rule",
      "ruleExpression": "utilization_rate < 80"
    }
  },
  {
    "id": "step-4",
    "type": "APPROVAL",
    "label": "ìƒì‚°íŒ€ì¥ ìŠ¹ì¸ ìš”ì²­",
    "config": {
      "approvers": ["production-manager@company.com"],
      "approvalType": "single",
      "timeoutMinutes": 30
    }
  },
  {
    "id": "step-5",
    "type": "ALERT",
    "label": "ê°€ë™ë¥  ì €í•˜ ì•Œë¦¼",
    "config": {
      "channels": ["email", "slack"],
      "recipients": "#production-team",
      "messageTemplate": "âš ï¸ Aë¼ì¸ ê°€ë™ë¥  {utilization_rate}% (80% ë¯¸ë§Œ)"
    }
  }
]

## Example 3: AI í’ˆì§ˆ íŒë‹¨
User: "ì œí’ˆ ì´ë¯¸ì§€ë¡œ ë¶ˆëŸ‰ ì—¬ë¶€ AI íŒë‹¨"
Output:
[
  {
    "id": "step-1",
    "type": "QUERY",
    "label": "ì œí’ˆ ì´ë¯¸ì§€ ì¡°íšŒ",
    "config": {
      "dataSource": "api",
      "endpoint": "https://api.factory.com/products/latest-image",
      "method": "GET"
    }
  },
  {
    "id": "step-2",
    "type": "JUDGMENT",
    "label": "AI ë¶ˆëŸ‰ íŒë‹¨",
    "config": {
      "judgmentMethod": "ai",
      "aiModel": "claude-sonnet-4-5-20250929",
      "prompt": "ë‹¤ìŒ ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë¶ˆëŸ‰ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”. ë¶ˆëŸ‰ì´ë©´ true, ì •ìƒì´ë©´ falseë¥¼ ë°˜í™˜í•˜ì„¸ìš”.",
      "temperature": 0.3
    }
  },
  {
    "id": "step-3",
    "type": "ALERT",
    "label": "ë¶ˆëŸ‰ ê°ì§€ ì•Œë¦¼",
    "config": {
      "channels": ["email"],
      "recipients": "quality-team@company.com",
      "messageTemplate": "ğŸ”´ ë¶ˆëŸ‰ ì œí’ˆ ê°ì§€! AI ì‹ ë¢°ë„: {confidence}%"
    }
  }
]

## Example 4: ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§
User: "ë§¤ì‹œê°„ ì „ì²´ ë¼ì¸ ì˜¨ë„ ì²´í¬"
Output:
[
  {
    "id": "step-1",
    "type": "TRIGGER",
    "label": "ë§¤ì‹œê°„ ì‹¤í–‰ íŠ¸ë¦¬ê±°",
    "config": {
      "triggerType": "schedule",
      "schedule": "0 * * * *"
    }
  },
  {
    "id": "step-2",
    "type": "QUERY",
    "label": "ì „ì²´ ë¼ì¸ ì˜¨ë„ ì¡°íšŒ",
    "config": {
      "dataSource": "database",
      "query": "SELECT line_id, AVG(temperature) as avg_temp FROM sensor_data WHERE timestamp > NOW() - INTERVAL 1 HOUR GROUP BY line_id",
      "queryType": "sql"
    }
  },
  {
    "id": "step-3",
    "type": "JUDGMENT",
    "label": "ì˜¨ë„ ì´ìƒ íŒë‹¨",
    "config": {
      "judgmentMethod": "rule",
      "ruleExpression": "avg_temp > 80 OR avg_temp < 20"
    }
  },
  {
    "id": "step-4",
    "type": "ALERT",
    "label": "ì˜¨ë„ ì´ìƒ ì•Œë¦¼",
    "config": {
      "channels": ["email"],
      "recipients": "maintenance-team@company.com",
      "messageTemplate": "ğŸŒ¡ï¸ ë¼ì¸ {line_id} ì˜¨ë„ ì´ìƒ: {avg_temp}Â°C"
    }
  }
]

## Example 5: ë‹¤ë‹¨ê³„ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤
User: "ì¬ê³  ë¶€ì¡±ì‹œ êµ¬ë§¤ ìš”ì²­ â†’ íŒ€ì¥ ìŠ¹ì¸ â†’ êµ¬ë§¤íŒ€ ì•Œë¦¼"
Output:
[
  {
    "id": "step-1",
    "type": "QUERY",
    "label": "ì¬ê³  ìˆ˜ëŸ‰ ì¡°íšŒ",
    "config": {
      "dataSource": "database",
      "query": "SELECT item_name, quantity, min_threshold FROM inventory WHERE quantity < min_threshold",
      "queryType": "sql"
    }
  },
  {
    "id": "step-2",
    "type": "JUDGMENT",
    "label": "ì¬ê³  ë¶€ì¡± íŒë‹¨",
    "config": {
      "judgmentMethod": "rule",
      "ruleExpression": "quantity < min_threshold"
    }
  },
  {
    "id": "step-3",
    "type": "APPROVAL",
    "label": "êµ¬ë§¤íŒ€ì¥ ìŠ¹ì¸ ìš”ì²­",
    "config": {
      "approvers": ["purchase-manager@company.com"],
      "approvalType": "single",
      "timeoutMinutes": 60,
      "requireComment": true
    }
  },
  {
    "id": "step-4",
    "type": "ALERT",
    "label": "êµ¬ë§¤íŒ€ ì•Œë¦¼",
    "config": {
      "channels": ["email", "slack"],
      "recipients": "#purchase-team",
      "messageTemplate": "ğŸ“¦ ì¬ê³  ë¶€ì¡± êµ¬ë§¤ ìŠ¹ì¸ë¨: {item_name} (í˜„ì¬ {quantity}ê°œ)"
    }
  }
]

Now, generate a workflow based on the user's request."##.to_string()
}

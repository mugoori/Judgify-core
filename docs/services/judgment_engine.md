# íŒë‹¨ ì½”ì–´ ì—”ì§„ ìƒì„¸ ì„¤ê³„ì„œ

**ë¬¸ì„œ ë²„ì „**: v2.0
**ì‘ì„±ì¼**: 2024.08.05
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-30 (Few-shot í•™ìŠµ í†µí•© ì™„ë£Œ)
**ì™„ë£Œìœ¨**: 80% âœ… (Few-shot í†µí•© ì™„ë£Œ, API ë¬¸ì„œí™” ì§„í–‰ ì¤‘)
**ëŒ€ìƒ**: ë°±ì—”ë“œ ê°œë°œì, AI ì—”ì§€ë‹ˆì–´, ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸
**ëª©ì **: Judgment Serviceì˜ ë‚´ë¶€ êµ¬í˜„ ë° í•µì‹¬ íŒë‹¨ ë¡œì§ ì •ì˜

## ğŸ†• Ver2.0 Final ì£¼ìš” ë³€ê²½ì‚¬í•­ (2025-10-30)
- âœ… **Few-shot í•™ìŠµ í†µí•©**: Learning Serviceì™€ ì—°ë™í•˜ì—¬ ìœ ì‚¬ ì‚¬ë¡€ 15ê°œ ìë™ ê²€ìƒ‰
- âœ… **í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ê°œì„ **: Rule Engine â†’ LLM + Few-shot ìˆœì°¨ ì‹¤í–‰
- âœ… **ì‹ ë¢°ë„ í–¥ìƒ**: Few-shot ìƒ˜í”Œ ê°œìˆ˜ì— ë”°ë¥¸ ë™ì  ì‹ ë¢°ë„ ë³´ì •
- âœ… **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: 3ê°œ í•µì‹¬ í…ŒìŠ¤íŠ¸ ì¶”ê°€ (ì´ 28ê°œ í†µê³¼)

## ğŸ“‹ 1. ê°œìš” ë° ì„¤ê³„ ì›ì¹™

### 1.1 í•µì‹¬ ì±…ì„
- **ì›Œí¬í”Œë¡œìš° í•´ì„**: JSON ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¡œì§ìœ¼ë¡œ ë³€í™˜
- **í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨**: Rule ê¸°ë°˜ê³¼ LLM ê¸°ë°˜ íŒë‹¨ì˜ ì¡°í•©
- **ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬**: MCPë¥¼ í†µí•œ ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ë° í™œìš©
- **ì‹ ë¢°ë„ í‰ê°€**: íŒë‹¨ ê²°ê³¼ì˜ ì‹ ë¢°ë„ ì‚°ì¶œ
- **ì„¤ëª… ìƒì„±**: íŒë‹¨ ê·¼ê±°ì™€ ì„¤ëª… ì œê³µ

### 1.2 ì„¤ê³„ ì›ì¹™
```python
# SOLID ì›ì¹™ ì ìš©
# S: ê° í´ë˜ìŠ¤ëŠ” ë‹¨ì¼ ì±…ì„
# O: ìƒˆë¡œìš´ íŒë‹¨ ë°©ì‹ í™•ì¥ ê°€ëŠ¥
# L: íŒë‹¨ ì¸í„°í˜ì´ìŠ¤ ì¼ê´€ì„±
# I: í•„ìš”í•œ ì¸í„°í˜ì´ìŠ¤ë§Œ êµ¬í˜„
# D: ì˜ì¡´ì„± ì—­ì „ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ìš©ì´ì„± í™•ë³´
```

## ğŸ— 2. ì•„í‚¤í…ì²˜ êµ¬ì¡°

### 2.1 ì»´í¬ë„ŒíŠ¸ ë‹¤ì´ì–´ê·¸ë¨
```mermaid
graph TB
    subgraph "Judgment Service"
        DISPATCHER[Judgment Dispatcher]
        EXECUTOR[Workflow Executor]
        
        subgraph "Judgment Engines"
            RULE[Rule Engine]
            LLM[LLM Engine]
            HYBRID[Hybrid Engine]
        end
        
        subgraph "Support Components"
            CONTEXT[Context Manager]
            VALIDATOR[Input Validator]
            EXPLAINER[Explanation Generator]
        end
    end
    
    subgraph "External Dependencies"
        MCP[MCP Client]
        OPENAI[OpenAI API]
        DB[(PostgreSQL)]
        CACHE[(Redis)]
    end
    
    DISPATCHER --> EXECUTOR
    EXECUTOR --> RULE
    EXECUTOR --> LLM
    EXECUTOR --> HYBRID
    
    CONTEXT --> MCP
    LLM --> OPENAI
    EXPLAINER --> OPENAI
    
    EXECUTOR --> DB
    CONTEXT --> CACHE
```

### 2.2 í•µì‹¬ í´ë˜ìŠ¤ êµ¬ì¡°
```python
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional
from pydantic import BaseModel
from enum import Enum


class JudgmentMethod(str, Enum):
    RULE = "rule"
    LLM = "llm"
    HYBRID = "hybrid"


class JudgmentInput(BaseModel):
    workflow_id: str
    input_data: Dict[str, Any]
    context: Optional[Dict[str, Any]] = None
    method: Optional[JudgmentMethod] = None


class JudgmentResult(BaseModel):
    result: Any
    confidence: float
    method_used: JudgmentMethod
    execution_time_ms: int
    explanation: Optional[str] = None
    error: Optional[str] = None


class JudgmentEngine(ABC):
    """íŒë‹¨ ì—”ì§„ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def judge(self, input_data: JudgmentInput) -> JudgmentResult:
        pass
    
    @abstractmethod
    def validate_input(self, input_data: JudgmentInput) -> bool:
        pass
class DashboardGenerationEngine:
    """ëŒ€ì‹œë³´ë“œ ìë™ ìƒì„± ì—”ì§„"""
    
    def __init__(self, llm_client, data_analyzer):
        self.llm_client = llm_client
        self.data_analyzer = data_analyzer
        self.component_generator = ComponentGenerator()
        
    async def generate_dashboard(self, request: str, context: dict):
        # êµ¬í˜„ ë¡œì§
        pass
```

## ğŸ”§ 3. Rule Engine ìƒì„¸ êµ¬í˜„

### 3.1 ì•ˆì „í•œ Rule DSL íŒŒì„œ
```python
import ast
import operator
from typing import Any, Dict, Set


class SafeRuleEngine(JudgmentEngine):
    """AST ê¸°ë°˜ ì•ˆì „í•œ Rule ì‹¤í–‰ ì—”ì§„"""
    
    # í—ˆìš©ëœ ì—°ì‚°ì ì •ì˜
    ALLOWED_OPERATORS = {
        ast.Gt: operator.gt,
        ast.Lt: operator.lt,
        ast.GtE: operator.ge,
        ast.LtE: operator.le,
        ast.Eq: operator.eq,
        ast.NotEq: operator.ne,
        ast.And: operator.and_,
        ast.Or: operator.or_,
        ast.Not: operator.not_,
        ast.In: lambda x, y: x in y,
        ast.NotIn: lambda x, y: x not in y,
    }
    
    # í—ˆìš©ëœ í•¨ìˆ˜
    ALLOWED_FUNCTIONS = {
        'abs': abs,
        'min': min,
        'max': max,
        'len': len,
        'round': round,
    }
    
    def __init__(self):
        self.variables: Dict[str, Any] = {}
    
    async def judge(self, input_data: JudgmentInput) -> JudgmentResult:
        start_time = time.time()
        
        try:
            # ì›Œí¬í”Œë¡œìš°ì—ì„œ ê·œì¹™ ì¶”ì¶œ
            workflow = await self.get_workflow(input_data.workflow_id)
            rule_expression = workflow.get('rule_expression')
            
            if not rule_expression:
                raise ValueError("Rule expression not found in workflow")
            
            # ë³€ìˆ˜ ë°”ì¸ë”©
            self.variables = input_data.input_data.copy()
            if input_data.context:
                self.variables.update(input_data.context)
            
            # ê·œì¹™ ì‹¤í–‰
            result = self._evaluate_expression(rule_expression)
            
            execution_time = int((time.time() - start_time) * 1000)
            
            return JudgmentResult(
                result=result,
                confidence=1.0,  # Rule ê¸°ë°˜ì€ í•­ìƒ í™•ì‹ 
                method_used=JudgmentMethod.RULE,
                execution_time_ms=execution_time,
                explanation=f"Rule '{rule_expression}' evaluated to {result}"
            )
            
        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)
            return JudgmentResult(
                result=None,
                confidence=0.0,
                method_used=JudgmentMethod.RULE,
                execution_time_ms=execution_time,
                error=str(e)
            )
    
    def _evaluate_expression(self, expression: str) -> Any:
        """ASTë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ í‘œí˜„ì‹ í‰ê°€"""
        try:
            tree = ast.parse(expression, mode='eval')
            return self._evaluate_node(tree.body)
        except SyntaxError as e:
            raise ValueError(f"Invalid syntax in rule expression: {e}")
    
    def _evaluate_node(self, node: ast.AST) -> Any:
        """AST ë…¸ë“œ ì¬ê·€ì  í‰ê°€"""
        if isinstance(node, ast.Constant):
            return node.value
        
        elif isinstance(node, ast.Name):
            if node.id in self.variables:
                return self.variables[node.id]
            else:
                raise NameError(f"Variable '{node.id}' is not defined")
        
        elif isinstance(node, ast.BinOp):
            left = self._evaluate_node(node.left)
            right = self._evaluate_node(node.right)
            op_func = self.ALLOWED_OPERATORS.get(type(node.op))
            
            if op_func:
                return op_func(left, right)
            else:
                raise ValueError(f"Operator {type(node.op)} not allowed")
        
        elif isinstance(node, ast.Compare):
            left = self._evaluate_node(node.left)
            
            for op, comparator in zip(node.ops, node.comparators):
                right = self._evaluate_node(comparator)
                op_func = self.ALLOWED_OPERATORS.get(type(op))
                
                if not op_func:
                    raise ValueError(f"Comparison {type(op)} not allowed")
                
                if not op_func(left, right):
                    return False
                left = right
            
            return True
        
        elif isinstance(node, ast.BoolOp):
            op_func = self.ALLOWED_OPERATORS.get(type(node.op))
            if not op_func:
                raise ValueError(f"Boolean operator {type(node.op)} not allowed")
            
            values = [self._evaluate_node(value) for value in node.values]
            
            if isinstance(node.op, ast.And):
                return all(values)
            elif isinstance(node.op, ast.Or):
                return any(values)
        
        elif isinstance(node, ast.UnaryOp):
            operand = self._evaluate_node(node.operand)
            op_func = self.ALLOWED_OPERATORS.get(type(node.op))
            
            if op_func:
                return op_func(operand)
            else:
                raise ValueError(f"Unary operator {type(node.op)} not allowed")
        
        elif isinstance(node, ast.Call):
            func_name = node.func.id if isinstance(node.func, ast.Name) else None
            
            if func_name in self.ALLOWED_FUNCTIONS:
                args = [self._evaluate_node(arg) for arg in node.args]
                return self.ALLOWED_FUNCTIONS[func_name](*args)
            else:
                raise ValueError(f"Function '{func_name}' not allowed")
        
        elif isinstance(node, ast.List):
            return [self._evaluate_node(item) for item in node.elts]
        
        else:
            raise ValueError(f"Node type {type(node)} not supported")
    
    def validate_input(self, input_data: JudgmentInput) -> bool:
        """ì…ë ¥ ë°ì´í„° ê²€ì¦"""
        required_fields = self._extract_variables_from_workflow(
            input_data.workflow_id
        )
        
        for field in required_fields:
            if field not in input_data.input_data:
                return False
        
        return True
    
    def _extract_variables_from_workflow(self, workflow_id: str) -> Set[str]:
        """ì›Œí¬í”Œë¡œìš°ì—ì„œ í•„ìš”í•œ ë³€ìˆ˜ ì¶”ì¶œ"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì›Œí¬í”Œë¡œìš° ì •ì˜ë¥¼ íŒŒì‹±í•˜ì—¬ ë³€ìˆ˜ ì¶”ì¶œ
        return set()
```

### 3.2 Rule DSL ì˜ˆì‹œ
```python
# ì§€ì›í•˜ëŠ” Rule í‘œí˜„ì‹ ì˜ˆì‹œ
RULE_EXAMPLES = {
    "simple_comparison": "temperature > 85",
    "multiple_conditions": "temperature > 85 and vibration > 40",
    "range_check": "temperature >= 80 and temperature <= 100",
    "list_membership": "status in ['ERROR', 'WARNING']",
    "function_usage": "abs(pressure - target_pressure) > threshold",
    "complex_logic": "(temperature > 85 or pressure > 100) and status != 'MAINTENANCE'"
}
```

## ğŸ¤– 4. LLM Engine ìƒì„¸ êµ¬í˜„

### 4.1 LLM íŒë‹¨ ì—”ì§„
```python
import openai
import json
from typing import Dict, Any
import asyncio


class LLMJudgmentEngine(JudgmentEngine):
    """OpenAI API ê¸°ë°˜ LLM íŒë‹¨ ì—”ì§„"""
    
    def __init__(self, api_key: str, model: str = "gpt-4"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model
        self.max_retries = 3
        self.timeout = 30
    
    async def judge(self, input_data: JudgmentInput) -> JudgmentResult:
        start_time = time.time()
        
        try:
            # ì›Œí¬í”Œë¡œìš°ì—ì„œ íŒë‹¨ ê¸°ì¤€ ì¶”ì¶œ
            workflow = await self.get_workflow(input_data.workflow_id)
            judgment_criteria = workflow.get('llm_criteria', '')
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = await self._build_judgment_prompt(
                input_data.input_data,
                input_data.context or {},
                judgment_criteria
            )
            
            # LLM í˜¸ì¶œ
            response = await self._call_llm_with_retry(prompt)
            
            # ì‘ë‹µ íŒŒì‹±
            parsed_result = self._parse_llm_response(response)
            
            execution_time = int((time.time() - start_time) * 1000)
            
            return JudgmentResult(
                result=parsed_result['result'],
                confidence=parsed_result.get('confidence', 0.5),
                method_used=JudgmentMethod.LLM,
                execution_time_ms=execution_time,
                explanation=parsed_result.get('explanation', '')
            )
            
        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)
            return JudgmentResult(
                result=None,
                confidence=0.0,
                method_used=JudgmentMethod.LLM,
                execution_time_ms=execution_time,
                error=str(e)
            )
    
    async def _build_judgment_prompt(
        self, 
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        criteria: str
    ) -> str:
        """íŒë‹¨ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt_template = """
ë‹¹ì‹ ì€ ì œì¡°ì—… í˜„ì¥ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ íŒë‹¨ì„ ë‚´ë ¤ì£¼ì„¸ìš”.

## ì…ë ¥ ë°ì´í„°
{input_data_formatted}

## ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
{context_formatted}

## íŒë‹¨ ê¸°ì¤€
{criteria}

## ì‘ë‹µ í˜•ì‹
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "result": true/false ë˜ëŠ” êµ¬ì²´ì ì¸ ê°’,
    "confidence": 0.0~1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„,
    "explanation": "íŒë‹¨ ê·¼ê±°ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…"
}}

íŒë‹¨ì„ ë‚´ë ¤ì£¼ì„¸ìš”:
        """.strip()
        
        input_data_formatted = json.dumps(input_data, indent=2, ensure_ascii=False)
        context_formatted = json.dumps(context, indent=2, ensure_ascii=False)
        
        return prompt_template.format(
            input_data_formatted=input_data_formatted,
            context_formatted=context_formatted,
            criteria=criteria
        )
    
    async def _call_llm_with_retry(self, prompt: str) -> str:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ LLM í˜¸ì¶œ"""
        
        for attempt in range(self.max_retries):
            try:
                response = await asyncio.wait_for(
                    self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {
                                "role": "system", 
                                "content": "ë‹¹ì‹ ì€ ì œì¡°ì—… í˜„ì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íŒë‹¨ì„ ë‚´ë ¤ì£¼ì„¸ìš”."
                            },
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.1,
                        max_tokens=500
                    ),
                    timeout=self.timeout
                )
                
                return response.choices[0].message.content
                
            except asyncio.TimeoutError:
                if attempt == self.max_retries - 1:
                    raise TimeoutError("LLM response timeout")
                await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise e
                await asyncio.sleep(1)
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µ íŒŒì‹± ë° ê²€ì¦"""
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            if response.strip().startswith('{'):
                parsed = json.loads(response)
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if 'result' not in parsed:
                    raise ValueError("Missing 'result' field in LLM response")
                
                # ì‹ ë¢°ë„ ê²€ì¦
                confidence = parsed.get('confidence', 0.5)
                if not 0 <= confidence <= 1:
                    parsed['confidence'] = 0.5
                
                return parsed
            
            else:
                # JSONì´ ì•„ë‹Œ ê²½ìš° íœ´ë¦¬ìŠ¤í‹± íŒŒì‹±
                return self._heuristic_parse(response)
                
        except json.JSONDecodeError:
            return self._heuristic_parse(response)
    
    def _heuristic_parse(self, response: str) -> Dict[str, Any]:
        """JSONì´ ì•„ë‹Œ ì‘ë‹µì— ëŒ€í•œ íœ´ë¦¬ìŠ¤í‹± íŒŒì‹±"""
        
        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ê²€ìƒ‰
        positive_keywords = ['yes', 'true', 'í•„ìš”', 'í•´ì•¼', 'ê¶Œì¥']
        negative_keywords = ['no', 'false', 'ë¶ˆí•„ìš”', 'ì•Šì•„ë„', 'ê¶Œì¥í•˜ì§€']
        
        response_lower = response.lower()
        
        positive_score = sum(1 for keyword in positive_keywords if keyword in response_lower)
        negative_score = sum(1 for keyword in negative_keywords if keyword in response_lower)
        
        if positive_score > negative_score:
            result = True
            confidence = min(0.9, 0.5 + positive_score * 0.1)
        elif negative_score > positive_score:
            result = False
            confidence = min(0.9, 0.5 + negative_score * 0.1)
        else:
            result = None
            confidence = 0.3
        
        return {
            'result': result,
            'confidence': confidence,
            'explanation': response[:200] + '...' if len(response) > 200 else response
        }
    
    def validate_input(self, input_data: JudgmentInput) -> bool:
        """LLM ì…ë ¥ ê²€ì¦"""
        # ê¸°ë³¸ì ì¸ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
        return bool(input_data.input_data)
```

## ğŸ”„ 5. Hybrid Engine êµ¬í˜„

### 5.1 í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ë¡œì§
```python
class HybridJudgmentEngine(JudgmentEngine):
    """Ruleê³¼ LLMì„ ì¡°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ íŒë‹¨ ì—”ì§„"""
    
    def __init__(self, rule_engine: SafeRuleEngine, llm_engine: LLMJudgmentEngine):
        self.rule_engine = rule_engine
        self.llm_engine = llm_engine
    
    async def judge(self, input_data: JudgmentInput) -> JudgmentResult:
        start_time = time.time()
        
        try:
            workflow = await self.get_workflow(input_data.workflow_id)
            strategy = workflow.get('hybrid_strategy', 'rule_first')
            
            if strategy == 'rule_first':
                return await self._rule_first_strategy(input_data)
            elif strategy == 'llm_first':
                return await self._llm_first_strategy(input_data)
            elif strategy == 'parallel':
                return await self._parallel_strategy(input_data)
            elif strategy == 'consensus':
                return await self._consensus_strategy(input_data)
            else:
                raise ValueError(f"Unknown hybrid strategy: {strategy}")
                
        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)
            return JudgmentResult(
                result=None,
                confidence=0.0,
                method_used=JudgmentMethod.HYBRID,
                execution_time_ms=execution_time,
                error=str(e)
            )
    
    async def _rule_first_strategy(self, input_data: JudgmentInput) -> JudgmentResult:
        """Rule ìš°ì„  ì „ëµ: Rule ì‹¤íŒ¨ì‹œì—ë§Œ LLM ì‚¬ìš©"""
        
        # Rule ì‹œë„
        rule_result = await self.rule_engine.judge(input_data)
        
        if rule_result.error is None:
            # Rule ì„±ê³µ
            rule_result.method_used = JudgmentMethod.HYBRID
            rule_result.explanation = f"Rule-based: {rule_result.explanation}"
            return rule_result
        
        # Rule ì‹¤íŒ¨ì‹œ LLM ì‚¬ìš©
        llm_input = input_data.model_copy()
        llm_input.context = llm_input.context or {}
        llm_input.context['rule_error'] = rule_result.error
        
        llm_result = await self.llm_engine.judge(llm_input)
        llm_result.method_used = JudgmentMethod.HYBRID
        llm_result.explanation = f"LLM-based (Rule failed): {llm_result.explanation}"
        
        return llm_result
    
    async def _consensus_strategy(self, input_data: JudgmentInput) -> JudgmentResult:
        """í•©ì˜ ì „ëµ: Ruleê³¼ LLM ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒë‹¨"""
        
        # ë³‘ë ¬ ì‹¤í–‰
        rule_task = asyncio.create_task(self.rule_engine.judge(input_data))
        llm_task = asyncio.create_task(self.llm_engine.judge(input_data))
        
        rule_result, llm_result = await asyncio.gather(rule_task, llm_task)
        
        # ê²°ê³¼ ë¶„ì„
        if rule_result.error and llm_result.error:
            # ë‘˜ ë‹¤ ì‹¤íŒ¨
            return JudgmentResult(
                result=None,
                confidence=0.0,
                method_used=JudgmentMethod.HYBRID,
                execution_time_ms=rule_result.execution_time_ms + llm_result.execution_time_ms,
                error="Both rule and LLM engines failed"
            )
        
        elif rule_result.error:
            # Rule ì‹¤íŒ¨, LLM ì„±ê³µ
            llm_result.method_used = JudgmentMethod.HYBRID
            return llm_result
        
        elif llm_result.error:
            # LLM ì‹¤íŒ¨, Rule ì„±ê³µ
            rule_result.method_used = JudgmentMethod.HYBRID
            return rule_result
        
        else:
            # ë‘˜ ë‹¤ ì„±ê³µ - í•©ì˜ ì•Œê³ ë¦¬ì¦˜ ì ìš©
            return self._merge_results(rule_result, llm_result)
    
    def _merge_results(self, rule_result: JudgmentResult, llm_result: JudgmentResult) -> JudgmentResult:
        """Ruleê³¼ LLM ê²°ê³¼ ë³‘í•©"""
        
        # ê²°ê³¼ê°€ ë™ì¼í•œ ê²½ìš°
        if rule_result.result == llm_result.result:
            combined_confidence = (rule_result.confidence + llm_result.confidence) / 2
            combined_confidence = min(combined_confidence * 1.2, 1.0)  # í•©ì˜ ë³´ë„ˆìŠ¤
            
            return JudgmentResult(
                result=rule_result.result,
                confidence=combined_confidence,
                method_used=JudgmentMethod.HYBRID,
                execution_time_ms=rule_result.execution_time_ms + llm_result.execution_time_ms,
                explanation=f"Consensus: Rule({rule_result.result}) + LLM({llm_result.result})"
            )
        
        # ê²°ê³¼ê°€ ë‹¤ë¥¸ ê²½ìš° - ì‹ ë¢°ë„ ê¸°ë°˜ ì„ íƒ
        else:
            if rule_result.confidence > llm_result.confidence:
                chosen_result = rule_result
                explanation = f"Rule-preferred: Rule({rule_result.confidence:.2f}) > LLM({llm_result.confidence:.2f})"
            else:
                chosen_result = llm_result
                explanation = f"LLM-preferred: LLM({llm_result.confidence:.2f}) > Rule({rule_result.confidence:.2f})"
            
            chosen_result.method_used = JudgmentMethod.HYBRID
            chosen_result.explanation = explanation
            chosen_result.execution_time_ms = rule_result.execution_time_ms + llm_result.execution_time_ms
            
            return chosen_result
    
    def validate_input(self, input_data: JudgmentInput) -> bool:
        """í•˜ì´ë¸Œë¦¬ë“œ ì…ë ¥ ê²€ì¦"""
        return (self.rule_engine.validate_input(input_data) or 
                self.llm_engine.validate_input(input_data))
```

## ğŸ“Š 6. Context Manager êµ¬í˜„

### 6.1 MCP ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
```python
from typing import Dict, Any, List
import aiohttp


class MCPContextManager:
    """MCP(Model Context Protocol)ë¥¼ í†µí•œ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
    
    def __init__(self, mcp_servers: List[Dict[str, str]]):
        self.mcp_servers = mcp_servers
        self.cache_ttl = 300  # 5ë¶„ ìºì‹œ
    
    async def gather_context(self, workflow_id: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš°ì™€ ì…ë ¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        
        workflow = await self.get_workflow(workflow_id)
        required_context = workflow.get('required_context', [])
        
        context = {}
        
        for context_req in required_context:
            context_type = context_req.get('type')
            
            if context_type == 'machine_status':
                machine_id = input_data.get('machine_id')
                if machine_id:
                    context['machine_status'] = await self._get_machine_status(machine_id)
            
            elif context_type == 'historical_data':
                context['historical_data'] = await self._get_historical_data(
                    context_req.get('timeframe', '1h'),
                    input_data
                )
            
            elif context_type == 'policy_documents':
                context['policies'] = await self._get_relevant_policies(
                    context_req.get('category', 'safety')
                )
        
        return context
    
    async def _get_machine_status(self, machine_id: str) -> Dict[str, Any]:
        """MCPë¥¼ í†µí•œ ê¸°ê³„ ìƒíƒœ ì¡°íšŒ"""
        
        mcp_request = {
            "method": "tools/call",
            "params": {
                "name": "get_machine_status",
                "arguments": {"machine_id": machine_id}
            }
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                for server in self.mcp_servers:
                    try:
                        async with session.post(
                            f"{server['url']}/mcp",
                            json=mcp_request,
                            headers={"Authorization": f"Bearer {server['token']}"}
                        ) as response:
                            if response.status == 200:
                                result = await response.json()
                                return result.get('content', {})
                    except Exception:
                        continue
            
            return {"status": "unknown", "error": "No MCP server available"}
            
        except Exception as e:
            return {"status": "error", "message": str(e)}
    
    async def _get_historical_data(self, timeframe: str, input_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê³¼ê±° ë°ì´í„° ì¡°íšŒ"""
        
        # ìºì‹œ í™•ì¸
        cache_key = f"historical:{timeframe}:{hash(str(input_data))}"
        cached_data = await self._get_from_cache(cache_key)
        
        if cached_data:
            return cached_data
        
        # MCPë¥¼ í†µí•œ ë°ì´í„° ì¡°íšŒ
        mcp_request = {
            "method": "tools/call",
            "params": {
                "name": "query_historical_data",
                "arguments": {
                    "timeframe": timeframe,
                    "filters": input_data
                }
            }
        }
        
        async def gather_dashboard_context(self, user_request: str):
        """ëŒ€ì‹œë³´ë“œ ìƒì„±ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        context = {}
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìˆ˜ì§‘
        context['available_schemas'] = await self.get_data_schemas()
        
        # ìµœê·¼ ë°ì´í„° ìƒ˜í”Œ ìˆ˜ì§‘
        context['sample_data'] = await self.get_sample_data()
        
        # ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ë¶„ì„
        context['user_preferences'] = await self.analyze_user_history()
        
        return context
        # ì‹¤ì œ êµ¬í˜„ì€ ìœ„ì™€ ë™ì¼í•œ íŒ¨í„´
        # ...
        
        return []
```

## ğŸ” 7. ì„¤ëª… ìƒì„±ê¸° (Explainer)

### 7.1 íŒë‹¨ ì„¤ëª… ìƒì„±
```python
class JudgmentExplainer:
    """íŒë‹¨ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª… ìƒì„±"""
    
    def __init__(self, llm_client: openai.AsyncOpenAI):
        self.llm_client = llm_client
    
    async def generate_explanation(
        self, 
        judgment_result: JudgmentResult,
        input_data: JudgmentInput,
        context: Dict[str, Any]
    ) -> str:
        """ìƒì„¸í•œ íŒë‹¨ ì„¤ëª… ìƒì„±"""
        
        if judgment_result.method_used == JudgmentMethod.RULE:
            return self._explain_rule_result(judgment_result, input_data)
        
        elif judgment_result.method_used == JudgmentMethod.LLM:
            return await self._enhance_llm_explanation(judgment_result, input_data, context)
        
        else:  # HYBRID
            return await self._explain_hybrid_result(judgment_result, input_data, context)
    
    def _explain_rule_result(self, result: JudgmentResult, input_data: JudgmentInput) -> str:
        """Rule ê¸°ë°˜ íŒë‹¨ ì„¤ëª…"""
        
        explanation = f"""
## ê·œì¹™ ê¸°ë°˜ íŒë‹¨ ê²°ê³¼

**íŒë‹¨ ê²°ê³¼**: {result.result}
**ì‹ ë¢°ë„**: {result.confidence:.2f}
**ì‹¤í–‰ ì‹œê°„**: {result.execution_time_ms}ms

### ì ìš©ëœ ê·œì¹™
{result.explanation}

### ì…ë ¥ ë°ì´í„°
{json.dumps(input_data.input_data, indent=2, ensure_ascii=False)}

### íŒë‹¨ ê³¼ì •
ê·œì¹™ ì—”ì§„ì´ ì •ì˜ëœ ì¡°ê±´ì‹ì„ í‰ê°€í•˜ì—¬ ëª…í™•í•œ ê²°ê³¼ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.
ê·œì¹™ ê¸°ë°˜ íŒë‹¨ì€ ì¼ê´€ì„±ì´ ë†’ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """.strip()
        
        return explanation
    
    async def _enhance_llm_explanation(
        self, 
        result: JudgmentResult, 
        input_data: JudgmentInput,
        context: Dict[str, Any]
    ) -> str:
        """LLM ì„¤ëª… í–¥ìƒ"""
        
        prompt = f"""
ë‹¤ìŒ AI íŒë‹¨ ê²°ê³¼ì— ëŒ€í•´ ë” ìƒì„¸í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.

## íŒë‹¨ ê²°ê³¼
- ê²°ê³¼: {result.result}
- ì‹ ë¢°ë„: {result.confidence:.2f}
- ê¸°ì¡´ ì„¤ëª…: {result.explanation}

## ì…ë ¥ ë°ì´í„°
{json.dumps(input_data.input_data, indent=2, ensure_ascii=False)}

## ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
{json.dumps(context, indent=2, ensure_ascii=False)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. íŒë‹¨ ìš”ì•½
2. í•µì‹¬ ê·¼ê±°
3. ê³ ë ¤ëœ ìš”ì¸ë“¤
4. ì‹ ë¢°ë„ í‰ê°€ ì´ìœ 
5. ê¶Œì¥ ì¡°ì¹˜ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)
        """
        
        try:
            response = await self.llm_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì œì¡°ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íŒë‹¨ ê²°ê³¼ë¥¼ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\nì›ë³¸ ì„¤ëª…: {result.explanation}"
```

## ğŸ§ª 8. í…ŒìŠ¤íŠ¸ ì „ëµ

### 8.1 ìœ ë‹› í…ŒìŠ¤íŠ¸
```python
import pytest
from unittest.mock import Mock, AsyncMock


class TestSafeRuleEngine:
    
    @pytest.fixture
    def rule_engine(self):
        return SafeRuleEngine()
    
    @pytest.mark.asyncio
    async def test_simple_comparison(self, rule_engine):
        """ê°„ë‹¨í•œ ë¹„êµ ì—°ì‚° í…ŒìŠ¤íŠ¸"""
        
        rule_engine.variables = {"temperature": 90}
        result = rule_engine._evaluate_expression("temperature > 85")
        
        assert result is True
    
    @pytest.mark.asyncio
    async def test_complex_logic(self, rule_engine):
        """ë³µí•© ë…¼ë¦¬ ì—°ì‚° í…ŒìŠ¤íŠ¸"""
        
        rule_engine.variables = {
            "temperature": 90,
            "pressure": 95,
            "status": "RUNNING"
        }
        
        result = rule_engine._evaluate_expression(
            "(temperature > 85 or pressure > 100) and status != 'MAINTENANCE'"
        )
        
        assert result is True
    
    @pytest.mark.asyncio
    async def test_security_injection(self, rule_engine):
        """ë³´ì•ˆ ì·¨ì•½ì  í…ŒìŠ¤íŠ¸"""
        
        with pytest.raises(ValueError):
            rule_engine._evaluate_expression("__import__('os').system('rm -rf /')")
        
        with pytest.raises(ValueError):
            rule_engine._evaluate_expression("exec('print(1)')")


class TestLLMJudgmentEngine:
    
    @pytest.fixture
    def llm_engine(self):
        mock_client = AsyncMock()
        engine = LLMJudgmentEngine("test-key")
        engine.client = mock_client
        return engine
    
    @pytest.mark.asyncio
    async def test_successful_judgment(self, llm_engine):
        """LLM íŒë‹¨ ì„±ê³µ ì¼€ì´ìŠ¤"""
        
        # Mock LLM ì‘ë‹µ
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = '{"result": true, "confidence": 0.85, "explanation": "Temperature exceeds threshold"}'
        
        llm_engine.client.chat.completions.create.return_value = mock_response
        
        input_data = JudgmentInput(
            workflow_id="test-workflow",
            input_data={"temperature": 90}
        )
        
        result = await llm_engine.judge(input_data)
        
        assert result.result is True
        assert result.confidence == 0.85
        assert result.method_used == JudgmentMethod.LLM
        assert result.error is None
```

## ğŸ“ˆ 9. ì„±ëŠ¥ ìµœì í™”

### 9.1 ìºì‹± ì „ëµ
```python
class CachedJudgmentService:
    """ìºì‹±ì´ ì ìš©ëœ íŒë‹¨ ì„œë¹„ìŠ¤"""
    
    def __init__(self, redis_client, judgment_engine):
        self.redis = redis_client
        self.engine = judgment_engine
        self.cache_ttl = 300  # 5ë¶„
    
    async def judge_with_cache(self, input_data: JudgmentInput) -> JudgmentResult:
        """ìºì‹œë¥¼ ê³ ë ¤í•œ íŒë‹¨ ì‹¤í–‰"""
        
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._generate_cache_key(input_data)
        
        # ìºì‹œ í™•ì¸
        cached_result = await self.redis.get(cache_key)
        if cached_result:
            return JudgmentResult.parse_raw(cached_result)
        
        # ì‹¤ì œ íŒë‹¨ ì‹¤í–‰
        result = await self.engine.judge(input_data)
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ ìºì‹œ
        if result.error is None:
            await self.redis.setex(
                cache_key, 
                self.cache_ttl, 
                result.json()
            )
        
        return result
    
    def _generate_cache_key(self, input_data: JudgmentInput) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        
        # ì…ë ¥ ë°ì´í„°ì˜ í•´ì‹œê°’ìœ¼ë¡œ í‚¤ ìƒì„±
        data_hash = hash(str(sorted(input_data.input_data.items())))
        return f"judgment:{input_data.workflow_id}:{data_hash}"
```

ì´ ì„¤ê³„ì„œëŠ” ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ ìƒì„¸í•œ ê¸°ìˆ  ëª…ì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ìŒ ë¬¸ì„œì¸ "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë° API ì„¤ê³„ì„œ"ë¥¼ ì‘ì„±í• ê¹Œìš”?
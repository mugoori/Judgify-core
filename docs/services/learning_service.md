# Learning Service ìƒì„¸ ì„¤ê³„ (Port 8009, Ver2.0 Final) ğŸ”¥

**ì™„ë£Œìœ¨**: 100% âœ… (2025-10-30 ì™„ì„±)
**ìƒíƒœ**: âœ… Rule ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€ ì™„ë£Œ, 3ê°œ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ì™„ë£Œ (ë¹ˆë„ ë¶„ì„ + LLM íŒ¨í„´ ë°œê²¬), í…ŒìŠ¤íŠ¸ 25ê°œ í†µê³¼

## 1. ê°œìš”

### 1.1 ì„œë¹„ìŠ¤ ëª©ì 
Learning ServiceëŠ” **ì „í†µì  ML ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ML ëª¨ë¸ì„ ì™„ì „ ëŒ€ì²´**í•˜ëŠ” í˜ì‹ ì ì¸ ìë™í•™ìŠµ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ Ruleì„ ì¶”ì¶œí•˜ê³ , Few-shot í•™ìŠµì„ í†µí•´ íŒë‹¨ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### 1.2 í•µì‹¬ ê¸°ëŠ¥
1. **3ê°€ì§€ Rule ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜**: ë¹ˆë„ ë¶„ì„, ê²°ì • íŠ¸ë¦¬, LLM íŒ¨í„´ ë°œê²¬
2. **Few-shot í•™ìŠµ ê´€ë¦¬**: pgvector ê¸°ë°˜ ìœ ì‚¬ ìƒ˜í”Œ 10-20ê°œ ìë™ ê²€ìƒ‰
3. **í”¼ë“œë°± ìˆ˜ì§‘**: ğŸ‘ğŸ‘, LOG ë¦¬ë·°, ì±„íŒ… í”¼ë“œë°± í†µí•© ê´€ë¦¬
4. **ì„±ëŠ¥ ê²€ì¦**: ì¶”ì¶œëœ Ruleì˜ ì •í™•ë„ ë° ì‹ ë¢°ë„ ìë™ ê²€ì¦

### 1.3 ML ëª¨ë¸ ë¯¸ì‚¬ìš© ì´ìœ 
- **í•´ì„ ê°€ëŠ¥ì„±**: Ruleì€ ëª…í™•í•œ ì¡°ê±´ì‹ìœ¼ë¡œ ì‚¬ëŒì´ ì´í•´ ê°€ëŠ¥
- **ìœ ì§€ë³´ìˆ˜ì„±**: ëª¨ë¸ ì¬í•™ìŠµ ì—†ì´ Rule ìˆ˜ì • ê°€ëŠ¥
- **ë¹„ìš© íš¨ìœ¨ì„±**: ê³ ê°€ì˜ GPU ì„œë²„ ë¶ˆí•„ìš”, ë‹¨ìˆœ CPUë¡œ ì²˜ë¦¬
- **ì¦‰ì‹œ ì ìš©ì„±**: í•™ìŠµ ì™„ë£Œ ì¦‰ì‹œ Ruleë¡œ ë³€í™˜í•˜ì—¬ ì›Œí¬í”Œë¡œìš°ì— ì ìš©

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 ì„œë¹„ìŠ¤ êµ¬ì¡°
```
Learning Service (Port 8009)
â”œâ”€â”€ Feedback Collection Engine    â† ğŸ‘ğŸ‘, LOG, ì±„íŒ… í”¼ë“œë°± ìˆ˜ì§‘
â”œâ”€â”€ Rule Extraction Engine         â† 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ë³‘ë ¬ ì‹¤í–‰
â”‚   â”œâ”€â”€ Frequency Analysis         (ë¹ˆë„ ë¶„ì„)
â”‚   â”œâ”€â”€ Decision Tree Converter    (ê²°ì • íŠ¸ë¦¬)
â”‚   â””â”€â”€ LLM Pattern Discovery      (LLM íŒ¨í„´ ë°œê²¬)
â”œâ”€â”€ Few-shot Sample Manager        â† pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (10-20ê°œ)
â”œâ”€â”€ Rule Validation Engine         â† ì¶”ì¶œ Rule ì •í™•ë„ ê²€ì¦
â””â”€â”€ REST API (FastAPI)             â† ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™
```

### 2.2 ë°ì´í„° íë¦„
```
ì‚¬ìš©ì í”¼ë“œë°± (ğŸ‘ğŸ‘/LOG/ì±„íŒ…)
    â†“
Feedback Collection Engine (ìµœì†Œ 50ê°œ ìˆ˜ì§‘)
    â†“
3ê°€ì§€ Rule ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ ë³‘ë ¬ ì‹¤í–‰
    â”œâ”€â”€ Frequency Analysis â†’ Rule í›„ë³´ 1
    â”œâ”€â”€ Decision Tree â†’ Rule í›„ë³´ 2
    â””â”€â”€ LLM Pattern â†’ Rule í›„ë³´ 3
    â†“
Rule Validation (ì •í™•ë„ ê²€ì¦, ì‹ ë¢°ë„ ë¹„êµ)
    â†“
ìµœì  Rule ì„ íƒ (ì‹ ë¢°ë„ ê°€ì¥ ë†’ì€ Rule)
    â†“
Workflow Serviceì— Rule ë“±ë¡
    â†“
Few-shot Sample Manager (íŒë‹¨ì‹œ ìœ ì‚¬ ìƒ˜í”Œ 10-20ê°œ ì œê³µ)
```

### 2.3 ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™
```yaml
ì…ë ¥ ì˜ì¡´ì„±:
  - Judgment Service (8002): íŒë‹¨ ì‹¤í–‰ ê²°ê³¼ + í”¼ë“œë°± ë°ì´í„°
  - Chat Interface (8008): ì±„íŒ… ê¸°ë°˜ í”¼ë“œë°± ìˆ˜ì§‘
  - PostgreSQL: raw_data, judgment_executions í…Œì´ë¸”

ì¶œë ¥ ì˜ì¡´ì„±:
  - Workflow Service (8001): ì¶”ì¶œëœ Rule ìë™ ë“±ë¡
  - Judgment Service (8002): Few-shot ìƒ˜í”Œ ì œê³µ (ìœ ì‚¬ë„ ê²€ìƒ‰)
  - BI Service (8007): í•™ìŠµ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œê°í™”
```

---

## 3. 3ê°€ì§€ Rule ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜

### 3.1 ì•Œê³ ë¦¬ì¦˜ 1: ë¹ˆë„ ë¶„ì„ (Frequency Analysis)
**ì›ë¦¬**: ì‚¬ìš©ì í”¼ë“œë°±ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” íŒ¨í„´ì„ ì°¾ì•„ Ruleë¡œ ë³€í™˜

#### ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
```python
def frequency_analysis(feedback_data: List[FeedbackData]) -> List[Rule]:
    """
    ë¹ˆë„ ë¶„ì„ ê¸°ë°˜ Rule ì¶”ì¶œ

    ì…ë ¥: ìµœê·¼ 100ê°œ íŒë‹¨ ë°ì´í„° + í”¼ë“œë°± (ğŸ‘ğŸ‘)
    ì¶œë ¥: 80% ì´ìƒ ë¹ˆë„ íŒ¨í„´ â†’ Rule í›„ë³´
    """
    # 1. íŒ¨í„´ ì¹´ìš´íŒ…
    pattern_counts = {}
    for data in feedback_data:
        if data.feedback == "ğŸ‘":  # ê¸ì • í”¼ë“œë°±ë§Œ ë¶„ì„
            pattern = extract_condition_pattern(data.input_data)
            pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1

    # 2. ì„ê³„ê°’ ì ìš© (80% ì´ìƒ)
    total_positive = sum(pattern_counts.values())
    threshold = total_positive * 0.80

    # 3. Rule ìƒì„±
    extracted_rules = []
    for pattern, count in pattern_counts.items():
        if count >= threshold:
            rule = Rule(
                expression=pattern_to_expression(pattern),
                frequency=count / total_positive,
                confidence=calculate_confidence(count, total_positive),
                sample_count=count,
                method="frequency_analysis"
            )
            extracted_rules.append(rule)

    return extracted_rules
```

#### ì˜ˆì‹œ: ì˜¨ë„/ì§„ë™ ëª¨ë‹ˆí„°ë§
```json
ì…ë ¥ ë°ì´í„° (ìµœê·¼ 100ê°œ):
[
  {"input": {"temp": 88, "vib": 42}, "result": true, "feedback": "ğŸ‘"},
  {"input": {"temp": 87, "vib": 43}, "result": true, "feedback": "ğŸ‘"},
  {"input": {"temp": 89, "vib": 41}, "result": true, "feedback": "ğŸ‘"},
  ... (82ê°œ ìœ ì‚¬ íŒ¨í„´)
  {"input": {"temp": 82, "vib": 38}, "result": false, "feedback": "ğŸ‘"},
  ... (18ê°œ ë‹¤ë¥¸ íŒ¨í„´)
]

ë¶„ì„ ê²°ê³¼:
- temp > 85 AND vib > 40: 82íšŒ (82%) â† Rule í›„ë³´!
- temp > 90 AND vib > 35: 15íšŒ (15%) â† ì„ê³„ê°’ ë¯¸ë‹¬

ì¶”ì¶œëœ Rule:
{
  "rule_expression": "temp > 85 AND vib > 40",
  "frequency": 0.82,
  "confidence": 0.85,
  "sample_count": 82,
  "method": "frequency_analysis",
  "recommendation": "ì´ Ruleì„ ì›Œí¬í”Œë¡œìš°ì— ì¶”ê°€í•˜ë©´ 82% ì¼€ì´ìŠ¤ë¥¼ ìë™ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
}
```

### 3.2 ì•Œê³ ë¦¬ì¦˜ 2: ê²°ì • íŠ¸ë¦¬ (Decision Tree Conversion)
**ì›ë¦¬**: sklearn DecisionTreeClassifierë¡œ í•™ìŠµ â†’ íŠ¸ë¦¬ë¥¼ Ruleë¡œ ë³€í™˜

#### ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
```python
from sklearn.tree import DecisionTreeClassifier, export_text

def decision_tree_extraction(feedback_data: List[FeedbackData]) -> List[Rule]:
    """
    ê²°ì • íŠ¸ë¦¬ ê¸°ë°˜ Rule ì¶”ì¶œ

    ì…ë ¥: ìµœê·¼ 100ê°œ íŒë‹¨ ë°ì´í„° + í”¼ë“œë°±
    ì¶œë ¥: íŠ¸ë¦¬ ê²½ë¡œ â†’ Rule ì¡°ê±´ì‹
    """
    # 1. ë°ì´í„° ì¤€ë¹„
    X = [extract_features(d.input_data) for d in feedback_data]
    y = [1 if d.feedback == "ğŸ‘" else 0 for d in feedback_data]

    # 2. ê²°ì • íŠ¸ë¦¬ í•™ìŠµ
    clf = DecisionTreeClassifier(
        max_depth=3,           # ìµœëŒ€ ê¹Šì´ ì œí•œ (í•´ì„ ê°€ëŠ¥ì„±)
        min_samples_split=10,  # ìµœì†Œ ë¶„í•  ìƒ˜í”Œ
        random_state=42
    )
    clf.fit(X, y)

    # 3. íŠ¸ë¦¬ ê²½ë¡œ ì¶”ì¶œ
    tree_rules = export_text(clf, feature_names=list(X[0].keys()))

    # 4. Rule ë³€í™˜
    extracted_rules = []
    for leaf in get_leaf_nodes(clf):
        path = get_decision_path(clf, leaf)
        rule_expression = path_to_expression(path)

        rule = Rule(
            expression=rule_expression,
            confidence=leaf.confidence,
            sample_count=leaf.samples,
            method="decision_tree",
            tree_depth=clf.get_depth(),
            feature_importance=dict(zip(X[0].keys(), clf.feature_importances_))
        )
        extracted_rules.append(rule)

    return extracted_rules
```

#### ì˜ˆì‹œ: ê²°ì • íŠ¸ë¦¬ â†’ Rule ë³€í™˜
```
í•™ìŠµ ì™„ë£Œëœ ê²°ì • íŠ¸ë¦¬:
|--- temp <= 85.0
|   |--- class: False (samples=22, confidence=0.91)
|--- temp > 85.0
|   |--- vib <= 40.0
|   |   |--- class: False (samples=12, confidence=0.83)
|   |--- vib > 40.0
|   |   |--- class: True (samples=78, confidence=0.89)

ë³€í™˜ëœ Rule:
{
  "rule_expression": "temp > 85 AND vib > 40",
  "confidence": 0.89,
  "sample_count": 78,
  "method": "decision_tree",
  "tree_depth": 2,
  "feature_importance": {
    "temp": 0.62,  // ì˜¨ë„ê°€ ë” ì¤‘ìš”
    "vib": 0.38
  }
}
```

### 3.3 ì•Œê³ ë¦¬ì¦˜ 3: LLM íŒ¨í„´ ë°œê²¬ (LLM Pattern Discovery)
**ì›ë¦¬**: ë°ì´í„° ì§‘ê³„ í†µê³„ë¥¼ LLMì´ ë¶„ì„ â†’ ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬ â†’ Rule ì œì•ˆ

#### ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
```python
async def llm_pattern_discovery(feedback_data: List[FeedbackData]) -> List[Rule]:
    """
    LLM ê¸°ë°˜ íŒ¨í„´ ë°œê²¬ Rule ì¶”ì¶œ

    ì…ë ¥: ë°ì´í„° ì§‘ê³„ ìš”ì•½ (í†µê³„)
    ì¶œë ¥: LLMì´ ì œì•ˆí•œ Rule í›„ë³´
    """
    # 1. ë°ì´í„° ì§‘ê³„
    summary = {
        "total_samples": len(feedback_data),
        "positive_feedback": sum(1 for d in feedback_data if d.feedback == "ğŸ‘"),
        "negative_feedback": sum(1 for d in feedback_data if d.feedback == "ğŸ‘"),
        "statistical_summary": calculate_statistics(feedback_data)
    }

    # 2. LLM Prompt ìƒì„±
    prompt = f"""
    ë„ˆëŠ” ë°ì´í„° íŒ¨í„´ ë°œê²¬ ì „ë¬¸ê°€ì•¼.
    ì•„ë˜ í†µê³„ ìš”ì•½ì„ ë¶„ì„í•´ì„œ ìˆ¨ê²¨ì§„ Ruleì„ ì œì•ˆí•´ì¤˜.

    ë°ì´í„° ì§‘ê³„ ìš”ì•½:
    {json.dumps(summary, indent=2)}

    ë¶„ì„ í”„ë¡œì„¸ìŠ¤:
    1. ê¸ì •/ë¶€ì • í”¼ë“œë°± ê°„ ë³€ìˆ˜ ì°¨ì´ ë°œê²¬
    2. ìƒê´€ê´€ê³„ ë¶„ì„
    3. íŒ¨í„´ ì œì•ˆ
    4. Rule ìƒì„±

    ìš”êµ¬ ì‘ë‹µ í˜•ì‹: JSON
    """

    # 3. LLM í˜¸ì¶œ (OpenAI)
    response = await openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3  # ì¼ê´€ì„± ìˆëŠ” ë¶„ì„
    )

    # 4. Rule íŒŒì‹±
    llm_rules = parse_llm_response(response.choices[0].message.content)

    return llm_rules
```

#### ì˜ˆì‹œ: LLM íŒ¨í„´ ë°œê²¬
```json
ì…ë ¥ (ë°ì´í„° ì§‘ê³„ ìš”ì•½):
{
  "total_samples": 100,
  "positive_feedback": 85,
  "negative_feedback": 15,
  "statistical_summary": {
    "temp_avg_positive": 87.5,
    "temp_avg_negative": 82.3,
    "vib_avg_positive": 43.2,
    "vib_avg_negative": 38.7,
    "correlation_temp_vib": 0.72  // ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„
  }
}

LLM ë¶„ì„ ê²°ê³¼:
"ê¸ì • í”¼ë“œë°± ì¼€ì´ìŠ¤ì—ì„œ ì˜¨ë„ í‰ê·  87.5ë„, ì§„ë™ í‰ê·  43.2ë¡œ
ë¶€ì • ì¼€ì´ìŠ¤ë³´ë‹¤ ê°ê° 5.2ë„, 4.5 ë†’ìŒ.
ì˜¨ë„ì™€ ì§„ë™ì˜ ìƒê´€ê´€ê³„ 0.72ë¡œ ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ì›€ì§ì„.
â†’ ë‘ ë³€ìˆ˜ê°€ ëª¨ë‘ ë†’ì„ ë•Œ ê¸ì • í”¼ë“œë°± ë°œìƒ"

ì¶”ì¶œëœ Rule:
{
  "rule_expression": "temp > 85 AND vib > 40",
  "reasoning": "ê¸ì • í”¼ë“œë°± ì¼€ì´ìŠ¤ì—ì„œ temp í‰ê·  87.5, vib í‰ê·  43.2ë¡œ ë¶€ì • ì¼€ì´ìŠ¤ë³´ë‹¤ ê°ê° 5.2, 4.5 ë†’ìŒ. ìƒê´€ê´€ê³„ 0.72ë¡œ ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ì›€ì§ì„.",
  "confidence": 0.83,
  "method": "llm_pattern_discovery"
}
```

### 3.4 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ í†µí•©
```python
def integrate_rules(
    freq_rules: List[Rule],
    tree_rules: List[Rule],
    llm_rules: List[Rule]
) -> Rule:
    """
    3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì  Rule ì„ íƒ

    í†µí•© ì „ëµ:
    1. ë™ì¼ Rule í‘œí˜„ì‹ ì°¾ê¸°
    2. ì‹ ë¢°ë„ í‰ê·  ê³„ì‚°
    3. ìƒ˜í”Œ ìˆ˜ í•©ì‚°
    4. ìµœì¢… ì‹ ë¢°ë„ ê°€ì¥ ë†’ì€ Rule ì„ íƒ
    """
    all_rules = freq_rules + tree_rules + llm_rules

    # Rule í‘œí˜„ì‹ë³„ ê·¸ë£¹í™”
    rule_groups = {}
    for rule in all_rules:
        expr = rule.expression
        if expr not in rule_groups:
            rule_groups[expr] = []
        rule_groups[expr].append(rule)

    # ê° ê·¸ë£¹ë³„ í†µí•© Rule ìƒì„±
    integrated_rules = []
    for expr, rules in rule_groups.items():
        avg_confidence = sum(r.confidence for r in rules) / len(rules)
        total_samples = sum(r.sample_count for r in rules)
        methods_used = [r.method for r in rules]

        integrated_rule = Rule(
            expression=expr,
            confidence=avg_confidence,
            sample_count=total_samples,
            method="integrated",
            methods_used=methods_used,
            agreement_level=len(rules) / 3.0  # 3ê°œ ì•Œê³ ë¦¬ì¦˜ ì¤‘ ì¼ì¹˜ìœ¨
        )
        integrated_rules.append(integrated_rule)

    # ìµœê³  ì‹ ë¢°ë„ Rule ë°˜í™˜
    best_rule = max(integrated_rules, key=lambda r: r.confidence)
    return best_rule
```

---

## 4. Few-shot í•™ìŠµ ê´€ë¦¬

### 4.1 pgvector ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
```python
async def select_few_shot_samples(
    current_input: dict,
    limit: int = 20
) -> List[FewShotSample]:
    """
    í˜„ì¬ íŒë‹¨ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ìƒ˜í”Œ 10-20ê°œ ê²€ìƒ‰

    ì…ë ¥: í˜„ì¬ íŒë‹¨ ì…ë ¥ ë°ì´í„°
    ì¶œë ¥: ìœ ì‚¬í•œ ê³¼ê±° ìƒ˜í”Œ 10-20ê°œ
    """
    # 1. ì…ë ¥ ì„ë² ë”© ìƒì„±
    embedding = await generate_embedding(current_input)

    # 2. pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (cosine similarity)
    query = f"""
    SELECT
        input_data,
        result,
        feedback,
        explanation,
        1 - (explanation_embedding <=> '{embedding}') AS similarity
    FROM judgment_executions
    WHERE feedback IS NOT NULL  -- í”¼ë“œë°± ìˆëŠ” ê²ƒë§Œ
    ORDER BY explanation_embedding <=> '{embedding}'
    LIMIT {limit * 2}  -- ë‹¤ì–‘ì„± í•„í„°ë§ ìœ„í•´ 2ë°° ê²€ìƒ‰
    """

    raw_samples = await db.execute(query)

    # 3. ë‹¤ì–‘ì„± í•„í„°ë§ (ë„ˆë¬´ ìœ ì‚¬í•œ ê²ƒ ì œê±°)
    filtered_samples = diversity_filter(raw_samples, threshold=0.95)

    # 4. ê¸ì •/ë¶€ì • ê· í˜• (ê¸ì • 15ê°œ, ë¶€ì • 5ê°œ)
    balanced_samples = balance_feedback(
        filtered_samples,
        positive_count=15,
        negative_count=5
    )

    # 5. ìµœì¢… ì„ íƒ (10-20ê°œ)
    final_samples = balanced_samples[:limit]

    return final_samples
```

### 4.2 Few-shot íš¨ê³¼ì„± ì¸¡ì •
```python
async def measure_few_shot_effectiveness(workflow_id: str) -> dict:
    """
    Few-shot ìƒ˜í”Œ ì‚¬ìš© íš¨ê³¼ ì¸¡ì •

    ë¹„êµ:
    - Few-shot ì‚¬ìš©ì‹œ ì •í™•ë„
    - Few-shot ë¯¸ì‚¬ìš©ì‹œ ì •í™•ë„
    â†’ í–¥ìƒë¥  ê³„ì‚° (ëª©í‘œ: +15%p)
    """
    # 1. Few-shot ì‚¬ìš© íŒë‹¨ ìˆ˜ì§‘ (ìµœê·¼ 100ê°œ)
    with_few_shot = await db.execute(f"""
        SELECT result, feedback
        FROM judgment_executions
        WHERE workflow_id = '{workflow_id}'
          AND few_shot_samples IS NOT NULL
        ORDER BY created_at DESC
        LIMIT 100
    """)

    # 2. Few-shot ë¯¸ì‚¬ìš© íŒë‹¨ ìˆ˜ì§‘ (ìµœê·¼ 100ê°œ)
    without_few_shot = await db.execute(f"""
        SELECT result, feedback
        FROM judgment_executions
        WHERE workflow_id = '{workflow_id}'
          AND few_shot_samples IS NULL
        ORDER BY created_at DESC
        LIMIT 100
    """)

    # 3. ì •í™•ë„ ê³„ì‚°
    accuracy_with = calculate_accuracy(with_few_shot)
    accuracy_without = calculate_accuracy(without_few_shot)

    improvement = accuracy_with - accuracy_without

    return {
        "accuracy_with_few_shot": accuracy_with,
        "accuracy_without_few_shot": accuracy_without,
        "improvement": improvement,
        "meets_target": improvement >= 0.15  # 15%p ëª©í‘œ
    }
```

---

## 5. API ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„

### 5.1 Rule ì¶”ì¶œ API
```python
@app.post("/api/v2/learning/extract-rules")
async def extract_rules(
    workflow_id: str,
    algorithm: str = "all",  # all | frequency | decision_tree | llm_pattern
    min_samples: int = 50
) -> RuleExtractionResponse:
    """
    í”¼ë“œë°± ë°ì´í„°ë¡œë¶€í„° ìë™ Rule ì¶”ì¶œ

    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/learning/extract-rules
    {
      "workflow_id": "temp_monitoring_v2",
      "algorithm": "all",
      "min_samples": 50
    }

    ì‘ë‹µ ì˜ˆì‹œ:
    {
      "extracted_rules": [
        {
          "rule_expression": "temp > 85 AND vib > 40",
          "confidence": 0.87,
          "method": "integrated",
          "methods_used": ["frequency_analysis", "decision_tree", "llm_pattern"],
          "sample_count": 82,
          "recommendation": "ì´ Ruleì„ ì›Œí¬í”Œë¡œìš°ì— ì¶”ê°€í•˜ë©´ 82% ì¼€ì´ìŠ¤ë¥¼ ìë™ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
      ],
      "total_feedback_samples": 100,
      "processing_time_ms": 2340
    }
    """
    # í”¼ë“œë°± ë°ì´í„° ìˆ˜ì§‘
    feedback_data = await collect_feedback(workflow_id)

    if len(feedback_data) < min_samples:
        raise HTTPException(400, f"ìƒ˜í”Œ ë¶€ì¡±: {len(feedback_data)}ê°œ (ìµœì†Œ {min_samples}ê°œ)")

    # ì•Œê³ ë¦¬ì¦˜ë³„ ì‹¤í–‰
    if algorithm == "all":
        freq_rules = await frequency_analysis(feedback_data)
        tree_rules = await decision_tree_extraction(feedback_data)
        llm_rules = await llm_pattern_discovery(feedback_data)

        best_rule = integrate_rules(freq_rules, tree_rules, llm_rules)
        return {"extracted_rules": [best_rule], ...}

    elif algorithm == "frequency":
        rules = await frequency_analysis(feedback_data)
        return {"extracted_rules": rules, ...}

    # ... ê¸°íƒ€ ì•Œê³ ë¦¬ì¦˜
```

### 5.2 Rule ì €ì¥ API (ì‹ ê·œ ì¶”ê°€! ğŸ†•)
```python
@app.post("/api/v2/learning/save-rule")
async def save_extracted_rule(
    workflow_id: str,
    rule_expression: str,
    confidence: float
) -> SaveRuleResponse:
    """
    ì¶”ì¶œëœ Ruleì„ Workflowì— ìë™ ì €ì¥

    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/learning/save-rule
    {
      "workflow_id": "temp_monitoring_v2",
      "rule_expression": "temperature > 85 && vibration > 40",
      "confidence": 0.92
    }

    ì‘ë‹µ ì˜ˆì‹œ:
    {
      "success": true,
      "workflow_id": "temp_monitoring_v2",
      "old_version": 1,
      "new_version": 2,
      "updated_at": "2025-10-30T14:23:45Z",
      "message": "Ruleì´ Workflowì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

    ì—ëŸ¬ ì‘ë‹µ (Workflow ì—†ìŒ):
    {
      "success": false,
      "error": "Workflow not found: temp_monitoring_v2"
    }
    """
    # Learning Serviceì˜ save_extracted_rule() í˜¸ì¶œ
    learning_service.save_extracted_rule(workflow_id, rule_expression, confidence)

    return {"success": True, "workflow_id": workflow_id, ...}
```

**ìë™ í†µí•©**: `extract_rules()` APIëŠ” ë‚´ë¶€ì ìœ¼ë¡œ `save_extracted_rule()`ì„ ìë™ í˜¸ì¶œí•˜ì—¬ ì¶”ì¶œëœ Ruleì„ ì¦‰ì‹œ Workflowì— ì €ì¥í•©ë‹ˆë‹¤.

### 5.3 Few-shot ìƒ˜í”Œ ê²€ìƒ‰ API
```python
@app.post("/api/v2/learning/few-shot-samples")
async def get_few_shot_samples(
    input_data: dict,
    limit: int = 20
) -> FewShotResponse:
    """
    í˜„ì¬ íŒë‹¨ê³¼ ìœ ì‚¬í•œ Few-shot ìƒ˜í”Œ ê²€ìƒ‰

    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/learning/few-shot-samples
    {
      "input_data": {"temperature": 88, "vibration": 42},
      "limit": 15
    }

    ì‘ë‹µ ì˜ˆì‹œ:
    {
      "selected_samples": [
        {
          "input": {"temp": 87, "vib": 43},
          "result": true,
          "feedback": "ğŸ‘",
          "similarity": 0.92
        },
        ... (15ê°œ)
      ],
      "selection_summary": {
        "positive_count": 12,
        "negative_count": 3,
        "avg_similarity": 0.88,
        "diversity_score": 0.65
      }
    }
    """
    samples = await select_few_shot_samples(input_data, limit)

    return FewShotResponse(
        selected_samples=samples,
        selection_summary=calculate_summary(samples)
    )
```

### 5.3 í”¼ë“œë°± ìˆ˜ì§‘ API
```python
@app.post("/api/v2/learning/feedback")
async def submit_feedback(
    execution_id: str,
    feedback_type: str,  # thumbs_up | thumbs_down | log_review | chat_feedback
    feedback_data: dict
) -> FeedbackResponse:
    """
    ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° ì €ì¥

    ìš”ì²­ ì˜ˆì‹œ:
    POST /api/v2/learning/feedback
    {
      "execution_id": "exec-uuid-123",
      "feedback_type": "thumbs_up",
      "feedback_data": {
        "comment": "ì •í™•í•œ íŒë‹¨ì´ì—ˆì–´ìš”",
        "timestamp": "2025-10-16T10:30:00Z"
      }
    }

    ì‘ë‹µ ì˜ˆì‹œ:
    {
      "feedback_id": "feedback-uuid-456",
      "status": "collected",
      "total_feedback_count": 52,
      "ready_for_extraction": false,
      "min_samples_needed": 50
    }
    """
    # í”¼ë“œë°± ì €ì¥
    feedback = await db.insert("feedback_data", {
        "execution_id": execution_id,
        "feedback_type": feedback_type,
        "feedback_data": feedback_data,
        "created_at": datetime.now()
    })

    # í”¼ë“œë°± ìˆ˜ í™•ì¸
    total_count = await db.count("feedback_data", {"workflow_id": ...})

    return FeedbackResponse(
        feedback_id=feedback.id,
        status="collected",
        total_feedback_count=total_count,
        ready_for_extraction=total_count >= 50
    )
```

---

## 6. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### 6.1 ì„±ëŠ¥ ëª©í‘œ
```yaml
Rule ì¶”ì¶œ ì„±ëŠ¥:
  - ì•Œê³ ë¦¬ì¦˜ë³„ ì‹¤í–‰ ì‹œê°„: < 2ì´ˆ
  - 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ë³‘ë ¬ ì‹¤í–‰ ì‹œê°„: < 3ì´ˆ
  - Rule í†µí•© ì‹œê°„: < 500ms
  - ì „ì²´ ì²˜ë¦¬ ì‹œê°„: < 5ì´ˆ

Few-shot ê²€ìƒ‰ ì„±ëŠ¥:
  - pgvector ìœ ì‚¬ë„ ê²€ìƒ‰: < 200ms
  - ë‹¤ì–‘ì„± í•„í„°ë§: < 100ms
  - ì „ì²´ ìƒ˜í”Œ ì„ íƒ ì‹œê°„: < 500ms

ëª©í‘œ ë©”íŠ¸ë¦­:
  - Rule ì¶”ì¶œ ì •í™•ë„: 85% ì´ìƒ
  - Few-shot íš¨ê³¼ì„±: +15%p í–¥ìƒ
  - ì˜ë„ ë¶„ë¥˜ ì •í™•ë„: 92% ì´ìƒ
```

### 6.2 ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
```python
# Prometheus ë©”íŠ¸ë¦­ ì •ì˜

from prometheus_client import Counter, Histogram, Gauge

# Rule ì¶”ì¶œ ë©”íŠ¸ë¦­
rule_extractions_total = Counter(
    'learning_rule_extractions_total',
    'Total number of rule extractions',
    ['algorithm', 'success']
)

rule_extraction_duration = Histogram(
    'learning_rule_extraction_duration_seconds',
    'Duration of rule extraction',
    ['algorithm']
)

rule_confidence_score = Gauge(
    'learning_rule_confidence_score',
    'Confidence score of extracted rules',
    ['workflow_id', 'algorithm']
)

# Few-shot ë©”íŠ¸ë¦­
few_shot_searches_total = Counter(
    'learning_few_shot_searches_total',
    'Total number of few-shot sample searches'
)

few_shot_effectiveness = Gauge(
    'learning_few_shot_effectiveness',
    'Few-shot learning effectiveness (accuracy improvement)',
    ['workflow_id']
)

# í”¼ë“œë°± ìˆ˜ì§‘ ë©”íŠ¸ë¦­
feedback_collected_total = Counter(
    'learning_feedback_collected_total',
    'Total feedback collected',
    ['feedback_type']
)

feedback_count_by_workflow = Gauge(
    'learning_feedback_count',
    'Current feedback count by workflow',
    ['workflow_id']
)
```

---

## 7. ë°°í¬ ë° ìš´ì˜ ê°€ì´ë“œ

### 7.1 Docker ì„¤ì •
```yaml
# docker-compose.yml ë°œì·Œ
learning-service:
  image: judgify/learning-service:2.0.0
  container_name: learning-service
  ports:
    - "8009:8009"
  environment:
    DATABASE_URL: ${DATABASE_URL}
    REDIS_URL: ${REDIS_URL}
    OPENAI_API_KEY: ${OPENAI_API_KEY}
    MIN_FEEDBACK_SAMPLES: 50
    RULE_CONFIDENCE_THRESHOLD: 0.70
    FEW_SHOT_SAMPLE_LIMIT: 20
  depends_on:
    - postgres
    - redis
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8009/health"]
    interval: 30s
    timeout: 10s
    retries: 3
```

### 7.2 í™˜ê²½ ë³€ìˆ˜
```bash
# .env.production
DATABASE_URL=postgresql://user:pass@postgres:5432/judgify_prod
REDIS_URL=redis://redis:6379/0
OPENAI_API_KEY=sk-...

# Learning Service ì„¤ì •
MIN_FEEDBACK_SAMPLES=50          # Rule ì¶”ì¶œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
RULE_CONFIDENCE_THRESHOLD=0.70   # Rule ì‹ ë¢°ë„ ì„ê³„ê°’
FEW_SHOT_SAMPLE_LIMIT=20         # Few-shot ìƒ˜í”Œ ìµœëŒ€ ê°œìˆ˜
EMBEDDING_MODEL=text-embedding-3-small  # OpenAI ì„ë² ë”© ëª¨ë¸
```

---

## 8. ì¶”ê°€ ì°¸ì¡° ë¬¸ì„œ

- **`docs/algorithms/auto_rule_extraction.md`**: 3ê°€ì§€ Rule ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ ìƒì„¸ ì„¤ê³„
- **`docs/algorithms/data_aggregation.md`**: ë°ì´í„° ì§‘ê³„ ì•Œê³ ë¦¬ì¦˜ (LLM í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)
- **`docs/architecture/database_design.md`**: feedback_data, judgment_executions í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ
- **`docs/services/judgment_engine.md`**: Few-shot ìƒ˜í”Œ í™œìš©í•œ íŒë‹¨ ë¡œì§

---

**Ver2.0 Final í•µì‹¬ í˜ì‹ **: ML ëª¨ë¸ ì—†ì´ ì „í†µì  ì•Œê³ ë¦¬ì¦˜ + LLMìœ¼ë¡œ ìë™í•™ìŠµ êµ¬í˜„! ğŸ”¥

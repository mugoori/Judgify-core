# ìë™ Rule ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ (Ver2.0 Final) ğŸ”¥

## 1. ê°œìš”

### 1.1 ì•Œê³ ë¦¬ì¦˜ ëª©ì 
ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ **ìë™ìœ¼ë¡œ Ruleì„ ì¶”ì¶œ**í•˜ëŠ” 3ê°€ì§€ ì „í†µì  ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ML ëª¨ë¸ ì—†ì´ í•´ì„ ê°€ëŠ¥í•œ Ruleë¡œ ì§ì ‘ ë³€í™˜í•˜ì—¬ ì¦‰ì‹œ ì›Œí¬í”Œë¡œìš°ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 1.2 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
| ì•Œê³ ë¦¬ì¦˜ | ì²˜ë¦¬ ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì í•©í•œ ìƒí™© |
|----------|----------|------|------|------------|
| **ë¹ˆë„ ë¶„ì„** | íŒ¨í„´ ì¹´ìš´íŒ… + ì„ê³„ê°’ | ë‹¨ìˆœ ëª…í™•, ë¹ ë¦„ | ë³µì¡í•œ íŒ¨í„´ ë†“ì¹¨ | ëª…í™•í•œ ë°˜ë³µ íŒ¨í„´ |
| **ê²°ì • íŠ¸ë¦¬** | sklearn í•™ìŠµ + ë³€í™˜ | ë³€ìˆ˜ ì¤‘ìš”ë„ ì œê³µ | ê³¼ì í•© ìœ„í—˜ | ë‹¤ë³€ìˆ˜ ì¡°ê±´ |
| **LLM íŒ¨í„´** | í†µê³„ ë¶„ì„ + LLM | ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬ | LLM ë¹„ìš© | ë³µì¡í•œ ìƒê´€ê´€ê³„ |

### 1.3 ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ì „ëµ
```python
def select_algorithm(feedback_data: List[FeedbackData]) -> str:
    """
    ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ìµœì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ

    ì„ íƒ ê¸°ì¤€:
    1. ìƒ˜í”Œ ìˆ˜ < 50: ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ ë³´ë¥˜
    2. ë³€ìˆ˜ 2ê°œ ì´í•˜ + ëª…í™•í•œ íŒ¨í„´: ë¹ˆë„ ë¶„ì„
    3. ë³€ìˆ˜ 3-5ê°œ + ë³µì¡í•œ ì¡°ê±´: ê²°ì • íŠ¸ë¦¬
    4. ë³€ìˆ˜ 5ê°œ ì´ìƒ + ìƒê´€ê´€ê³„: LLM íŒ¨í„´
    5. ë¶ˆí™•ì‹¤í•  ë•Œ: 3ê°€ì§€ ëª¨ë‘ ì‹¤í–‰ í›„ í†µí•©
    """
    sample_count = len(feedback_data)
    variable_count = len(feedback_data[0].input_data.keys())

    if sample_count < 50:
        return "insufficient_data"

    if variable_count <= 2:
        return "frequency_analysis"
    elif variable_count <= 5:
        return "decision_tree"
    elif variable_count > 5:
        return "llm_pattern"
    else:
        return "all"  # ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰ í›„ í†µí•©
```

---

## 2. ì•Œê³ ë¦¬ì¦˜ 1: ë¹ˆë„ ë¶„ì„ (Frequency Analysis)

### 2.1 ì•Œê³ ë¦¬ì¦˜ ì›ë¦¬
**í•µì‹¬ ì•„ì´ë””ì–´**: ì‚¬ìš©ì í”¼ë“œë°±ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” íŒ¨í„´(80% ì´ìƒ)ì„ ì°¾ì•„ Ruleë¡œ ë³€í™˜

### 2.2 ìƒì„¸ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
```python
from collections import Counter
from typing import List, Dict

class FrequencyAnalyzer:
    def __init__(self, threshold: float = 0.80):
        """
        ë¹ˆë„ ë¶„ì„ Rule ì¶”ì¶œê¸°

        Args:
            threshold: Rule í›„ë³´ë¡œ ì„ ì •í•  ìµœì†Œ ë¹ˆë„ (ê¸°ë³¸: 80%)
        """
        self.threshold = threshold

    def extract_rules(self, feedback_data: List[FeedbackData]) -> List[Rule]:
        """
        ë¹ˆë„ ë¶„ì„ ê¸°ë°˜ Rule ì¶”ì¶œ

        ì²˜ë¦¬ ë‹¨ê³„:
        1. ê¸ì • í”¼ë“œë°±ë§Œ í•„í„°ë§
        2. ì¡°ê±´ íŒ¨í„´ ì¶”ì¶œ ë° ì¹´ìš´íŒ…
        3. ì„ê³„ê°’ ì ìš© (80% ì´ìƒ)
        4. Rule í‘œí˜„ì‹ ìƒì„±
        5. ì‹ ë¢°ë„ ê³„ì‚°
        """
        # 1. ê¸ì • í”¼ë“œë°±ë§Œ í•„í„°ë§
        positive_data = [d for d in feedback_data if d.feedback == "ğŸ‘"]

        # 2. ì¡°ê±´ íŒ¨í„´ ì¶”ì¶œ ë° ì¹´ìš´íŒ…
        pattern_counts = Counter()
        for data in positive_data:
            pattern = self._extract_pattern(data.input_data)
            pattern_counts[pattern] += 1

        # 3. ì„ê³„ê°’ ì ìš©
        total_positive = len(positive_data)
        min_count = int(total_positive * self.threshold)

        # 4. Rule ìƒì„±
        extracted_rules = []
        for pattern, count in pattern_counts.items():
            if count >= min_count:
                rule = self._create_rule(
                    pattern=pattern,
                    count=count,
                    total=total_positive
                )
                extracted_rules.append(rule)

        # 5. ì‹ ë¢°ë„ ìˆœ ì •ë ¬
        extracted_rules.sort(key=lambda r: r.confidence, reverse=True)

        return extracted_rules

    def _extract_pattern(self, input_data: dict) -> str:
        """
        ì…ë ¥ ë°ì´í„°ì—ì„œ ì¡°ê±´ íŒ¨í„´ ì¶”ì¶œ

        ì˜ˆì‹œ:
        {"temp": 88, "vib": 42} â†’ "temp>85_vib>40"
        """
        conditions = []
        for key, value in sorted(input_data.items()):
            # ìˆ˜ì¹˜í˜• ë°ì´í„°ëŠ” ë²”ìœ„ë¡œ ë³€í™˜
            if isinstance(value, (int, float)):
                threshold = self._find_threshold(key, value)
                conditions.append(f"{key}>{threshold}")
            # ë¬¸ìì—´ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ
            else:
                conditions.append(f"{key}={value}")

        return "_".join(conditions)

    def _find_threshold(self, key: str, value: float) -> float:
        """
        ë³€ìˆ˜ë³„ ì„ê³„ê°’ ìë™ ê³„ì‚°

        ì „ëµ:
        - 5ì˜ ë°°ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼ (ì˜ˆ: 88 â†’ 85)
        - ë°ì´í„° ë¶„í¬ ê³ ë ¤ (ì¤‘ì•™ê°’ ê¸°ì¤€)
        """
        return round(value / 5) * 5 - 5

    def _create_rule(self, pattern: str, count: int, total: int) -> Rule:
        """
        íŒ¨í„´ì„ Rule ê°ì²´ë¡œ ë³€í™˜

        ì‹ ë¢°ë„ ê³„ì‚°:
        confidence = (count / total) * 0.9
        â†’ 0.9ë¥¼ ê³±í•˜ëŠ” ì´ìœ : ê³¼ì í•© ë°©ì§€
        """
        frequency = count / total
        confidence = frequency * 0.9  # ê³¼ì í•© ë°©ì§€ ë³´ì •

        # íŒ¨í„´ì„ Rule í‘œí˜„ì‹ìœ¼ë¡œ ë³€í™˜
        expression = pattern.replace("_", " AND ").replace("=", " == ")

        return Rule(
            expression=expression,
            frequency=frequency,
            confidence=confidence,
            sample_count=count,
            method="frequency_analysis"
        )
```

### 2.3 ì‹¤ì œ ì ìš© ì˜ˆì‹œ
```python
# ì…ë ¥ ë°ì´í„° ì˜ˆì‹œ (ì œì¡°ì—… ì˜¨ë„/ì§„ë™ ëª¨ë‹ˆí„°ë§)
feedback_data = [
    FeedbackData(input={"temp": 88, "vib": 42}, result=True, feedback="ğŸ‘"),
    FeedbackData(input={"temp": 87, "vib": 43}, result=True, feedback="ğŸ‘"),
    FeedbackData(input={"temp": 89, "vib": 41}, result=True, feedback="ğŸ‘"),
    FeedbackData(input={"temp": 86, "vib": 44}, result=True, feedback="ğŸ‘"),
    # ... 78ê°œ ë” (ì´ 82ê°œ ìœ ì‚¬ íŒ¨í„´)
    FeedbackData(input={"temp": 82, "vib": 38}, result=False, feedback="ğŸ‘"),
    FeedbackData(input={"temp": 83, "vib": 37}, result=False, feedback="ğŸ‘"),
    # ... 16ê°œ ë” (ì´ 18ê°œ ë‹¤ë¥¸ íŒ¨í„´)
]

# Rule ì¶”ì¶œ ì‹¤í–‰
analyzer = FrequencyAnalyzer(threshold=0.80)
rules = analyzer.extract_rules(feedback_data)

# ì¶”ì¶œëœ Rule
print(rules[0])
# Output:
# Rule(
#   expression="temp > 85 AND vib > 40",
#   frequency=0.82,
#   confidence=0.74,  # 0.82 * 0.9 = 0.738
#   sample_count=82,
#   method="frequency_analysis"
# )
```

### 2.4 ì¥ë‹¨ì  ë° ì ìš© ìƒí™©
**ì¥ì **:
- âœ… êµ¬í˜„ ë‹¨ìˆœ, ì‹¤í–‰ ì†ë„ ë¹ ë¦„ (< 1ì´ˆ)
- âœ… í•´ì„ ìš©ì´, ê²°ê³¼ ì˜ˆì¸¡ ê°€ëŠ¥
- âœ… ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ

**ë‹¨ì **:
- âŒ ë³µì¡í•œ ìƒí˜¸ì‘ìš© íŒ¨í„´ ë†“ì¹  ìˆ˜ ìˆìŒ
- âŒ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ê³ ë ¤ ì•ˆ ë¨
- âŒ í¬ê·€ íŒ¨í„´ ë°œê²¬ ì–´ë ¤ì›€

**ì í•©í•œ ìƒí™©**:
- ë³€ìˆ˜ 2-3ê°œ, ëª…í™•í•œ ì„ê³„ê°’ ì¡´ì¬
- ëŒ€ë¶€ë¶„ ì¼€ì´ìŠ¤ê°€ ìœ ì‚¬í•œ íŒ¨í„´
- ë¹ ë¥¸ Rule ì¶”ì¶œ í•„ìš”

---

## 3. ì•Œê³ ë¦¬ì¦˜ 2: ê²°ì • íŠ¸ë¦¬ ë³€í™˜ (Decision Tree Conversion)

### 3.1 ì•Œê³ ë¦¬ì¦˜ ì›ë¦¬
**í•µì‹¬ ì•„ì´ë””ì–´**: sklearn DecisionTreeClassifierë¡œ í•™ìŠµí•œ íŠ¸ë¦¬ë¥¼ Rule í‘œí˜„ì‹ìœ¼ë¡œ ë³€í™˜

### 3.2 ìƒì„¸ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
```python
from sklearn.tree import DecisionTreeClassifier, _tree
import numpy as np

class DecisionTreeConverter:
    def __init__(self, max_depth: int = 3, min_samples_split: int = 10):
        """
        ê²°ì • íŠ¸ë¦¬ ê¸°ë°˜ Rule ì¶”ì¶œê¸°

        Args:
            max_depth: íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ (í•´ì„ ê°€ëŠ¥ì„± ìœ ì§€)
            min_samples_split: ë…¸ë“œ ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        """
        self.max_depth = max_depth
        self.min_samples_split = min_samples_split

    def extract_rules(self, feedback_data: List[FeedbackData]) -> List[Rule]:
        """
        ê²°ì • íŠ¸ë¦¬ í•™ìŠµ â†’ Rule ë³€í™˜

        ì²˜ë¦¬ ë‹¨ê³„:
        1. ë°ì´í„° ì¤€ë¹„ (X, y ë¶„ë¦¬)
        2. ê²°ì • íŠ¸ë¦¬ í•™ìŠµ (sklearn)
        3. ë¦¬í”„ ë…¸ë“œë³„ ê²½ë¡œ ì¶”ì¶œ
        4. ê²½ë¡œë¥¼ Rule í‘œí˜„ì‹ìœ¼ë¡œ ë³€í™˜
        5. ì‹ ë¢°ë„ ë° Feature Importance ê³„ì‚°
        """
        # 1. ë°ì´í„° ì¤€ë¹„
        X, y, feature_names = self._prepare_data(feedback_data)

        # 2. ê²°ì • íŠ¸ë¦¬ í•™ìŠµ
        clf = DecisionTreeClassifier(
            max_depth=self.max_depth,
            min_samples_split=self.min_samples_split,
            random_state=42  # ì¬í˜„ ê°€ëŠ¥ì„±
        )
        clf.fit(X, y)

        # 3. íŠ¸ë¦¬ êµ¬ì¡° ë¶„ì„
        tree = clf.tree_

        # 4. ë¦¬í”„ ë…¸ë“œë³„ Rule ì¶”ì¶œ
        rules = []
        for leaf_id in self._get_leaf_nodes(tree):
            rule = self._extract_rule_from_path(
                clf, tree, leaf_id, feature_names
            )
            if rule.confidence >= 0.70:  # ì‹ ë¢°ë„ í•„í„°
                rules.append(rule)

        return rules

    def _prepare_data(self, feedback_data: List[FeedbackData]):
        """
        í”¼ë“œë°± ë°ì´í„°ë¥¼ sklearn í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        feature_names = list(feedback_data[0].input_data.keys())

        X = []
        y = []
        for data in feedback_data:
            # ì…ë ¥ íŠ¹ì§•
            features = [data.input_data[name] for name in feature_names]
            X.append(features)

            # ë¼ë²¨ (ğŸ‘=1, ğŸ‘=0)
            label = 1 if data.feedback == "ğŸ‘" else 0
            y.append(label)

        return np.array(X), np.array(y), feature_names

    def _get_leaf_nodes(self, tree) -> List[int]:
        """
        íŠ¸ë¦¬ì—ì„œ ë¦¬í”„ ë…¸ë“œ ID ëª©ë¡ ì¶”ì¶œ
        """
        leaf_nodes = []
        for node_id in range(tree.node_count):
            if tree.children_left[node_id] == _tree.TREE_LEAF:
                leaf_nodes.append(node_id)
        return leaf_nodes

    def _extract_rule_from_path(
        self,
        clf: DecisionTreeClassifier,
        tree,
        leaf_id: int,
        feature_names: List[str]
    ) -> Rule:
        """
        ë¦¬í”„ ë…¸ë“œê¹Œì§€ì˜ ê²½ë¡œë¥¼ Rule í‘œí˜„ì‹ìœ¼ë¡œ ë³€í™˜

        ì˜ˆì‹œ:
        Node 0: temp <= 85.0 â†’ left
        Node 2: vib <= 40.0 â†’ right
        Node 4: class = True (leaf)

        â†’ Rule: "temp > 85 AND vib > 40"
        """
        # ê²½ë¡œ ì¶”ì 
        path = []
        node_id = 0

        while node_id != leaf_id:
            feature_idx = tree.feature[node_id]
            threshold = tree.threshold[node_id]
            feature_name = feature_names[feature_idx]

            # ë¦¬í”„ê¹Œì§€ ì–´ëŠ ë°©í–¥ìœ¼ë¡œ ê°ˆì§€ ê²°ì •
            if tree.children_left[node_id] == leaf_id or \
               self._is_in_subtree(tree, tree.children_left[node_id], leaf_id):
                # ì™¼ìª½ (<=)
                path.append(f"{feature_name} <= {threshold:.1f}")
                node_id = tree.children_left[node_id]
            else:
                # ì˜¤ë¥¸ìª½ (>)
                path.append(f"{feature_name} > {threshold:.1f}")
                node_id = tree.children_right[node_id]

        # Rule í‘œí˜„ì‹ ìƒì„±
        expression = " AND ".join(path)

        # ì‹ ë¢°ë„ ê³„ì‚°
        samples = tree.n_node_samples[leaf_id]
        class_counts = tree.value[leaf_id][0]
        confidence = max(class_counts) / sum(class_counts)

        # Feature Importance
        feature_importance = dict(zip(
            feature_names,
            clf.feature_importances_
        ))

        return Rule(
            expression=expression,
            confidence=confidence,
            sample_count=int(samples),
            method="decision_tree",
            tree_depth=clf.get_depth(),
            feature_importance=feature_importance
        )

    def _is_in_subtree(self, tree, parent: int, target: int) -> bool:
        """
        target ë…¸ë“œê°€ parentì˜ ì„œë¸ŒíŠ¸ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸
        """
        if parent == target:
            return True

        left = tree.children_left[parent]
        right = tree.children_right[parent]

        if left != _tree.TREE_LEAF and self._is_in_subtree(tree, left, target):
            return True

        if right != _tree.TREE_LEAF and self._is_in_subtree(tree, right, target):
            return True

        return False
```

### 3.3 ì‹¤ì œ ì ìš© ì˜ˆì‹œ
```python
# ì…ë ¥ ë°ì´í„° (100ê°œ ìƒ˜í”Œ)
feedback_data = [...]  # ë™ì¼ ë°ì´í„°

# Rule ì¶”ì¶œ ì‹¤í–‰
converter = DecisionTreeConverter(max_depth=3, min_samples_split=10)
rules = converter.extract_rules(feedback_data)

# ì¶”ì¶œëœ Rule
print(rules[0])
# Output:
# Rule(
#   expression="temp > 85.0 AND vib > 40.0",
#   confidence=0.89,
#   sample_count=78,
#   method="decision_tree",
#   tree_depth=2,
#   feature_importance={
#     "temp": 0.62,  # ì˜¨ë„ê°€ ë” ì¤‘ìš”
#     "vib": 0.38
#   }
# )

# íŠ¸ë¦¬ ì‹œê°í™”
from sklearn.tree import export_text
tree_rules = export_text(converter.clf, feature_names=["temp", "vib"])
print(tree_rules)
# Output:
# |--- temp <= 85.0
# |   |--- class: False
# |--- temp > 85.0
# |   |--- vib <= 40.0
# |   |   |--- class: False
# |   |--- vib > 40.0
# |   |   |--- class: True
```

### 3.4 ì¥ë‹¨ì  ë° ì ìš© ìƒí™©
**ì¥ì **:
- âœ… ë³€ìˆ˜ ì¤‘ìš”ë„ ì œê³µ (Feature Importance)
- âœ… ë‹¤ë³€ìˆ˜ ì¡°ê±´ ìë™ ë°œê²¬
- âœ… ë¹„ì„ í˜• íŒ¨í„´ í¬ì°© ê°€ëŠ¥

**ë‹¨ì **:
- âŒ ê³¼ì í•© ìœ„í—˜ (max_depth ì¡°ì ˆ í•„ìš”)
- âŒ íŠ¸ë¦¬ ê¹Šì´ ì¦ê°€ì‹œ í•´ì„ ì–´ë ¤ì›€
- âŒ í•™ìŠµ ë°ì´í„°ì— ë¯¼ê°

**ì í•©í•œ ìƒí™©**:
- ë³€ìˆ˜ 3-5ê°œ, ë³µì¡í•œ ì¡°ê±´
- ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš© ì¡´ì¬
- Feature Importance ë¶„ì„ í•„ìš”

---

## 4. ì•Œê³ ë¦¬ì¦˜ 3: LLM íŒ¨í„´ ë°œê²¬ (LLM Pattern Discovery)

### 4.1 ì•Œê³ ë¦¬ì¦˜ ì›ë¦¬
**í•µì‹¬ ì•„ì´ë””ì–´**: ë°ì´í„° ì§‘ê³„ í†µê³„ë¥¼ LLMì´ ë¶„ì„í•˜ì—¬ ìˆ¨ê²¨ì§„ ìƒê´€ê´€ê³„ ë° íŒ¨í„´ ë°œê²¬

### 4.2 ìƒì„¸ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤
```python
import openai
from typing import Dict

class LLMPatternDiscoverer:
    def __init__(self, model: str = "gpt-4o", temperature: float = 0.3):
        """
        LLM ê¸°ë°˜ íŒ¨í„´ ë°œê²¬ Rule ì¶”ì¶œê¸°

        Args:
            model: OpenAI ëª¨ë¸ (gpt-4o ê¶Œì¥)
            temperature: ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
        """
        self.model = model
        self.temperature = temperature

    async def extract_rules(self, feedback_data: List[FeedbackData]) -> List[Rule]:
        """
        LLM ê¸°ë°˜ íŒ¨í„´ ë°œê²¬ Rule ì¶”ì¶œ

        ì²˜ë¦¬ ë‹¨ê³„:
        1. ë°ì´í„° ì§‘ê³„ (í†µê³„ ìš”ì•½)
        2. LLM Prompt ìƒì„±
        3. LLM í˜¸ì¶œ (íŒ¨í„´ ë¶„ì„)
        4. Rule íŒŒì‹± ë° ê²€ì¦
        """
        # 1. ë°ì´í„° ì§‘ê³„
        summary = self._aggregate_data(feedback_data)

        # 2. LLM Prompt ìƒì„±
        prompt = self._create_prompt(summary)

        # 3. LLM í˜¸ì¶œ
        response = await openai.ChatCompletion.acreate(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=self.temperature
        )

        # 4. Rule íŒŒì‹±
        llm_output = response.choices[0].message.content
        rules = self._parse_llm_response(llm_output)

        return rules

    def _aggregate_data(self, feedback_data: List[FeedbackData]) -> Dict:
        """
        í”¼ë“œë°± ë°ì´í„°ë¥¼ í†µê³„ ìš”ì•½ìœ¼ë¡œ ì§‘ê³„

        ì§‘ê³„ í•­ëª©:
        - ì „ì²´ ìƒ˜í”Œ ìˆ˜
        - ê¸ì •/ë¶€ì • í”¼ë“œë°± ìˆ˜
        - ë³€ìˆ˜ë³„ í‰ê·  (ê¸ì •/ë¶€ì • ë¶„ë¦¬)
        - ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
        """
        positive_data = [d for d in feedback_data if d.feedback == "ğŸ‘"]
        negative_data = [d for d in feedback_data if d.feedback == "ğŸ‘"]

        # ë³€ìˆ˜ ëª©ë¡
        variables = list(feedback_data[0].input_data.keys())

        # ë³€ìˆ˜ë³„ í‰ê·  ê³„ì‚°
        stats = {}
        for var in variables:
            positive_values = [d.input_data[var] for d in positive_data]
            negative_values = [d.input_data[var] for d in negative_data]

            stats[f"{var}_avg_positive"] = np.mean(positive_values)
            stats[f"{var}_avg_negative"] = np.mean(negative_values)
            stats[f"{var}_std_positive"] = np.std(positive_values)
            stats[f"{var}_std_negative"] = np.std(negative_values)

        # ìƒê´€ê´€ê³„ ê³„ì‚° (ê¸ì • í”¼ë“œë°± ë°ì´í„°ë§Œ)
        if len(variables) >= 2:
            correlations = self._calculate_correlations(positive_data, variables)
            stats["correlations"] = correlations

        return {
            "total_samples": len(feedback_data),
            "positive_feedback": len(positive_data),
            "negative_feedback": len(negative_data),
            "statistical_summary": stats
        }

    def _calculate_correlations(self, data: List[FeedbackData], variables: List[str]) -> Dict:
        """
        ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ê³„ì‚° (Pearson correlation)
        """
        import pandas as pd

        # DataFrame ìƒì„±
        df = pd.DataFrame([d.input_data for d in data])

        # ìƒê´€í–‰ë ¬ ê³„ì‚°
        corr_matrix = df[variables].corr()

        # ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„ë§Œ ì¶”ì¶œ (|r| > 0.5)
        correlations = {}
        for i, var1 in enumerate(variables):
            for var2 in variables[i+1:]:
                corr = corr_matrix.loc[var1, var2]
                if abs(corr) > 0.5:
                    correlations[f"{var1}_vs_{var2}"] = corr

        return correlations

    def _create_prompt(self, summary: Dict) -> str:
        """
        LLMì—ê²Œ ì „ë‹¬í•  ë¶„ì„ Prompt ìƒì„±
        """
        return f"""
ë„ˆëŠ” ì œì¡°ì—… ë°ì´í„° íŒ¨í„´ ë°œê²¬ ì „ë¬¸ê°€ì•¼.
ì•„ë˜ í†µê³„ ìš”ì•½ì„ ë¶„ì„í•´ì„œ ìˆ¨ê²¨ì§„ Ruleì„ ì œì•ˆí•´ì¤˜.

## ë°ì´í„° ì§‘ê³„ ìš”ì•½
{json.dumps(summary, indent=2)}

## ë¶„ì„ í”„ë¡œì„¸ìŠ¤
1. **í†µê³„ ë¶„ì„**: ê¸ì •/ë¶€ì • í”¼ë“œë°± ê°„ ë³€ìˆ˜ ì°¨ì´ ë°œê²¬
2. **ìƒê´€ê´€ê³„ ë¶„ì„**: ë³€ìˆ˜ ê°„ ê´€ê³„ íŒŒì•…
3. **íŒ¨í„´ ì œì•ˆ**: ë°œê²¬í•œ íŒ¨í„´ì„ ìì—°ì–´ë¡œ ì„¤ëª…
4. **Rule ìƒì„±**: ì œì•ˆí•œ íŒ¨í„´ì„ ì¡°ê±´ì‹ìœ¼ë¡œ ë³€í™˜

## ìš”êµ¬ ì‘ë‹µ í˜•ì‹ (JSON)
```json
{{
  "analysis": "ë¶„ì„ ê²°ê³¼ (1-2ë¬¸ì¥)",
  "pattern_description": "ë°œê²¬í•œ íŒ¨í„´ ì„¤ëª… (2-3ë¬¸ì¥)",
  "extracted_rules": [
    {{
      "rule_expression": "Rule ì¡°ê±´ì‹ (ì˜ˆ: temp > 85 AND vib > 40)",
      "reasoning": "ì´ Ruleì„ ì œì•ˆí•œ ì´ìœ  (í†µê³„ì  ê·¼ê±°)",
      "confidence": 0.0-1.0,
      "method": "llm_pattern_discovery"
    }}
  ]
}}
```

## ì£¼ì˜ì‚¬í•­
- í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ë§Œ Ruleë¡œ ì œì•ˆ (ì°¨ì´ > 5)
- ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ë“¤ (|r| > 0.5)ì„ í•¨ê»˜ ê³ ë ¤
- Rule í‘œí˜„ì‹ì€ ë°˜ë“œì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì¡°ê±´ì‹ í˜•íƒœë¡œ ì‘ì„±
"""

    def _parse_llm_response(self, llm_output: str) -> List[Rule]:
        """
        LLM ì‘ë‹µ JSON íŒŒì‹± ë° Rule ê°ì²´ ë³€í™˜
        """
        import json

        try:
            data = json.loads(llm_output)
            rules = []

            for rule_data in data["extracted_rules"]:
                rule = Rule(
                    expression=rule_data["rule_expression"],
                    reasoning=rule_data["reasoning"],
                    confidence=rule_data["confidence"],
                    method="llm_pattern_discovery"
                )
                rules.append(rule)

            return rules

        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return []
```

### 4.3 ì‹¤ì œ ì ìš© ì˜ˆì‹œ
```python
# ì…ë ¥ ë°ì´í„° (100ê°œ ìƒ˜í”Œ)
feedback_data = [...]  # ë™ì¼ ë°ì´í„°

# Rule ì¶”ì¶œ ì‹¤í–‰
discoverer = LLMPatternDiscoverer(model="gpt-4o", temperature=0.3)
rules = await discoverer.extract_rules(feedback_data)

# LLM ë¶„ì„ ê²°ê³¼
# {
#   "analysis": "ê¸ì • í”¼ë“œë°± ì¼€ì´ìŠ¤ì—ì„œ ì˜¨ë„ì™€ ì§„ë™ì´ ëª¨ë‘ ë†’ì€ ê²½í–¥",
#   "pattern_description": "ê¸ì • ì¼€ì´ìŠ¤ì˜ ì˜¨ë„ í‰ê·  87.5ë„, ì§„ë™ í‰ê·  43.2ë¡œ ë¶€ì • ì¼€ì´ìŠ¤ë³´ë‹¤ ê°ê° 5.2ë„, 4.5 ë†’ìŒ. ì˜¨ë„ì™€ ì§„ë™ì˜ ìƒê´€ê´€ê³„ 0.72ë¡œ ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ í™•ì¸.",
#   "extracted_rules": [...]
# }

# ì¶”ì¶œëœ Rule
print(rules[0])
# Output:
# Rule(
#   expression="temp > 85 AND vib > 40",
#   reasoning="ê¸ì • í”¼ë“œë°± ì¼€ì´ìŠ¤ì—ì„œ temp í‰ê·  87.5, vib í‰ê·  43.2ë¡œ ë¶€ì • ì¼€ì´ìŠ¤ë³´ë‹¤ ê°ê° 5.2, 4.5 ë†’ìŒ. ìƒê´€ê´€ê³„ 0.72ë¡œ ë‘ ë³€ìˆ˜ê°€ í•¨ê»˜ ì›€ì§ì„.",
#   confidence=0.83,
#   method="llm_pattern_discovery"
# )
```

### 4.4 ì¥ë‹¨ì  ë° ì ìš© ìƒí™©
**ì¥ì **:
- âœ… ìˆ¨ê²¨ì§„ ë³µì¡í•œ íŒ¨í„´ ë°œê²¬
- âœ… ìƒê´€ê´€ê³„ ë° ì¸ê³¼ê´€ê³„ ë¶„ì„
- âœ… ìì—°ì–´ ì„¤ëª… ì œê³µ (í•´ì„ì„±)

**ë‹¨ì **:
- âŒ LLM API ë¹„ìš© ë°œìƒ
- âŒ ì‘ë‹µ ì‹œê°„ ëŠë¦¼ (1-2ì´ˆ)
- âŒ LLM ê²°ê³¼ ê²€ì¦ í•„ìš”

**ì í•©í•œ ìƒí™©**:
- ë³€ìˆ˜ 5ê°œ ì´ìƒ, ë³µì¡í•œ ìƒê´€ê´€ê³„
- ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ íŒ¨í„´ ë°œê²¬ ì‹¤íŒ¨
- ì„¤ëª… ê°€ëŠ¥ì„± ì¤‘ìš”

---

## 5. 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ í†µí•© ì „ëµ

### 5.1 í†µí•© ë¡œì§
```python
class RuleIntegrator:
    def integrate_rules(
        self,
        freq_rules: List[Rule],
        tree_rules: List[Rule],
        llm_rules: List[Rule]
    ) -> Rule:
        """
        3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ í†µí•© â†’ ìµœì  Rule ì„ íƒ

        í†µí•© ì „ëµ:
        1. ë™ì¼ Rule í‘œí˜„ì‹ ì°¾ê¸° (ì¼ì¹˜ìœ¨ ê³„ì‚°)
        2. ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê·  ê³„ì‚°
        3. ìƒ˜í”Œ ìˆ˜ í•©ì‚°
        4. ìµœì¢… ì‹ ë¢°ë„ ê°€ì¥ ë†’ì€ Rule ì„ íƒ
        """
        all_rules = freq_rules + tree_rules + llm_rules

        # Rule í‘œí˜„ì‹ ì •ê·œí™” (ê³µë°±, ëŒ€ì†Œë¬¸ì í†µì¼)
        normalized_rules = self._normalize_rules(all_rules)

        # Rule ê·¸ë£¹í™”
        rule_groups = {}
        for rule in normalized_rules:
            expr = rule.expression
            if expr not in rule_groups:
                rule_groups[expr] = []
            rule_groups[expr].append(rule)

        # ê° ê·¸ë£¹ë³„ í†µí•© Rule ìƒì„±
        integrated_rules = []
        for expr, rules in rule_groups.items():
            integrated = self._create_integrated_rule(expr, rules)
            integrated_rules.append(integrated)

        # ìµœê³  ì‹ ë¢°ë„ Rule ë°˜í™˜
        best_rule = max(integrated_rules, key=lambda r: r.confidence)

        return best_rule

    def _normalize_rules(self, rules: List[Rule]) -> List[Rule]:
        """
        Rule í‘œí˜„ì‹ ì •ê·œí™”

        ì˜ˆì‹œ:
        "temp>85 AND vib>40"
        "temp > 85 and vib > 40"
        "temp > 85 AND vibration > 40"
        â†’ "temp > 85 AND vib > 40" (í†µì¼)
        """
        normalized = []
        for rule in rules:
            expr = rule.expression.upper()  # ëŒ€ë¬¸ì í†µì¼
            expr = re.sub(r'\s+', ' ', expr)  # ê³µë°± ì •ë¦¬
            expr = expr.replace(' AND ', ' AND ')  # AND í†µì¼

            # ë³€ìˆ˜ëª… ì•½ì–´ í†µì¼ (vibration â†’ vib)
            expr = self._standardize_variable_names(expr)

            rule.expression = expr
            normalized.append(rule)

        return normalized

    def _create_integrated_rule(self, expression: str, rules: List[Rule]) -> Rule:
        """
        ë™ì¼ í‘œí˜„ì‹ì˜ Ruleë“¤ì„ í†µí•©

        ì‹ ë¢°ë„ ê³„ì‚°:
        - ê°€ì¤‘ í‰ê·  (ìƒ˜í”Œ ìˆ˜ë¡œ ê°€ì¤‘)
        - ì¼ì¹˜ìœ¨ ë³´ë„ˆìŠ¤ (3ê°œ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ ì œì•ˆì‹œ +0.05)
        """
        # ê°€ì¤‘ í‰ê·  ì‹ ë¢°ë„
        total_samples = sum(r.sample_count for r in rules)
        weighted_confidence = sum(
            r.confidence * r.sample_count for r in rules
        ) / total_samples

        # ì¼ì¹˜ìœ¨ ê³„ì‚°
        agreement_level = len(rules) / 3.0  # 3ê°œ ì•Œê³ ë¦¬ì¦˜ ì¤‘ ì¼ì¹˜ìœ¨

        # ì¼ì¹˜ìœ¨ ë³´ë„ˆìŠ¤
        if agreement_level == 1.0:  # 3ê°œ ëª¨ë‘ ì¼ì¹˜
            weighted_confidence = min(weighted_confidence + 0.05, 1.0)

        # í†µí•© Rule ìƒì„±
        integrated_rule = Rule(
            expression=expression,
            confidence=weighted_confidence,
            sample_count=total_samples,
            method="integrated",
            methods_used=[r.method for r in rules],
            agreement_level=agreement_level
        )

        return integrated_rule
```

### 5.2 í†µí•© ì˜ˆì‹œ
```python
# 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼
freq_rules = [
    Rule(expression="temp > 85 AND vib > 40", confidence=0.74, sample_count=82)
]
tree_rules = [
    Rule(expression="temp > 85.0 AND vib > 40.0", confidence=0.89, sample_count=78)
]
llm_rules = [
    Rule(expression="temp > 85 AND vib > 40", confidence=0.83, sample_count=85)
]

# í†µí•© ì‹¤í–‰
integrator = RuleIntegrator()
best_rule = integrator.integrate_rules(freq_rules, tree_rules, llm_rules)

# í†µí•© ê²°ê³¼
print(best_rule)
# Output:
# Rule(
#   expression="temp > 85 AND vib > 40",
#   confidence=0.87,  # (0.74*82 + 0.89*78 + 0.83*85) / (82+78+85) + 0.05(ë³´ë„ˆìŠ¤)
#   sample_count=245,  # 82 + 78 + 85
#   method="integrated",
#   methods_used=["frequency_analysis", "decision_tree", "llm_pattern"],
#   agreement_level=1.0  # 3ê°œ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ ì¼ì¹˜!
# )
```

---

## 6. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### 6.1 ì„±ëŠ¥ ëª©í‘œ
```yaml
ì•Œê³ ë¦¬ì¦˜ë³„ ì‹¤í–‰ ì‹œê°„:
  - ë¹ˆë„ ë¶„ì„: < 1ì´ˆ
  - ê²°ì • íŠ¸ë¦¬: < 2ì´ˆ
  - LLM íŒ¨í„´: < 3ì´ˆ (LLM API ëŒ€ê¸° í¬í•¨)
  - 3ê°€ì§€ ë³‘ë ¬ ì‹¤í–‰: < 3ì´ˆ (ë³‘ë ¬ ì²˜ë¦¬)
  - í†µí•© ë¡œì§: < 500ms

ì •í™•ë„ ëª©í‘œ:
  - Rule ì¶”ì¶œ ì •í™•ë„: 85% ì´ìƒ
  - ì•Œê³ ë¦¬ì¦˜ ì¼ì¹˜ìœ¨: 70% ì´ìƒ (2ê°œ ì´ìƒ ì¼ì¹˜)
  - í†µí•© Rule ì‹ ë¢°ë„: 0.80 ì´ìƒ
```

### 6.2 ì—ëŸ¬ ì²˜ë¦¬ ë° í´ë°±
```python
async def extract_rules_with_fallback(
    feedback_data: List[FeedbackData]
) -> List[Rule]:
    """
    ì—ëŸ¬ ì²˜ë¦¬ ë° í´ë°± ì „ëµ

    ìš°ì„ ìˆœìœ„:
    1. 3ê°€ì§€ ëª¨ë‘ ì‹¤í–‰ (ë³‘ë ¬) â†’ í†µí•©
    2. 1-2ê°œ ì‹¤íŒ¨ì‹œ ì„±ê³µí•œ ì•Œê³ ë¦¬ì¦˜ë§Œ ì‚¬ìš©
    3. ëª¨ë‘ ì‹¤íŒ¨ì‹œ ë¹ˆë„ ë¶„ì„ ë‹¨ë… ì‹¤í–‰ (ê°€ì¥ ì•ˆì „)
    """
    results = {
        "frequency": None,
        "decision_tree": None,
        "llm_pattern": None
    }

    # 1. 3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ ë³‘ë ¬ ì‹¤í–‰
    try:
        freq_task = frequency_analysis(feedback_data)
        tree_task = decision_tree_conversion(feedback_data)
        llm_task = llm_pattern_discovery(feedback_data)

        freq_rules, tree_rules, llm_rules = await asyncio.gather(
            freq_task, tree_task, llm_task,
            return_exceptions=True
        )

        # ì„±ê³µí•œ ê²°ê³¼ë§Œ ì €ì¥
        if not isinstance(freq_rules, Exception):
            results["frequency"] = freq_rules
        if not isinstance(tree_rules, Exception):
            results["decision_tree"] = tree_rules
        if not isinstance(llm_rules, Exception):
            results["llm_pattern"] = llm_rules

    except Exception as e:
        logger.error(f"All algorithms failed: {e}")

    # 2. í†µí•© ì‹¤í–‰
    successful_results = [r for r in results.values() if r is not None]

    if len(successful_results) >= 2:
        # 2ê°œ ì´ìƒ ì„±ê³µ â†’ í†µí•©
        return integrate_rules(*successful_results)

    elif len(successful_results) == 1:
        # 1ê°œë§Œ ì„±ê³µ â†’ ë‹¨ë… ì‚¬ìš©
        return successful_results[0]

    else:
        # ëª¨ë‘ ì‹¤íŒ¨ â†’ ë¹ˆë„ ë¶„ì„ í´ë°±
        logger.warning("All algorithms failed, fallback to frequency analysis")
        return await frequency_analysis(feedback_data)
```

---

## 7. ì¶”ê°€ ì°¸ì¡° ë¬¸ì„œ

- **`docs/services/learning_service.md`**: Learning Service ì „ì²´ ì•„í‚¤í…ì²˜
- **`docs/algorithms/data_aggregation.md`**: ë°ì´í„° ì§‘ê³„ ì•Œê³ ë¦¬ì¦˜ (LLM í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)
- **`docs/architecture/database_design.md`**: feedback_data í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ

---

**Ver2.0 Final í•µì‹¬ í˜ì‹ **: ML ëª¨ë¸ ì—†ì´ ì „í†µì  ì•Œê³ ë¦¬ì¦˜ 3ê°€ì§€ë¡œ í•´ì„ ê°€ëŠ¥í•œ Rule ìë™ ì¶”ì¶œ! ğŸ”¥

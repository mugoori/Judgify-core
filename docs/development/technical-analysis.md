# ê¸°ìˆ ì  ë¶„ì„ ë° ìœ„í—˜ í‰ê°€ (Ver2.0 Final)

ì´ ë¬¸ì„œëŠ” Judgify-core Ver2.0 Finalì˜ **ì•„í‚¤í…ì²˜, ì„±ëŠ¥, ë³´ì•ˆ, ìœ„í—˜ ìš”ì†Œ**ë¥¼ ë¶„ì„í•˜ê³  ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.

---

## ğŸ“Š ë¶„ì„ ê°œìš”

| ë¶„ì„ ì˜ì—­ | ìœ„í—˜ ìˆ˜ì¤€ | ì£¼ìš” ë°œê²¬ì‚¬í•­ | ëŒ€ì‘ ì „ëµ |
|----------|----------|-------------|----------|
| **ì•„í‚¤í…ì²˜** | ğŸŸ¡ ì¤‘ê°„ | 9ê°œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë³µì¡ë„ | ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬, API Gateway |
| **ì„±ëŠ¥** | ğŸŸ¡ ì¤‘ê°„ | LLM ì‘ë‹µ ì‹œê°„, pgvector ê²€ìƒ‰ | ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬, ì¸ë±ì‹± |
| **ë³´ì•ˆ** | ğŸŸ¢ ë‚®ìŒ | AST ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „ | JWT, RBAC, ì…ë ¥ ê²€ì¦ ì² ì € |
| **ìœ„í—˜** | ğŸŸ¡ ì¤‘ê°„ | ì¼ì • ì§€ì—° ê°€ëŠ¥ì„± | ë‹¨ê³„ì  ì¶œì‹œ, MVP ìš°ì„  |

---

## 1. ì•„í‚¤í…ì²˜ ë¶„ì„

### 1.1 ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µì‹  íŒ¨í„´ ë¶„ì„

#### ë¶„ì„ ë‚´ìš©
```
ì‚¬ìš©ì ìš”ì²­
    â†“
API Gateway (8000)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Judgment â”‚ Learning â”‚    BI     â”‚   Chat   â”‚
â”‚ (8002)  â”‚  (8009)  â”‚  (8007)   â”‚  (8008)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“           â†“          â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PostgreSQL + pgvector + Redis       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**í†µì‹  ë°©ì‹**:
- **ë™ê¸° í†µì‹ **: REST API (Judgment â†” Learning, BI â†” Judgment)
- **ë¹„ë™ê¸° í†µì‹ **: Celery + Redis (Action Service)
- **ì‹¤ì‹œê°„ í†µì‹ **: WebSocket (Data Visualization)

#### ğŸŸ¡ ë°œê²¬ëœ ìœ„í—˜
1. **ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„±**: Judgment Serviceê°€ Learning Serviceì— ì˜ì¡´
   - Learning Service ì¥ì•  ì‹œ Few-shot í•™ìŠµ ë¶ˆê°€
   - ì—°ì‡„ ì¥ì•  ê°€ëŠ¥ì„±

2. **ë„¤íŠ¸ì›Œí¬ ì§€ì—°**: 9ê°œ ì„œë¹„ìŠ¤ ê°„ ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œë¡œ ì¸í•œ ì§€ì—°
   - ìµœì•…ì˜ ê²½ìš°: API Gateway â†’ Judgment â†’ Learning â†’ OpenAI (4-hop)
   - ì˜ˆìƒ ì´ ì‘ë‹µ ì‹œê°„: 2-5ì´ˆ

3. **ë°ì´í„° ì¼ê´€ì„±**: ë¶„ì‚° íŠ¸ëœì­ì…˜ ë¯¸ì§€ì›
   - Judgment ì €ì¥ ì„±ê³µ + Learning ì €ì¥ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤
   - Eventually Consistent ë°©ì‹ ì±„íƒ í•„ìš”

#### âœ… ëŒ€ì‘ ì „ëµ

**ì „ëµ 1: Circuit Breaker íŒ¨í„´**
```python
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
async def call_learning_service(input_data):
    """
    Learning Service í˜¸ì¶œ ì‹œ Circuit Breaker ì ìš©
    - 5íšŒ ì—°ì† ì‹¤íŒ¨ ì‹œ Circuit Open (60ì´ˆ ë™ì•ˆ í˜¸ì¶œ ì°¨ë‹¨)
    - Fallback: Few-shot í•™ìŠµ ì—†ì´ ì§„í–‰
    """
    try:
        return await learning_client.get_few_shot_samples(input_data)
    except Exception as e:
        logger.warning(f"Learning Service unavailable: {e}")
        return []  # Fallback: ë¹ˆ Few-shot ìƒ˜í”Œ
```

**ì „ëµ 2: Saga íŒ¨í„´ (ë¶„ì‚° íŠ¸ëœì­ì…˜)**
```python
async def execute_judgment_saga(workflow_input):
    """
    Saga íŒ¨í„´ìœ¼ë¡œ ë¶„ì‚° íŠ¸ëœì­ì…˜ êµ¬í˜„
    """
    judgment_id = None

    try:
        # 1. Judgment ì €ì¥
        judgment_id = await judgment_repo.save(workflow_input)

        # 2. Learning Serviceì— ì˜ˆì¸¡ ì €ì¥
        await learning_repo.save_prediction(judgment_id, result)

        return {"status": "success", "judgment_id": judgment_id}

    except Exception as e:
        # ë¡¤ë°±: Judgment ì‚­ì œ
        if judgment_id:
            await judgment_repo.delete(judgment_id)

        return {"status": "failed", "error": str(e)}
```

**ì „ëµ 3: API Gateway ë ˆë²¨ íƒ€ì„ì•„ì›ƒ**
```yaml
# Kong íƒ€ì„ì•„ì›ƒ ì„¤ì •
routes:
  - path: /api/v2/judgment/*
    service: judgment-service:8002
    timeout: 5000ms  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
    retries: 2       # 2íšŒ ì¬ì‹œë„
```

---

### 1.2 ë°ì´í„° ì¼ê´€ì„± ì „ëµ ë¶„ì„

#### ë¶„ì„ ë‚´ìš©
- **Eventually Consistent** ë°©ì‹ ì±„íƒ
- PostgreSQL ë‹¨ì¼ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© (ACID ë³´ì¥)
- ì„œë¹„ìŠ¤ ê°„ ë°ì´í„° ë™ê¸°í™”ëŠ” ì´ë²¤íŠ¸ ê¸°ë°˜

#### ğŸŸ¢ ì¥ì 
- PostgreSQL ACID íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥
- ë‹¨ì¼ DBë¡œ ì¸í•œ ë‚®ì€ ë³µì¡ë„

#### ğŸŸ¡ ìœ„í—˜
- 9ê°œ ì„œë¹„ìŠ¤ê°€ ë™ì¼ DB ì ‘ê·¼ ì‹œ ë³‘ëª© ê°€ëŠ¥ì„±
- DB ì¥ì•  ì‹œ ì „ì²´ ì‹œìŠ¤í…œ ë‹¤ìš´

#### âœ… ëŒ€ì‘ ì „ëµ

**ì „ëµ 1: PostgreSQL ì½ê¸° ë³µì œë³¸ (Read Replica)**
```yaml
# docker-compose.prod.yml
services:
  postgres-primary:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_REPLICATION_MODE: master

  postgres-replica-1:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_REPLICATION_MODE: slave
      POSTGRES_MASTER_HOST: postgres-primary
```

**ì „ëµ 2: ì—°ê²° í’€ë§ (Connection Pooling)**
```python
# SQLAlchemy ì—°ê²° í’€ ì„¤ì •
engine = create_engine(
    DATABASE_URL,
    pool_size=20,        # ê¸°ë³¸ ì—°ê²° 20ê°œ
    max_overflow=10,     # ìµœëŒ€ ì¶”ê°€ ì—°ê²° 10ê°œ
    pool_pre_ping=True,  # ì—°ê²° ì‚¬ì „ í™•ì¸
    pool_recycle=3600    # 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬ìƒì„±
)
```

**ì „ëµ 3: DB ë°±ì—… ë° ë³µêµ¬ ìë™í™”**
```bash
#!/bin/bash
# ë§¤ì¼ ìì • ìë™ ë°±ì—…
0 0 * * * pg_dump -U judgify -d judgify_core | gzip > /backups/backup_$(date +\%Y\%m\%d).sql.gz

# 7ì¼ ì´ìƒ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
find /backups -name "backup_*.sql.gz" -mtime +7 -delete
```

---

## 2. ì„±ëŠ¥ ë¶„ì„

### 2.1 ì‘ë‹µ ì‹œê°„ ë¶„ì„

#### ì˜ˆìƒ ì‘ë‹µ ì‹œê°„ (95 percentile)

| ì—”ë“œí¬ì¸íŠ¸ | ì£¼ìš” ì²˜ë¦¬ | ì˜ˆìƒ ì‹œê°„ | ëª©í‘œ ì‹œê°„ | ìƒíƒœ |
|-----------|---------|----------|----------|------|
| **Judgment (Rule Only)** | AST íŒŒì‹± + í‰ê°€ | 50-100ms | <200ms | âœ… ì–‘í˜¸ |
| **Judgment (LLM Only)** | OpenAI API í˜¸ì¶œ | 2-4ì´ˆ | <5ì´ˆ | ğŸŸ¡ ì£¼ì˜ |
| **Judgment (Hybrid)** | Rule + LLM | 100ms-4ì´ˆ | <5ì´ˆ | âœ… ì–‘í˜¸ |
| **Learning (Few-shot)** | pgvector ê²€ìƒ‰ | 200-500ms | <1ì´ˆ | âœ… ì–‘í˜¸ |
| **Learning (Rule ì¶”ì¶œ)** | 3ê°œ ì•Œê³ ë¦¬ì¦˜ ë³‘ë ¬ | 5-10ì´ˆ | <15ì´ˆ | ğŸŸ¡ ì£¼ì˜ |
| **BI (ì»´í¬ë„ŒíŠ¸ ì¡°ë¦½)** | MCP ê²€ìƒ‰ + LLM | 3-6ì´ˆ | <8ì´ˆ | ğŸŸ¡ ì£¼ì˜ |

#### ğŸŸ¡ ì„±ëŠ¥ ë³‘ëª© ì§€ì 

1. **LLM API í˜¸ì¶œ** (OpenAI)
   - í‰ê·  2-4ì´ˆ
   - í† í° ìˆ˜ì— ë”°ë¼ ê°€ë³€ì 
   - ì›” ë¹„ìš© ê³ ë ¤ í•„ìš”

2. **pgvector ìœ ì‚¬ë„ ê²€ìƒ‰**
   - 10ë§Œ ê°œ ì´ìƒ ìƒ˜í”Œ ì‹œ ëŠë ¤ì§ˆ ê°€ëŠ¥ì„±
   - ì¸ë±ì‹± ì „ëµ í•„ìˆ˜

3. **Rule ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜**
   - ê²°ì • íŠ¸ë¦¬ í•™ìŠµ: 3-5ì´ˆ
   - LLM íŒ¨í„´ ë°œê²¬: 2-3ì´ˆ
   - ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ìµœì í™” í•„ìš”

#### âœ… ëŒ€ì‘ ì „ëµ

**ì „ëµ 1: Redis ë‹¤ì¸µ ìºì‹±**
```python
# 3ë‹¨ê³„ ìºì‹± ì „ëµ
class CachingStrategy:
    async def get_judgment_result(self, input_hash: str):
        # Level 1: ì¸ë©”ëª¨ë¦¬ ìºì‹œ (LRU, 1000ê°œ)
        if result := self.memory_cache.get(input_hash):
            return result

        # Level 2: Redis ìºì‹œ (TTL 5ë¶„)
        if result := await self.redis_cache.get(input_hash):
            self.memory_cache.set(input_hash, result)
            return result

        # Level 3: DB ì¡°íšŒ
        result = await self.db.query_judgment(input_hash)
        await self.redis_cache.set(input_hash, result, ttl=300)
        self.memory_cache.set(input_hash, result)
        return result
```

**ì „ëµ 2: pgvector ì¸ë±ì‹± ìµœì í™”**
```sql
-- HNSW ì¸ë±ìŠ¤ (Hierarchical Navigable Small World)
CREATE INDEX ON training_samples USING hnsw (sample_embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- IVFFlat ì¸ë±ìŠ¤ (ëŒ€ìš©ëŸ‰ ë°ì´í„°ìš©)
CREATE INDEX ON training_samples USING ivfflat (sample_embedding vector_cosine_ops)
WITH (lists = 100);

-- ì¸ë±ìŠ¤ ì„±ëŠ¥ ë¹„êµ ì¿¼ë¦¬
EXPLAIN ANALYZE
SELECT * FROM training_samples
ORDER BY sample_embedding <-> $1
LIMIT 20;
```

**ì „ëµ 3: LLM API ë°°ì¹˜ ì²˜ë¦¬**
```python
# ë°°ì¹˜ ìš”ì²­ìœ¼ë¡œ ë¹„ìš© ë° ì‹œê°„ ì ˆê°
async def batch_llm_requests(requests: List[dict]):
    """
    ì—¬ëŸ¬ íŒë‹¨ ìš”ì²­ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
    - ë‹¨ì¼ ìš”ì²­: 2-4ì´ˆ Ã— 10íšŒ = 20-40ì´ˆ
    - ë°°ì¹˜ ìš”ì²­: 5-8ì´ˆ (80% ì‹œê°„ ë‹¨ì¶•)
    """
    batch_prompt = "\n\n---\n\n".join([
        f"ìš”ì²­ {i+1}:\n{req}" for i, req in enumerate(requests)
    ])

    response = await openai.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": batch_prompt}]
    )

    return parse_batch_response(response)
```

**ì „ëµ 4: ë¹„ë™ê¸° Rule ì¶”ì¶œ (Celery)**
```python
# Rule ì¶”ì¶œì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
@celery_app.task
def extract_rules_async(workflow_id: UUID):
    """
    ì‚¬ìš©ì ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ Rule ì¶”ì¶œ
    - ì™„ë£Œì‹œ Notification Serviceë¡œ ì•Œë¦¼
    """
    results = asyncio.run(extract_rules(workflow_id))
    notification_service.send(
        channel="#alerts",
        message=f"Rule ì¶”ì¶œ ì™„ë£Œ: {results}"
    )
```

---

### 2.2 í™•ì¥ì„± ë¶„ì„

#### ì˜ˆìƒ íŠ¸ë˜í”½

| ì‹œë‚˜ë¦¬ì˜¤ | ì˜ˆìƒ QPS | ë™ì‹œ ì‚¬ìš©ì | ìƒíƒœ |
|---------|---------|----------|------|
| **ê°œë°œ í™˜ê²½** | 10 | 5 | âœ… ë¬¸ì œì—†ìŒ |
| **ìŠ¤í…Œì´ì§•** | 100 | 50 | âœ… ë¬¸ì œì—†ìŒ |
| **í”„ë¡œë•ì…˜ (ì´ˆê¸°)** | 1000 | 500 | ğŸŸ¡ ëª¨ë‹ˆí„°ë§ í•„ìš” |
| **í”„ë¡œë•ì…˜ (í™•ì¥)** | 10000 | 5000 | ğŸ”´ ìˆ˜í‰ í™•ì¥ í•„ìˆ˜ |

#### âœ… ëŒ€ì‘ ì „ëµ

**ì „ëµ 1: Kubernetes ìˆ˜í‰ í™•ì¥ (HPA)**
```yaml
# Horizontal Pod Autoscaler
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: judgment-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: judgment-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

**ì „ëµ 2: ë¡œë“œë°¸ëŸ°ì‹± ì „ëµ**
```yaml
# Nginx ë¡œë“œë°¸ëŸ°ì„œ
upstream judgment_service {
    least_conn;  # ìµœì†Œ ì—°ê²° ì•Œê³ ë¦¬ì¦˜
    server judgment-1:8002 weight=3;
    server judgment-2:8002 weight=2;
    server judgment-3:8002 weight=1;
}
```

---

## 3. ë³´ì•ˆ ë¶„ì„

### 3.1 AST ê¸°ë°˜ Rule Engine ì•ˆì „ì„± ë¶„ì„

#### ë³´ì•ˆ ìœ„í˜‘ ì‹œë‚˜ë¦¬ì˜¤

| ìœ„í˜‘ | ì„¤ëª… | ìœ„í—˜ ìˆ˜ì¤€ | ëŒ€ì‘ |
|------|------|----------|------|
| **ì½”ë“œ ì¸ì ì…˜** | ì•…ì˜ì ì¸ Rule í‘œí˜„ì‹ ì‹¤í–‰ | ğŸ”´ ë†’ìŒ | AST whitelist |
| **DoS ê³µê²©** | ë¬´í•œë£¨í”„ Rule í‘œí˜„ì‹ | ğŸŸ¡ ì¤‘ê°„ | íƒ€ì„ì•„ì›ƒ ì„¤ì • |
| **ë°ì´í„° íƒˆì·¨** | Ruleì—ì„œ ë¯¼ê° ë°ì´í„° ì ‘ê·¼ | ğŸŸ¡ ì¤‘ê°„ | ë³€ìˆ˜ whitelist |

#### âœ… AST Whitelist êµ¬í˜„
```python
# AST ì•ˆì „ì„± ê²€ì¦
ALLOWED_AST_NODES = {
    ast.Expression,
    ast.BoolOp,
    ast.BinOp,
    ast.UnaryOp,
    ast.Compare,
    ast.Name,
    ast.Constant,
    ast.And,
    ast.Or,
    ast.Not,
    ast.Eq,
    ast.NotEq,
    ast.Lt,
    ast.LtE,
    ast.Gt,
    ast.GtE,
    ast.Add,
    ast.Sub,
    ast.Mult,
    ast.Div,
}

class ASTValidator:
    def validate(self, tree: ast.AST) -> bool:
        """
        AST íŠ¸ë¦¬ì˜ ëª¨ë“  ë…¸ë“œê°€ whitelistì— ìˆëŠ”ì§€ ê²€ì¦
        """
        for node in ast.walk(tree):
            if type(node) not in ALLOWED_AST_NODES:
                raise SecurityError(
                    f"Forbidden AST node: {type(node).__name__}"
                )

        return True

    def validate_variables(self, tree: ast.AST, allowed_vars: Set[str]):
        """
        Ruleì—ì„œ ì‚¬ìš©í•˜ëŠ” ë³€ìˆ˜ê°€ í—ˆìš©ëœ ë³€ìˆ˜ì¸ì§€ ê²€ì¦
        """
        for node in ast.walk(tree):
            if isinstance(node, ast.Name):
                if node.id not in allowed_vars:
                    raise SecurityError(
                        f"Forbidden variable: {node.id}"
                    )
```

**ì˜ˆì‹œ: ì•…ì˜ì ì¸ Rule ì°¨ë‹¨**
```python
# âŒ ì°¨ë‹¨ë˜ëŠ” ì•…ì˜ì  Rule í‘œí˜„ì‹ë“¤
evil_rules = [
    "__import__('os').system('rm -rf /')",  # ì‹œìŠ¤í…œ ëª…ë ¹ ì‹¤í–‰
    "eval('malicious code')",                # eval ì‹¤í–‰
    "[x for x in range(99999999)]",          # ë©”ëª¨ë¦¬ ì†Œì§„
]

# âœ… í—ˆìš©ë˜ëŠ” ì•ˆì „í•œ Rule í‘œí˜„ì‹ë“¤
safe_rules = [
    "temperature > 85 and vibration > 40",
    "(temp + vib) / 2 > 60",
    "status == 'RUNNING' or status == 'IDLE'",
]
```

---

### 3.2 ì¸ì¦ ë° ì¸ê°€ ë¶„ì„

#### JWT ì¸ì¦ êµ¬í˜„
```python
# JWT í† í° ìƒì„± ë° ê²€ì¦
from jose import jwt, JWTError
from datetime import datetime, timedelta

SECRET_KEY = os.getenv("JWT_SECRET_KEY")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

def create_access_token(data: dict) -> str:
    """JWT ì•¡ì„¸ìŠ¤ í† í° ìƒì„±"""
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

def verify_token(token: str) -> dict:
    """JWT í† í° ê²€ì¦"""
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
```

#### RBAC (Role-Based Access Control)
```python
# ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´
class Role(str, Enum):
    ADMIN = "admin"        # ëª¨ë“  ê¶Œí•œ
    OPERATOR = "operator"  # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë° ì¡°íšŒ
    VIEWER = "viewer"      # ì¡°íšŒë§Œ ê°€ëŠ¥

ROLE_PERMISSIONS = {
    Role.ADMIN: ["*"],
    Role.OPERATOR: [
        "workflow:execute",
        "workflow:read",
        "judgment:read",
    ],
    Role.VIEWER: [
        "workflow:read",
        "judgment:read",
        "dashboard:read",
    ],
}

def check_permission(user_role: Role, required_permission: str) -> bool:
    """ê¶Œí•œ í™•ì¸"""
    permissions = ROLE_PERMISSIONS[user_role]
    return "*" in permissions or required_permission in permissions
```

---

### 3.3 ë°ì´í„° ë³´ì•ˆ ë¶„ì„

#### ë¯¼ê° ë°ì´í„° ì•”í˜¸í™”
```python
# AES-256 ì•”í˜¸í™”
from cryptography.fernet import Fernet

class DataEncryption:
    def __init__(self):
        self.key = os.getenv("ENCRYPTION_KEY")
        self.cipher = Fernet(self.key)

    def encrypt(self, data: str) -> str:
        """ë°ì´í„° ì•”í˜¸í™”"""
        return self.cipher.encrypt(data.encode()).decode()

    def decrypt(self, encrypted_data: str) -> str:
        """ë°ì´í„° ë³µí˜¸í™”"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()

# ë¯¼ê° ë°ì´í„° í•„ë“œ
SENSITIVE_FIELDS = [
    "judgment_data.input_data.password",
    "judgment_data.input_data.api_key",
    "judgment_data.input_data.secret",
]
```

---

## 4. ìœ„í—˜ ë¶„ì„ ë° ëŒ€ì‘ ì „ëµ

### 4.1 ì¼ì • ìœ„í—˜

| ìœ„í—˜ ìš”ì†Œ | í™•ë¥  | ì˜í–¥ | ì‹¬ê°ë„ | ëŒ€ì‘ ì „ëµ |
|----------|------|------|--------|----------|
| **LLM API ë³€ê²½** | ğŸŸ¡ ì¤‘ê°„ | ğŸ”´ ë†’ìŒ | ğŸŸ¡ ì¤‘ê°„ | OpenAI API ë²„ì „ ê³ ì •, ëŒ€ì²´ API ì¤€ë¹„ |
| **pgvector ì„±ëŠ¥ ì €í•˜** | ğŸŸ¡ ì¤‘ê°„ | ğŸŸ¡ ì¤‘ê°„ | ğŸŸ¡ ì¤‘ê°„ | ì¸ë±ì‹± ìµœì í™”, ìƒ¤ë”© ê²€í†  |
| **ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„±** | ğŸŸ¢ ë‚®ìŒ | ğŸŸ¡ ì¤‘ê°„ | ğŸŸ¢ ë‚®ìŒ | Circuit Breaker, Fallback |
| **ì¼ì • ì§€ì—°** | ğŸŸ¡ ì¤‘ê°„ | ğŸŸ¡ ì¤‘ê°„ | ğŸŸ¡ ì¤‘ê°„ | ë‹¨ê³„ì  ì¶œì‹œ, MVP ìš°ì„  |

#### ëŒ€ì‘ ì „ëµ: OpenAI API ë²„ì „ ê³ ì •
```python
# OpenAI API ë²„ì „ ê³ ì •
OPENAI_API_VERSION = "2023-05-15"  # íŠ¹ì • ë²„ì „ ê³ ì •

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    default_headers={"OpenAI-Version": OPENAI_API_VERSION}
)
```

---

### 4.2 ê¸°ìˆ  ìœ„í—˜

| ê¸°ìˆ  | ìœ„í—˜ | í™•ë¥  | ëŒ€ì‘ |
|------|------|------|------|
| **FastAPI** | ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ | ğŸŸ¢ ë‚®ìŒ | Poetryë¡œ ë²„ì „ ê³ ì • |
| **PostgreSQL** | ë°ì´í„° ì†ì‹¤ | ğŸŸ¢ ë‚®ìŒ | ìë™ ë°±ì—… + ë³µì œë³¸ |
| **pgvector** | ì„±ëŠ¥ ì €í•˜ | ğŸŸ¡ ì¤‘ê°„ | HNSW ì¸ë±ì‹± |
| **Redis** | ë©”ëª¨ë¦¬ ë¶€ì¡± | ğŸŸ¡ ì¤‘ê°„ | TTL ì„¤ì • + LRU ì •ì±… |

---

### 4.3 ë¹„ì¦ˆë‹ˆìŠ¤ ìœ„í—˜

#### ë¹„ìš© ë¶„ì„ (ì›” ê¸°ì¤€)

| í•­ëª© | ì˜ˆìƒ ë¹„ìš© | ë¹„ê³  |
|------|----------|------|
| **OpenAI API** | $500-2000 | ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ê°€ë³€ |
| **PostgreSQL (AWS RDS)** | $200-500 | db.t3.medium ê¸°ì¤€ |
| **Redis (AWS ElastiCache)** | $100-200 | cache.t3.medium ê¸°ì¤€ |
| **Kubernetes (AWS EKS)** | $300-600 | 3-6 ë…¸ë“œ ê¸°ì¤€ |
| **ì´ ì˜ˆìƒ ë¹„ìš©** | **$1100-3300** | ì´ˆê¸° ë‹¨ê³„ |

#### ëŒ€ì‘ ì „ëµ: ë¹„ìš© ìµœì í™”
```python
# LLM í˜¸ì¶œ ìµœì í™”
class CostOptimizer:
    async def should_use_llm(self, input_data: dict, rule_result: RuleResult) -> bool:
        """
        LLM í˜¸ì¶œ ì—¬ë¶€ ê²°ì • (ë¹„ìš© ì ˆê°)
        - Rule ì„±ê³µ + ë†’ì€ ì‹ ë¢°ë„ â†’ LLM ë¶ˆí•„ìš”
        - Rule ì‹¤íŒ¨ ë˜ëŠ” ë‚®ì€ ì‹ ë¢°ë„ â†’ LLM í•„ìš”
        """
        if rule_result.success and rule_result.confidence >= 0.8:
            return False  # LLM ìƒëµ (ë¹„ìš© ì ˆê°)

        return True  # LLM í˜¸ì¶œ

    async def use_cheaper_model(self, complexity: float) -> str:
        """
        ë³µì¡ë„ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ
        - ë‹¨ìˆœí•œ ì¼€ì´ìŠ¤: gpt-3.5-turbo (ì €ë¹„ìš©)
        - ë³µì¡í•œ ì¼€ì´ìŠ¤: gpt-4 (ê³ ë¹„ìš©, ê³ ì •í™•ë„)
        """
        if complexity < 0.5:
            return "gpt-3.5-turbo"  # 20ë°° ì €ë ´
        else:
            return "gpt-4"
```

---

## 5. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì „ëµ

### 5.1 í•µì‹¬ ë©”íŠ¸ë¦­

#### ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
```python
# Prometheus ë©”íŠ¸ë¦­ ì •ì˜
from prometheus_client import Counter, Histogram, Gauge

# íŒë‹¨ ì‹¤í–‰ ì¹´ìš´í„°
judgment_executions_total = Counter(
    'judgment_executions_total',
    'Total number of judgment executions',
    ['method', 'result', 'workflow_id']
)

# íŒë‹¨ ì‹¤í–‰ ì‹œê°„
judgment_execution_duration = Histogram(
    'judgment_execution_duration_seconds',
    'Duration of judgment execution',
    ['method']
)

# íŒë‹¨ ì‹ ë¢°ë„ ì ìˆ˜
judgment_confidence_score = Gauge(
    'judgment_confidence_score',
    'Average confidence score of judgments',
    ['workflow_id']
)

# LLM API ë¹„ìš©
llm_api_cost_total = Counter(
    'llm_api_cost_dollars',
    'Total LLM API cost in dollars'
)
```

#### ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
- CPU ì‚¬ìš©ë¥ 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
- API ì‘ë‹µ ì‹œê°„
- ì—ëŸ¬ìœ¨

---

### 5.2 ì•Œë¦¼ ê·œì¹™

```yaml
# Prometheus Alertmanager ê·œì¹™
groups:
  - name: judgify_alerts
    rules:
      # íŒë‹¨ ì‹¤í–‰ ì‹¤íŒ¨ìœ¨ 50% ì´ìƒ
      - alert: HighJudgmentFailureRate
        expr: rate(judgment_executions_total{result="failed"}[5m]) > 0.5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High judgment failure rate"

      # API ì‘ë‹µ ì‹œê°„ 5ì´ˆ ì´ìƒ
      - alert: SlowAPIResponse
        expr: histogram_quantile(0.95, rate(judgment_execution_duration_seconds_bucket[5m])) > 5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "API response time > 5 seconds"

      # LLM API ë¹„ìš© $1000 ì´ˆê³¼
      - alert: HighLLMCost
        expr: llm_api_cost_dollars > 1000
        labels:
          severity: info
        annotations:
          summary: "LLM API cost exceeds $1000"
```

---

## 6. ì¬í•´ ë³µêµ¬ ê³„íš (Disaster Recovery)

### 6.1 ë°±ì—… ì „ëµ

| ëŒ€ìƒ | ë°±ì—… ì£¼ê¸° | ë³´ê´€ ê¸°ê°„ | ë³µêµ¬ ëª©í‘œ (RTO) |
|------|----------|----------|----------------|
| **PostgreSQL** | ë§¤ì¼ ìì • | 30ì¼ | 1ì‹œê°„ |
| **Redis** | ë§¤ 6ì‹œê°„ | 7ì¼ | 30ë¶„ |
| **ì„¤ì • íŒŒì¼** | Git ì»¤ë°‹ì‹œ | ì˜êµ¬ | ì¦‰ì‹œ |
| **ì½”ë“œ** | Git í‘¸ì‹œì‹œ | ì˜êµ¬ | ì¦‰ì‹œ |

### 6.2 ì¥ì•  ë³µêµ¬ ì ˆì°¨

```bash
#!/bin/bash
# ì¬í•´ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

# 1. ìµœì‹  ë°±ì—… í™•ì¸
LATEST_BACKUP=$(ls -t /backups/*.sql.gz | head -1)
echo "Latest backup: $LATEST_BACKUP"

# 2. PostgreSQL ë³µêµ¬
gunzip -c $LATEST_BACKUP | psql -U judgify -d judgify_core

# 3. Redis ë³µêµ¬
redis-cli --rdb /backups/dump.rdb

# 4. Kubernetes ì¬ë°°í¬
kubectl rollout restart deployment/judgment-service
kubectl rollout restart deployment/learning-service
kubectl rollout restart deployment/bi-service

# 5. í—¬ìŠ¤ì²´í¬
for service in judgment learning bi; do
    curl -f http://$service-service:800X/health || echo "$service health check failed"
done
```

---

## âœ… ë¶„ì„ ìš”ì•½ ë° ê¶Œì¥ì‚¬í•­

### ğŸ¯ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” (P0)
1. âœ… **AST whitelist êµ¬í˜„** - ë³´ì•ˆ ìµœìš°ì„ 
2. âœ… **Redis ìºì‹± ì „ëµ** - ì„±ëŠ¥ ìµœì í™”
3. âœ… **pgvector HNSW ì¸ë±ì‹±** - Few-shot ê²€ìƒ‰ ì„±ëŠ¥
4. âœ… **Circuit Breaker íŒ¨í„´** - ì„œë¹„ìŠ¤ ì•ˆì •ì„±

### ğŸŸ¡ ì¡°ê¸° êµ¬í˜„ ê¶Œì¥ (P1)
5. Prometheus + Grafana ëª¨ë‹ˆí„°ë§
6. PostgreSQL ì½ê¸° ë³µì œë³¸
7. Kubernetes HPA ì„¤ì •
8. LLM API ë¹„ìš© ìµœì í™”

### ğŸŸ¢ ì ì§„ì  ê°œì„  (P2)
9. ELK Stack ë¡œê·¸ ë¶„ì„
10. ì¬í•´ ë³µêµ¬ ìë™í™”
11. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
12. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬

---

**ë¶„ì„ ì™„ë£Œì¼**: 2025-10-20
**ë¶„ì„ì**: Claude (AI Engineer + Architect)
**ë‹¤ìŒ ë‹¨ê³„**: /speckit.implement - ì‹¤ì œ êµ¬í˜„ ì‹œì‘
